{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPWUm4M98Dbv"
   },
   "source": [
    "FinBERT testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "isOR_Fw_8Bt7"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbGuQYudHlxY",
    "outputId": "b350d788-bdbd-4415-f3c7-611f9783d401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q newspaper3k pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ii4fcVDzjFx8"
   },
   "outputs": [],
   "source": [
    "!pip install -q lxml-html-clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6C-f3v6kS78g",
    "outputId": "0333b233-6077-4657-b29e-0c4d0669dfe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pandas 2.2.2\n",
      "Uninstalling pandas-2.2.2:\n",
      "  Successfully uninstalled pandas-2.2.2\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pandas-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pandas -y\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OWV7T2_JH7Ok"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsJ2EYCuIUlz",
    "outputId": "d82cfd16-5def-4a9a-eee3-a7c5d8a3f70b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "fbcc51559e7b42f496cc05592127a1d9",
      "0f1bfe056199463fbf21d7ab8db71087",
      "8c9ba4d543c748b194c5b4fd49719cd2",
      "b00b5e85c6ac4d2ab59fbe8d438bc7e9",
      "ffdad097ef8c4a7d961670cede1d65f9",
      "0f54cb4034e44b5a860cec94eb70e5f8",
      "58bf3e1b3d894fbca84e0f5d47b9491d",
      "04d1884b23cb4f91b4be30f018652a6a",
      "7cce38151a7b4ad8a8bb449291e45f8d",
      "971fbdbc971a4a3db05b6debe7ee9c78",
      "4732b406cd3e4beb9ef1c7c439d2d3ab",
      "b29737915a974f8f9dbe86b3183a6940",
      "b8ff565c064a48b68604def8294a6a36",
      "e021405063db4f52ba5bdc07852974f9",
      "3282cdecfc8547c48d5ffa78ca859890",
      "7cbfdf8d7b3d4cc1af0b84cf81ead3e3",
      "5eb6618011b545c8af48afbedee0bf9d",
      "1ca725d3bf2d4d9793b26cd947bfba25",
      "f768d284e3184c7c986395926ac8ee3b",
      "c478a73580f14935aa30d101b283fd9e",
      "5cc6008f474f49aeb1dce9e5c7707b3e",
      "a59fa2b78147485ca7768260acc47f39",
      "a1c1c1b8c56b438f88377d24fde8998c",
      "d1d8ec9697ed466cbe1f12fbffd870d0",
      "a1c5c7983543428b960d6517133d6d5e",
      "7f853399e45443aea4e5fa97e0704db7",
      "f0b25f27c6fe42e488cfa60f0a0f138f",
      "58c06a6465fd4b71aa947262e335d299",
      "69504145b9e44eae9dd27ead9e69e1a2",
      "880ecf6d73f249ed90cb03fccc39083a",
      "40350e7234a64f5e8d14b1a7c2785797",
      "a0735f2f741b4f81b231302e4840772b",
      "bc29ae56e5d04722a76141ac47ae04a3",
      "bb1a9f9dd921430b850b475c53068573",
      "08c1182c80bb4a9aada26f53d1abacf4",
      "4639c1a60a7f4145841fae22bef42625",
      "e2f6fc4ad47843648588bea13e56b2b3",
      "1824ad8b682c43a49d7dde66c2b6cb00",
      "e602e5b0c5de45ada254c2c31ac770ce",
      "83ad61ebca374fd497bf7441df2a6d33",
      "e1b5e110bb9b41c8bfdd71c595bc0782",
      "d7f81fa802654fe2825b823e9a7b139b",
      "c5cef2bc73124433873ad61b360798aa",
      "00b2e6418e2444d98123638bb9052d65",
      "9958940f00c54cf39047a1be983e8bc2",
      "3bc9c648f1c14749833b61c0edc3ae14",
      "d0b2a671eb27437885f7a9945c1ea48e",
      "01be476b3a6d40449c5632b4a8a57599",
      "97ddfd3151f84342b6682fba38a82c0d",
      "eea1ab83fca744f793fb025736ededd6",
      "ff99ebd3e8bb468cb3bd879c5ad385e0",
      "7a4c7eb15a964128adcb76328df1afd1",
      "b4aa04b12b644e35ab521ef38c32d2f0",
      "ee2c2b0bec3e4e5db8975f09e5e0742b",
      "b0e70365d51547acbfd197aa7dcc8680"
     ]
    },
    "id": "Ie4ZyFLX8qr3",
    "outputId": "1df5c5c8-ceff-4a11-a6e4-1e744ef5a58f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcc51559e7b42f496cc05592127a1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29737915a974f8f9dbe86b3183a6940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c1c1b8c56b438f88377d24fde8998c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1a9f9dd921430b850b475c53068573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9958940f00c54cf39047a1be983e8bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\", device=0 if torch.cuda.is_available() else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eZNPi3VS9NF5"
   },
   "outputs": [],
   "source": [
    "test_data = [\"Adherents of the Dogs strategy assume that the highest yielding Dow stocks are unfairly and temporarily depressed. That presumably means they'll hold up better than the S&P 500. And that seems to be the case in 2022. Adding the Dogs stocks' 4% average dividend yield coming into 2022 plus their average 1.8% drop still left investors with a positive return of more than 2% on the stocks. Additionally, half of last year's Dogs, including International Business Machines (IBM), Chevron (CVX), Merck (MRK), Amgen (AMGN), and Coca-Cola (KO) posted gains in 2022. Chevron alone gained 53% on top of yielding 4.6%.\",\n",
    "             \"The biggest dog of them all for 2023 is fallen communication services firm Verizon (VZ). The company, which has seen its stock drop 24% in 2022, is now yielding more than any other Dow stock: 6.5%. It's important to note, though, there's a reason Verizon's stock is shrinking. Verizon's profit is seen falling nearly 4% in 2022 and nearly 3% in 2023.\",\n",
    "             \"the most average stock is stock ABC, which did not change at all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9U2qW973F3Ox",
    "outputId": "1c4eabdf-f0a4-4b55-c062-8b0723b3c3f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'positive', 'score': 0.8819699287414551}, {'label': 'negative', 'score': 0.9748380184173584}, {'label': 'neutral', 'score': 0.9416248202323914}]\n"
     ]
    }
   ],
   "source": [
    "result = pipe(test_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1l0n0S1HhiT"
   },
   "source": [
    "Upload local files for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wS1cxDAkvz4k",
    "outputId": "10446995-1e8a-422a-9a46-befae3ceef79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load FinBERT model and tokenizer once\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DUoJtUpIi4Mn"
   },
   "outputs": [],
   "source": [
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJ0cmNpcPy7Q",
    "outputId": "c7bbfe44-aec9-4f48-ddcf-d3a9f60e4f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "RxZqGJ8fHgEc",
    "outputId": "c90e13fe-297a-4874-dbb0-49f84e13fa32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-da60c9df-eddc-450b-8f07-d0af7988fd74\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-da60c9df-eddc-450b-8f07-d0af7988fd74\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving AAPL_main.csv to AAPL_main.csv\n",
      "Saving AAPL_relation.csv to AAPL_relation.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "usaWRHgDNQ7i",
    "outputId": "74d32b99-be5e-4a8d-c188-42355cbcd3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User uploaded file \"AAPL_main.csv\" with length 5386490 bytes\n",
      "User uploaded file \"AAPL_relation.csv\" with length 1017748 bytes\n"
     ]
    }
   ],
   "source": [
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ci5k7GErkQIW",
    "outputId": "903b96a9-8e57-487e-a538-4073d943d5e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL_main.csv  AAPL_relation.csv  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tM0EWpm5NTQn"
   },
   "outputs": [],
   "source": [
    "def get_news_text(url):\n",
    "    article = Article(url)\n",
    "    try:\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.text\n",
    "    except Exception as error:\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "cbxH-4AvNfE2"
   },
   "outputs": [],
   "source": [
    "def combine_dataframes_with_time_range(main_df, relation_df, start_time, end_time):\n",
    "    start_time = pd.to_datetime(start_time)\n",
    "    end_time = pd.to_datetime(end_time)\n",
    "\n",
    "    main_df['publish_time'] = pd.to_datetime(main_df['publish_time'])\n",
    "    relation_df['time'] = pd.to_datetime(relation_df['time'])\n",
    "    filtered_rel = relation_df[relation_df['ticker'] == relation_df['source_ticker']]\n",
    "\n",
    "    # Merge the two dataframes on `id` and `news_id`\n",
    "    merged_df = main_df.merge(filtered_rel, left_on='id', right_on='news_id', how='inner')\n",
    "\n",
    "    filtered_df = merged_df\n",
    "\n",
    "    time_filtered_df = filtered_df[(filtered_df['publish_time'] >= start_time) & (filtered_df['publish_time'] <= end_time)]\n",
    "\n",
    "    time_filtered_df = time_filtered_df.rename(columns={'ticker_x': 'ticker'})\n",
    "\n",
    "    result_df = time_filtered_df[['id', 'publish_time', 'article_url', 'sentiment', 'ticker']]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asDq71GHKZVV"
   },
   "outputs": [],
   "source": [
    "# def combine_dataframes_with_time_range(main_df, relation_df, start_time, end_time):\n",
    "#     start_time = pd.to_datetime(start_time)\n",
    "#     end_time = pd.to_datetime(end_time)\n",
    "\n",
    "#     main_df['publish_time'] = pd.to_datetime(main_df['publish_time'])\n",
    "#     relation_df['time'] = pd.to_datetime(relation_df['time'])\n",
    "\n",
    "#     relation_df_grouped = relation_df.groupby('news_id')['sentiment'].agg(lambda x: x.mode()[0]).reset_index()\n",
    "\n",
    "#     merged_df = main_df.merge(relation_df_grouped, left_on='id', right_on='news_id', how='inner')\n",
    "\n",
    "#     time_filtered_df = merged_df[(merged_df['publish_time'] >= start_time) & (merged_df['publish_time'] <= end_time)]\n",
    "\n",
    "#     result_df = time_filtered_df[['id', 'publish_time', 'article_url', 'sentiment']]\n",
    "\n",
    "#     return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyhJO13jhoCg"
   },
   "outputs": [],
   "source": [
    "# def compare_sentiments_finbert(merged_df, model, tokenizer, truncate_or_split=\"truncate\"):\n",
    "#     \"\"\"\n",
    "#     Compare sentiment labels from FinBERT predictions with existing sentiment labels,\n",
    "#     handling text sequences longer than 512 tokens.\n",
    "#     \"\"\"\n",
    "#     # Map numerical labels to sentiment strings\n",
    "#     label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "#     # Initialize a 3x3 matrix for results\n",
    "#     sentiment_matrix = {\n",
    "#         \"positive\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "#         \"neutral\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "#         \"negative\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "#     }\n",
    "\n",
    "#     i = 0  # Counter to track progress\n",
    "\n",
    "#     for row in merged_df.itertuples():\n",
    "#         if i % 10 == 0:\n",
    "#             print(f\"Processing: {i}\")\n",
    "\n",
    "#         url = row.article_url\n",
    "#         text = get_news_text(url)\n",
    "\n",
    "#         if text != \"Error\" and isinstance(text, str):  # Check for valid text retrieval\n",
    "#             if truncate_or_split == \"split\":\n",
    "#                 # Tokenize without truncation to check length\n",
    "#                 tokens = tokenizer(text, truncation=False, add_special_tokens=True)[\"input_ids\"]\n",
    "\n",
    "#                 if len(tokens) > 512:\n",
    "#                     chunk_size = 512\n",
    "#                     chunks = [text[start:start + chunk_size] for start in range(0, len(text), chunk_size)]\n",
    "\n",
    "#                     # Get predictions for each chunk\n",
    "#                     chunk_predictions = []\n",
    "#                     for chunk in chunks:\n",
    "#                         inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "#                         outputs = model(**inputs)\n",
    "#                         prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "#                         chunk_predictions.append(label_map[prediction])\n",
    "\n",
    "#                     # Use the most frequent label\n",
    "#                     predicted = max(set(chunk_predictions), key=chunk_predictions.count)\n",
    "#                 else:\n",
    "#                     # Text is already within limits\n",
    "#                     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "#                     outputs = model(**inputs)\n",
    "#                     prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "#                     predicted = label_map[prediction]\n",
    "#             else:\n",
    "#                 inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "#                 outputs = model(**inputs)\n",
    "#                 prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "#                 predicted = label_map[prediction]\n",
    "\n",
    "#             old = row.sentiment  # Old sentiment label\n",
    "\n",
    "#             # Increment the corresponding matrix cell\n",
    "#             if old in sentiment_matrix and predicted in sentiment_matrix:\n",
    "#                 sentiment_matrix[predicted][old] += 1\n",
    "\n",
    "#         i += 1\n",
    "\n",
    "#     result_matrix = pd.DataFrame(sentiment_matrix).T\n",
    "\n",
    "#     return result_matrix\n",
    "\n",
    "def compare_sentiments_finbert(merged_df, model, tokenizer, truncate_or_split=\"truncate\"):\n",
    "    \"\"\"\n",
    "    Compare sentiment labels from FinBERT predictions with existing sentiment labels,\n",
    "    handling text sequences longer than 512 tokens and ensuring the model and inputs are moved to the GPU.\n",
    "    \"\"\"\n",
    "    label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "    sentiment_matrix = {\n",
    "        \"positive\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "        \"neutral\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "        \"negative\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "    }\n",
    "\n",
    "\n",
    "    i = 0 \n",
    "\n",
    "    for row in merged_df.itertuples():\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing: {i}\")\n",
    "\n",
    "        url = row.article_url\n",
    "        text = get_news_text(url)\n",
    "\n",
    "        if text != \"Error\" and isinstance(text, str):\n",
    "            if truncate_or_split == \"split\":\n",
    "                tokens = tokenizer(text, truncation=False, add_special_tokens=True)[\"input_ids\"]\n",
    "\n",
    "                if len(tokens) > 512:\n",
    "                    chunk_size = 512\n",
    "                    chunks = [text[start:start + chunk_size] for start in range(0, len(text), chunk_size)]\n",
    "\n",
    "                    chunk_predictions = []\n",
    "                    for chunk in chunks:\n",
    "                        inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "                        inputs = {key: val.to(device) for key, val in inputs.items()}  # Move inputs to GPU\n",
    "                        outputs = model(**inputs)\n",
    "                        prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "                        chunk_predictions.append(label_map[prediction])\n",
    "\n",
    "                    # Use the most frequent label\n",
    "                    predicted = max(set(chunk_predictions), key=chunk_predictions.count)\n",
    "                else:\n",
    "                    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "                    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "                    outputs = model(**inputs)\n",
    "                    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "                    predicted = label_map[prediction]\n",
    "            else:\n",
    "                inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "                inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "                outputs = model(**inputs)\n",
    "                prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "                predicted = label_map[prediction]\n",
    "\n",
    "            old = row.sentiment \n",
    "\n",
    "            # Increment the corresponding matrix cell\n",
    "            if old in sentiment_matrix and predicted in sentiment_matrix:\n",
    "                sentiment_matrix[predicted][old] += 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # Convert the dictionary to a pandas DataFrame\n",
    "    result_matrix = pd.DataFrame(sentiment_matrix).T  # Transpose for correct layout\n",
    "\n",
    "    return result_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRd05XbZDToc"
   },
   "outputs": [],
   "source": [
    "# def compare_sentiments_finbert_pipeline(merged_df, pipe, truncate_or_split=\"truncate\"):\n",
    "#     \"\"\"\n",
    "#     Compare sentiment labels from FinBERT predictions with existing sentiment labels,\n",
    "#     handling text sequences longer than 512 tokens using the transformers pipeline.\n",
    "#     \"\"\"\n",
    "#     sentiment_matrix = {\n",
    "#         \"positive\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "#         \"neutral\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "#         \"negative\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "#     }\n",
    "\n",
    "#     i = 0 \n",
    "\n",
    "#     for row in merged_df.itertuples():\n",
    "#         if i % 10 == 0:\n",
    "#             print(f\"Processing: {i}\")\n",
    "\n",
    "#         url = row.article_url\n",
    "#         text = get_news_text(url) \n",
    "\n",
    "#         if text != \"Error\" and isinstance(text, str): \n",
    "#             if truncate_or_split == \"split\":\n",
    "#                 tokens = pipe.tokenizer(text, truncation=False, add_special_tokens=True)[\"input_ids\"]\n",
    "\n",
    "#                 if len(tokens) > 512:\n",
    "#                     chunk_size = 512\n",
    "#                     chunks = [text[start:start + chunk_size] for start in range(0, len(text), chunk_size)]\n",
    "\n",
    "#                     # Get predictions for each chunk\n",
    "#                     chunk_predictions = []\n",
    "#                     for chunk in chunks:\n",
    "#                         result = pipe(chunk)\n",
    "#                         chunk_predictions.append(result[0]['label'])\n",
    "\n",
    "#                     # Use the most frequent label\n",
    "#                     predicted = max(set(chunk_predictions), key=chunk_predictions.count)\n",
    "#                 else:\n",
    "#                     result = pipe(text)\n",
    "#                     predicted = result[0]['label']\n",
    "#             else:\n",
    "#                 result = pipe(text, truncation=True)\n",
    "#                 predicted = result[0]['label']\n",
    "\n",
    "#             old = row.sentiment \n",
    "\n",
    "#             if old in sentiment_matrix and predicted in sentiment_matrix:\n",
    "#                 sentiment_matrix[predicted][old] += 1\n",
    "\n",
    "#         i += 1\n",
    "\n",
    "#     result_matrix = pd.DataFrame(sentiment_matrix).T  # Transpose for correct layout\n",
    "\n",
    "#     return result_matrix\n",
    "\n",
    "def compare_sentiments_finbert_pipeline(merged_df, pipe, truncate_or_split=\"truncate\"):\n",
    "    \"\"\"\n",
    "    Compare sentiment labels from FinBERT predictions with existing sentiment labels,\n",
    "    handling text sequences longer than 512 tokens using the transformers pipeline.\n",
    "    \"\"\"\n",
    "    sentiment_matrix = {\n",
    "        \"positive\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "        \"neutral\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "        \"negative\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "    }\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for row in merged_df.itertuples():\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing: {i}\")\n",
    "\n",
    "        url = row.article_url\n",
    "        text = get_news_text(url)  \n",
    "\n",
    "        if text != \"Error\" and isinstance(text, str):\n",
    "            if truncate_or_split == \"split\":\n",
    "                tokens = pipe.tokenizer(text, truncation=False, add_special_tokens=True)[\"input_ids\"]\n",
    "\n",
    "                if len(tokens) > 512:\n",
    "                    chunk_size = 512\n",
    "                    chunks = [text[start:start + chunk_size] for start in range(0, len(text), chunk_size)]\n",
    "\n",
    "                    # Get predictions for each chunk\n",
    "                    chunk_predictions = []\n",
    "                    for chunk in chunks:\n",
    "                        result = pipe(chunk) \n",
    "                        chunk_predictions.append(result[0]['label'])\n",
    "\n",
    "                    predicted = max(set(chunk_predictions), key=chunk_predictions.count)\n",
    "                else:\n",
    "                    result = pipe(text)\n",
    "                    predicted = result[0]['label']\n",
    "            else:\n",
    "                result = pipe(text, truncation=True)\n",
    "                predicted = result[0]['label']\n",
    "\n",
    "            old = row.sentiment  \n",
    "\n",
    "            if old in sentiment_matrix and predicted in sentiment_matrix:\n",
    "                sentiment_matrix[predicted][old] += 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    result_matrix = pd.DataFrame(sentiment_matrix).T  # Transpose for correct layout\n",
    "\n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "2EwBl0ouSvt9"
   },
   "outputs": [],
   "source": [
    "def analyze_sentiments_finbert_pipeline(merged_df, pipe, truncate_or_split=\"truncate\"):\n",
    "    \"\"\"\n",
    "    Perform sentiment analysis on financial news articles using FinBERT,\n",
    "    processing text sequences longer than 512 tokens as needed.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store results\n",
    "    result_data = []\n",
    "\n",
    "    for i, row in enumerate(merged_df.itertuples(), start=1):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing article {i}/{len(merged_df)}\")\n",
    "\n",
    "        url = row.article_url\n",
    "        text = get_news_text(url) \n",
    "\n",
    "        if text != \"Error\" and isinstance(text, str): \n",
    "            if truncate_or_split == \"split\":\n",
    "                tokens = pipe.tokenizer(text, truncation=False, add_special_tokens=True)[\"input_ids\"]\n",
    "\n",
    "                if len(tokens) > 512:\n",
    "                    chunk_size = 512\n",
    "                    chunks = [text[start:start + chunk_size] for start in range(0, len(text), chunk_size)]\n",
    "\n",
    "                    # Get predictions for each chunk\n",
    "                    chunk_predictions = []\n",
    "                    for chunk in chunks:\n",
    "                        result = pipe(chunk)\n",
    "                        chunk_predictions.append(result[0]['label'])\n",
    "\n",
    "                    # Use the most frequent label\n",
    "                    predicted_sentiment = max(set(chunk_predictions), key=chunk_predictions.count)\n",
    "                else:\n",
    "                    result = pipe(text) \n",
    "                    predicted_sentiment = result[0]['label']\n",
    "            else:\n",
    "                result = pipe(text, truncation=True)\n",
    "                predicted_sentiment = result[0]['label']\n",
    "\n",
    "            result_data.append({\n",
    "                \"ticker\": row.ticker,\n",
    "                \"sentiment\": predicted_sentiment,\n",
    "                \"news_id\": row.id,\n",
    "                \"source_ticker\": row.ticker, \n",
    "                \"time\": row.publish_time\n",
    "            })\n",
    "\n",
    "    result_df = pd.DataFrame(result_data, columns=['ticker', 'sentiment', 'news_id', 'source_ticker', 'time'])\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRebciUBg910"
   },
   "outputs": [],
   "source": [
    "def add_explanations_to_matrix(result_matrix):\n",
    "    row_explanations = [\n",
    "        \"Predicted as positive\",\n",
    "        \"Predicted as neutral\",\n",
    "        \"Predicted as negative\",\n",
    "    ]\n",
    "    result_matrix.insert(0, \"Explanation\", row_explanations)\n",
    "\n",
    "\n",
    "    explanation_row = {\n",
    "        \"Explanation\": \"Row description\",\n",
    "        \"positive\": \"Labeled positive\",\n",
    "        \"neutral\": \"Labeled neutral\",\n",
    "        \"negative\": \"Labeled negative\",\n",
    "    }\n",
    "\n",
    "    explanation_df = pd.DataFrame([explanation_row])\n",
    "    result_matrix = pd.concat([result_matrix, explanation_df], ignore_index=True)\n",
    "\n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xPdSgZjLj_hl"
   },
   "outputs": [],
   "source": [
    "df_news = pd.read_csv('AAPL_main.csv')\n",
    "df_rela = pd.read_csv('AAPL_relation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "jKzHWKYYg6DY"
   },
   "outputs": [],
   "source": [
    "merged_df = combine_dataframes_with_time_range(df_news, df_rela, \"2024-07-01\", \"2024-08-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDJqT0n-kXs1",
    "outputId": "410bc025-2431-46b3-f69b-d712d2c2dfd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    id        publish_time  \\\n",
      "397  98c6ca14cab03a3bd104600a398277c200673939a9ef65... 2024-07-31 18:12:00   \n",
      "398  c6ad5b53e41888dcaad92a4fa2af4f82b8f7d3649cd883... 2024-07-31 15:23:46   \n",
      "399  5c9942bce64846d690ff4a1593f767e2b7712c6ad1ff8f... 2024-07-31 12:15:00   \n",
      "400  c1f4e581e6ad7955af2a52c2f98fd20d63597fae248d7b... 2024-07-31 04:00:00   \n",
      "401  0e2c7c16e5f2b68814f368a981536eeb048c946e68af80... 2024-07-30 22:40:00   \n",
      "..                                                 ...                 ...   \n",
      "658  1fcac93fed0e133da96bfb1c8953aac2f52188cd442308... 2024-07-02 23:30:49   \n",
      "659  860ffff9a7f8e6ac55b2ddd19bd169ecd1a9f503e9f1dc... 2024-07-02 21:05:40   \n",
      "660  4d843941162f622729de3d2276012094d587ca8dfb916f... 2024-07-02 20:15:43   \n",
      "661  1d7b72c113d7c86046e8832efab111ddbc673a08a41547... 2024-07-02 20:14:53   \n",
      "662  61d80aa431470bc0a67ae461d70964cc7827fa8a37eefd... 2024-07-02 19:16:19   \n",
      "\n",
      "                                           article_url sentiment ticker  \n",
      "397  https://www.zacks.com/stock/news/2313423/amd-q...   neutral   AAPL  \n",
      "398  https://www.fool.com/investing/2024/07/31/the-...   neutral   AAPL  \n",
      "399  https://www.fool.com/investing/2024/07/31/is-t...  positive   AAPL  \n",
      "400  https://www.globenewswire.com/news-release/202...   neutral   AAPL  \n",
      "401  https://www.fool.com/investing/2024/07/30/nvid...   neutral   AAPL  \n",
      "..                                                 ...       ...    ...  \n",
      "658  https://au.investing.com/news/stock-market-new...  positive   AAPL  \n",
      "659  https://www.investing.com/news/stock-market-ne...  positive   AAPL  \n",
      "660  https://www.benzinga.com/news/large-cap/24/07/...  positive   AAPL  \n",
      "661  https://www.benzinga.com/news/retail-sales/24/...  positive   AAPL  \n",
      "662  https://www.benzinga.com/markets/equities/24/0...  positive   AAPL  \n",
      "\n",
      "[266 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "U_m_MuT4jQmd"
   },
   "outputs": [],
   "source": [
    "# result_matrix = compare_sentiments_finbert(merged_df, model, tokenizer, truncate_or_split=\"truncate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DuUef-5LS08H",
    "outputId": "8721ce63-6c21-4d58-f749-ea8332e4d2bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing article 10/266\n",
      "Processing article 20/266\n",
      "Processing article 30/266\n",
      "Processing article 40/266\n",
      "Processing article 50/266\n",
      "Processing article 60/266\n",
      "Processing article 70/266\n",
      "Processing article 80/266\n",
      "Processing article 90/266\n",
      "Processing article 100/266\n",
      "Processing article 110/266\n",
      "Processing article 120/266\n",
      "Processing article 130/266\n",
      "Processing article 140/266\n",
      "Processing article 150/266\n",
      "Processing article 160/266\n",
      "Processing article 170/266\n",
      "Processing article 180/266\n",
      "Processing article 190/266\n",
      "Processing article 200/266\n",
      "Processing article 210/266\n",
      "Processing article 220/266\n",
      "Processing article 230/266\n",
      "Processing article 240/266\n",
      "Processing article 250/266\n",
      "Processing article 260/266\n"
     ]
    }
   ],
   "source": [
    "result_df = analyze_sentiments_finbert_pipeline(merged_df, pipe, truncate_or_split=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "riG7AzB_TN1A",
    "outputId": "40225deb-88be-4828-dd5a-0053431f5962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker sentiment                                            news_id  \\\n",
      "0     AAPL   neutral  98c6ca14cab03a3bd104600a398277c200673939a9ef65...   \n",
      "1     AAPL   neutral  c6ad5b53e41888dcaad92a4fa2af4f82b8f7d3649cd883...   \n",
      "2     AAPL   neutral  5c9942bce64846d690ff4a1593f767e2b7712c6ad1ff8f...   \n",
      "3     AAPL   neutral  c1f4e581e6ad7955af2a52c2f98fd20d63597fae248d7b...   \n",
      "4     AAPL  negative  0e2c7c16e5f2b68814f368a981536eeb048c946e68af80...   \n",
      "..     ...       ...                                                ...   \n",
      "213   AAPL  negative  9157017d50628fbd2c24329b6f42207f23a58271cb2ef6...   \n",
      "214   AAPL  positive  3ce64356f2d9ee55998edb22e8b44897fb279d3a3b88d7...   \n",
      "215   AAPL  negative  6c0bc65d6a4675fecebd1e3838124acb9c992cf4182624...   \n",
      "216   AAPL  positive  1fcac93fed0e133da96bfb1c8953aac2f52188cd442308...   \n",
      "217   AAPL   neutral  860ffff9a7f8e6ac55b2ddd19bd169ecd1a9f503e9f1dc...   \n",
      "\n",
      "    source_ticker                time  \n",
      "0            AAPL 2024-07-31 18:12:00  \n",
      "1            AAPL 2024-07-31 15:23:46  \n",
      "2            AAPL 2024-07-31 12:15:00  \n",
      "3            AAPL 2024-07-31 04:00:00  \n",
      "4            AAPL 2024-07-30 22:40:00  \n",
      "..            ...                 ...  \n",
      "213          AAPL 2024-07-03 09:01:25  \n",
      "214          AAPL 2024-07-03 08:52:00  \n",
      "215          AAPL 2024-07-03 07:57:07  \n",
      "216          AAPL 2024-07-02 23:30:49  \n",
      "217          AAPL 2024-07-02 21:05:40  \n",
      "\n",
      "[218 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "2nKKAjs7XN6G"
   },
   "outputs": [],
   "source": [
    "result_df.to_csv('AAPL_rel_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "wl-cRHNgXgL5",
    "outputId": "b7f1e0d6-bbde-4a3b-ac6e-fb3f33053e86"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_82d7e758-53ac-484c-b4de-a18e13950091\", \"AAPL_rel_2.csv\", 22611)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download('AAPL_rel_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCgO2c4KkctR",
    "outputId": "82e9d9a4-6958-435a-ea2a-d0d951746ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Explanation          positive          neutral          negative\n",
      "0  Predicted as positive               115               60                15\n",
      "1   Predicted as neutral                38               26                16\n",
      "2  Predicted as negative                79               32                10\n",
      "3        Row description  Labeled positive  Labeled neutral  Labeled negative\n"
     ]
    }
   ],
   "source": [
    "# result_matrix = add_explanations_to_matrix(result_matrix)\n",
    "# print(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxF2KIhx8H7",
    "outputId": "67fccf8b-d531-4cf5-e150-d6aac2226f37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 0\n",
      "Processing: 10\n",
      "Processing: 20\n",
      "Processing: 30\n",
      "Processing: 40\n",
      "Processing: 50\n",
      "Processing: 60\n",
      "Processing: 70\n",
      "Processing: 80\n",
      "Processing: 90\n",
      "Processing: 100\n",
      "Processing: 110\n",
      "Processing: 120\n",
      "Processing: 130\n",
      "Processing: 140\n",
      "Processing: 150\n",
      "Processing: 160\n",
      "Processing: 170\n",
      "Processing: 180\n",
      "Processing: 190\n",
      "Processing: 200\n",
      "Processing: 210\n",
      "Processing: 220\n",
      "Processing: 230\n",
      "Processing: 240\n",
      "Processing: 250\n",
      "Processing: 260\n",
      "Processing: 270\n",
      "Processing: 280\n",
      "Processing: 290\n",
      "Processing: 300\n",
      "Processing: 310\n",
      "Processing: 320\n",
      "Processing: 330\n",
      "Processing: 340\n",
      "Processing: 350\n",
      "Processing: 360\n",
      "Processing: 370\n",
      "Processing: 380\n",
      "Processing: 390\n",
      "Processing: 400\n",
      "Processing: 410\n"
     ]
    }
   ],
   "source": [
    "result_matrix = compare_sentiments_finbert(merged_df, model, tokenizer, truncate_or_split=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tvw2La6AyLir",
    "outputId": "8d8dc60e-db65-4283-9894-46fedafeed23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Explanation          positive          neutral          negative\n",
      "0  Predicted as positive               125               63                20\n",
      "1   Predicted as neutral                24               18                16\n",
      "2  Predicted as negative                83               40                 4\n",
      "3        Row description  Labeled positive  Labeled neutral  Labeled negative\n"
     ]
    }
   ],
   "source": [
    "result_matrix = add_explanations_to_matrix(result_matrix)\n",
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lAElGrZDtP6",
    "outputId": "c31d6e30-60c9-41b0-9445-dfe07677bef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 0\n",
      "Processing: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 20\n",
      "Processing: 30\n",
      "Processing: 40\n",
      "Processing: 50\n",
      "Processing: 60\n",
      "Processing: 70\n",
      "Processing: 80\n",
      "Processing: 90\n",
      "Processing: 100\n",
      "Processing: 110\n",
      "Processing: 120\n",
      "Processing: 130\n",
      "Processing: 140\n",
      "Processing: 150\n",
      "Processing: 160\n",
      "Processing: 170\n",
      "Processing: 180\n",
      "Processing: 190\n",
      "Processing: 200\n",
      "Processing: 210\n",
      "Processing: 220\n",
      "Processing: 230\n",
      "Processing: 240\n",
      "Processing: 250\n",
      "Processing: 260\n",
      "Processing: 270\n",
      "Processing: 280\n",
      "Processing: 290\n",
      "Processing: 300\n",
      "Processing: 310\n",
      "Processing: 320\n",
      "Processing: 330\n",
      "Processing: 340\n",
      "Processing: 350\n",
      "Processing: 360\n",
      "Processing: 370\n",
      "Processing: 380\n",
      "Processing: 390\n",
      "Processing: 400\n",
      "Processing: 410\n"
     ]
    }
   ],
   "source": [
    "result_matrix = compare_sentiments_finbert_pipeline(merged_df, pipe, truncate_or_split=\"truncate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLv1T6iADziD",
    "outputId": "5afd5516-7eb0-4af4-c71a-6dd2c6c890cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Explanation          positive          neutral          negative\n",
      "0  Predicted as positive                75               38                10\n",
      "1   Predicted as neutral               103               76                14\n",
      "2  Predicted as negative                36               21                22\n",
      "3        Row description  Labeled positive  Labeled neutral  Labeled negative\n"
     ]
    }
   ],
   "source": [
    "result_matrix = add_explanations_to_matrix(result_matrix)\n",
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZMdber68DzqI",
    "outputId": "91ec0cfb-c9ac-478e-aa69-dfdd531b5d46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1457 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 10\n",
      "Processing: 20\n",
      "Processing: 30\n",
      "Processing: 40\n",
      "Processing: 50\n",
      "Processing: 60\n",
      "Processing: 70\n",
      "Processing: 80\n",
      "Processing: 90\n",
      "Processing: 100\n",
      "Processing: 110\n",
      "Processing: 120\n",
      "Processing: 130\n",
      "Processing: 140\n",
      "Processing: 150\n",
      "Processing: 160\n",
      "Processing: 170\n",
      "Processing: 180\n",
      "Processing: 190\n",
      "Processing: 200\n",
      "Processing: 210\n",
      "Processing: 220\n",
      "Processing: 230\n",
      "Processing: 240\n",
      "Processing: 250\n",
      "Processing: 260\n",
      "Processing: 270\n",
      "Processing: 280\n",
      "Processing: 290\n",
      "Processing: 300\n",
      "Processing: 310\n",
      "Processing: 320\n",
      "Processing: 330\n",
      "Processing: 340\n",
      "Processing: 350\n",
      "Processing: 360\n",
      "Processing: 370\n",
      "Processing: 380\n",
      "Processing: 390\n",
      "Processing: 400\n",
      "Processing: 410\n"
     ]
    }
   ],
   "source": [
    "result_matrix = compare_sentiments_finbert_pipeline(merged_df, pipe, truncate_or_split=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ULUfuvpDzyb",
    "outputId": "be360db0-c1d5-4f11-f1c1-63db1d50f270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Explanation          positive          neutral          negative\n",
      "0  Predicted as positive                90               49                 6\n",
      "1   Predicted as neutral               102               71                23\n",
      "2  Predicted as negative                22               15                17\n",
      "3        Row description  Labeled positive  Labeled neutral  Labeled negative\n"
     ]
    }
   ],
   "source": [
    "result_matrix = add_explanations_to_matrix(result_matrix)\n",
    "print(result_matrix)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00b2e6418e2444d98123638bb9052d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "01be476b3a6d40449c5632b4a8a57599": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee2c2b0bec3e4e5db8975f09e5e0742b",
      "placeholder": "​",
      "style": "IPY_MODEL_b0e70365d51547acbfd197aa7dcc8680",
      "value": " 112/112 [00:00&lt;00:00, 2.23kB/s]"
     }
    },
    "04d1884b23cb4f91b4be30f018652a6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08c1182c80bb4a9aada26f53d1abacf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e602e5b0c5de45ada254c2c31ac770ce",
      "placeholder": "​",
      "style": "IPY_MODEL_83ad61ebca374fd497bf7441df2a6d33",
      "value": "vocab.txt: 100%"
     }
    },
    "0f1bfe056199463fbf21d7ab8db71087": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f54cb4034e44b5a860cec94eb70e5f8",
      "placeholder": "​",
      "style": "IPY_MODEL_58bf3e1b3d894fbca84e0f5d47b9491d",
      "value": "config.json: 100%"
     }
    },
    "0f54cb4034e44b5a860cec94eb70e5f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1824ad8b682c43a49d7dde66c2b6cb00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ca725d3bf2d4d9793b26cd947bfba25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3282cdecfc8547c48d5ffa78ca859890": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5cc6008f474f49aeb1dce9e5c7707b3e",
      "placeholder": "​",
      "style": "IPY_MODEL_a59fa2b78147485ca7768260acc47f39",
      "value": " 438M/438M [00:02&lt;00:00, 194MB/s]"
     }
    },
    "3bc9c648f1c14749833b61c0edc3ae14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eea1ab83fca744f793fb025736ededd6",
      "placeholder": "​",
      "style": "IPY_MODEL_ff99ebd3e8bb468cb3bd879c5ad385e0",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "40350e7234a64f5e8d14b1a7c2785797": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4639c1a60a7f4145841fae22bef42625": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1b5e110bb9b41c8bfdd71c595bc0782",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7f81fa802654fe2825b823e9a7b139b",
      "value": 231508
     }
    },
    "4732b406cd3e4beb9ef1c7c439d2d3ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58bf3e1b3d894fbca84e0f5d47b9491d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58c06a6465fd4b71aa947262e335d299": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cc6008f474f49aeb1dce9e5c7707b3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5eb6618011b545c8af48afbedee0bf9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69504145b9e44eae9dd27ead9e69e1a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a4c7eb15a964128adcb76328df1afd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cbfdf8d7b3d4cc1af0b84cf81ead3e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cce38151a7b4ad8a8bb449291e45f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7f853399e45443aea4e5fa97e0704db7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0735f2f741b4f81b231302e4840772b",
      "placeholder": "​",
      "style": "IPY_MODEL_bc29ae56e5d04722a76141ac47ae04a3",
      "value": " 252/252 [00:00&lt;00:00, 4.72kB/s]"
     }
    },
    "83ad61ebca374fd497bf7441df2a6d33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "880ecf6d73f249ed90cb03fccc39083a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c9ba4d543c748b194c5b4fd49719cd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04d1884b23cb4f91b4be30f018652a6a",
      "max": 758,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7cce38151a7b4ad8a8bb449291e45f8d",
      "value": 758
     }
    },
    "971fbdbc971a4a3db05b6debe7ee9c78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97ddfd3151f84342b6682fba38a82c0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9958940f00c54cf39047a1be983e8bc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3bc9c648f1c14749833b61c0edc3ae14",
       "IPY_MODEL_d0b2a671eb27437885f7a9945c1ea48e",
       "IPY_MODEL_01be476b3a6d40449c5632b4a8a57599"
      ],
      "layout": "IPY_MODEL_97ddfd3151f84342b6682fba38a82c0d"
     }
    },
    "a0735f2f741b4f81b231302e4840772b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1c1c1b8c56b438f88377d24fde8998c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d1d8ec9697ed466cbe1f12fbffd870d0",
       "IPY_MODEL_a1c5c7983543428b960d6517133d6d5e",
       "IPY_MODEL_7f853399e45443aea4e5fa97e0704db7"
      ],
      "layout": "IPY_MODEL_f0b25f27c6fe42e488cfa60f0a0f138f"
     }
    },
    "a1c5c7983543428b960d6517133d6d5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_880ecf6d73f249ed90cb03fccc39083a",
      "max": 252,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40350e7234a64f5e8d14b1a7c2785797",
      "value": 252
     }
    },
    "a59fa2b78147485ca7768260acc47f39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b00b5e85c6ac4d2ab59fbe8d438bc7e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_971fbdbc971a4a3db05b6debe7ee9c78",
      "placeholder": "​",
      "style": "IPY_MODEL_4732b406cd3e4beb9ef1c7c439d2d3ab",
      "value": " 758/758 [00:00&lt;00:00, 10.4kB/s]"
     }
    },
    "b0e70365d51547acbfd197aa7dcc8680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b29737915a974f8f9dbe86b3183a6940": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b8ff565c064a48b68604def8294a6a36",
       "IPY_MODEL_e021405063db4f52ba5bdc07852974f9",
       "IPY_MODEL_3282cdecfc8547c48d5ffa78ca859890"
      ],
      "layout": "IPY_MODEL_7cbfdf8d7b3d4cc1af0b84cf81ead3e3"
     }
    },
    "b4aa04b12b644e35ab521ef38c32d2f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b8ff565c064a48b68604def8294a6a36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5eb6618011b545c8af48afbedee0bf9d",
      "placeholder": "​",
      "style": "IPY_MODEL_1ca725d3bf2d4d9793b26cd947bfba25",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "bb1a9f9dd921430b850b475c53068573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_08c1182c80bb4a9aada26f53d1abacf4",
       "IPY_MODEL_4639c1a60a7f4145841fae22bef42625",
       "IPY_MODEL_e2f6fc4ad47843648588bea13e56b2b3"
      ],
      "layout": "IPY_MODEL_1824ad8b682c43a49d7dde66c2b6cb00"
     }
    },
    "bc29ae56e5d04722a76141ac47ae04a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c478a73580f14935aa30d101b283fd9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c5cef2bc73124433873ad61b360798aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0b2a671eb27437885f7a9945c1ea48e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a4c7eb15a964128adcb76328df1afd1",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b4aa04b12b644e35ab521ef38c32d2f0",
      "value": 112
     }
    },
    "d1d8ec9697ed466cbe1f12fbffd870d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58c06a6465fd4b71aa947262e335d299",
      "placeholder": "​",
      "style": "IPY_MODEL_69504145b9e44eae9dd27ead9e69e1a2",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "d7f81fa802654fe2825b823e9a7b139b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e021405063db4f52ba5bdc07852974f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f768d284e3184c7c986395926ac8ee3b",
      "max": 437992753,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c478a73580f14935aa30d101b283fd9e",
      "value": 437992753
     }
    },
    "e1b5e110bb9b41c8bfdd71c595bc0782": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2f6fc4ad47843648588bea13e56b2b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5cef2bc73124433873ad61b360798aa",
      "placeholder": "​",
      "style": "IPY_MODEL_00b2e6418e2444d98123638bb9052d65",
      "value": " 232k/232k [00:00&lt;00:00, 532kB/s]"
     }
    },
    "e602e5b0c5de45ada254c2c31ac770ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee2c2b0bec3e4e5db8975f09e5e0742b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eea1ab83fca744f793fb025736ededd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0b25f27c6fe42e488cfa60f0a0f138f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f768d284e3184c7c986395926ac8ee3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbcc51559e7b42f496cc05592127a1d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0f1bfe056199463fbf21d7ab8db71087",
       "IPY_MODEL_8c9ba4d543c748b194c5b4fd49719cd2",
       "IPY_MODEL_b00b5e85c6ac4d2ab59fbe8d438bc7e9"
      ],
      "layout": "IPY_MODEL_ffdad097ef8c4a7d961670cede1d65f9"
     }
    },
    "ff99ebd3e8bb468cb3bd879c5ad385e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ffdad097ef8c4a7d961670cede1d65f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
