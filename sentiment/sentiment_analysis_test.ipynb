{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0dd359",
   "metadata": {},
   "source": [
    "Code for preliminary testing of webscraping and sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f649c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- ------------\n",
      "aiobotocore                   2.4.2\n",
      "aiofiles                      22.1.0\n",
      "aiohttp                       3.8.3\n",
      "aioitertools                  0.7.1\n",
      "aiosignal                     1.2.0\n",
      "aiosqlite                     0.18.0\n",
      "alabaster                     0.7.12\n",
      "anaconda-catalogs             0.2.0\n",
      "anaconda-client               1.12.0\n",
      "anaconda-navigator            2.4.2\n",
      "anaconda-project              0.11.1\n",
      "anyio                         3.5.0\n",
      "appdirs                       1.4.4\n",
      "applaunchservices             0.3.0\n",
      "appnope                       0.1.2\n",
      "appscript                     1.1.2\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "arrow                         1.2.3\n",
      "astroid                       2.14.2\n",
      "astropy                       5.1\n",
      "asttokens                     2.0.5\n",
      "async-timeout                 4.0.2\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         22.1.0\n",
      "Automat                       20.2.0\n",
      "autopep8                      1.6.0\n",
      "Babel                         2.11.0\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "backports.tempfile            1.0\n",
      "backports.weakref             1.0.post1\n",
      "bcrypt                        3.2.0\n",
      "beautifulsoup4                4.12.2\n",
      "binaryornot                   0.4.4\n",
      "bitarray                      2.9.2\n",
      "bitstring                     4.2.3\n",
      "black                         0.0\n",
      "bleach                        4.1.0\n",
      "bokeh                         3.2.1\n",
      "boltons                       23.0.0\n",
      "boto3                         1.24.28\n",
      "botocore                      1.27.59\n",
      "Bottleneck                    1.3.5\n",
      "brotlipy                      0.7.0\n",
      "certifi                       2023.7.22\n",
      "cffi                          1.15.1\n",
      "chardet                       4.0.0\n",
      "charset-normalizer            2.0.4\n",
      "click                         8.0.4\n",
      "cloudpickle                   2.2.1\n",
      "clyent                        1.2.2\n",
      "colorama                      0.4.6\n",
      "colorcet                      3.0.1\n",
      "comm                          0.1.2\n",
      "conda                         23.7.2\n",
      "conda-build                   3.26.0\n",
      "conda-content-trust           0+unknown\n",
      "conda_index                   0.2.3\n",
      "conda-libmamba-solver         23.5.0\n",
      "conda-pack                    0.6.0\n",
      "conda-package-handling        2.2.0\n",
      "conda_package_streaming       0.9.0\n",
      "conda-repo-cli                1.0.41\n",
      "conda-token                   0.4.0\n",
      "conda-verify                  3.4.2\n",
      "constantly                    15.1.0\n",
      "contourpy                     1.0.5\n",
      "cookiecutter                  1.7.3\n",
      "cryptography                  41.0.2\n",
      "cssselect                     1.1.0\n",
      "cycler                        0.11.0\n",
      "cytoolz                       0.12.0\n",
      "dask                          2023.6.0\n",
      "datashader                    0.15.1\n",
      "datashape                     0.5.4\n",
      "debugpy                       1.6.7\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "diff-match-patch              20200713\n",
      "dill                          0.3.6\n",
      "distributed                   2023.6.0\n",
      "dnspython                     2.4.2\n",
      "docstring-to-markdown         0.11\n",
      "docutils                      0.18.1\n",
      "ecdsa                         0.19.0\n",
      "entrypoints                   0.4\n",
      "esptool                       4.7.0\n",
      "et-xmlfile                    1.1.0\n",
      "executing                     0.8.3\n",
      "fastjsonschema                2.16.2\n",
      "feedfinder2                   0.0.4\n",
      "feedparser                    6.0.11\n",
      "filelock                      3.9.0\n",
      "flake8                        6.0.0\n",
      "Flask                         2.2.2\n",
      "fonttools                     4.25.0\n",
      "frozenlist                    1.3.3\n",
      "fsspec                        2024.2.0\n",
      "future                        0.18.3\n",
      "gensim                        4.3.0\n",
      "glob2                         0.7\n",
      "gmpy2                         2.1.2\n",
      "greenlet                      2.0.1\n",
      "h5py                          3.7.0\n",
      "HeapDict                      1.0.1\n",
      "holoviews                     1.17.0\n",
      "huggingface-hub               0.20.3\n",
      "hvplot                        0.8.4\n",
      "hyperlink                     21.0.0\n",
      "idna                          3.4\n",
      "imagecodecs                   2021.8.26\n",
      "imageio                       2.31.1\n",
      "imagesize                     1.4.1\n",
      "imbalanced-learn              0.10.1\n",
      "importlib-metadata            6.0.0\n",
      "incremental                   21.3.0\n",
      "inflection                    0.5.1\n",
      "iniconfig                     1.1.1\n",
      "intake                        0.6.8\n",
      "intelhex                      2.3.0\n",
      "interchange                   2021.0.4\n",
      "intervaltree                  3.1.0\n",
      "ipykernel                     6.19.2\n",
      "ipython                       8.12.0\n",
      "ipython-genutils              0.2.0\n",
      "ipython-sql                   0.5.0\n",
      "ipywidgets                    8.0.4\n",
      "isort                         5.9.3\n",
      "itemadapter                   0.3.0\n",
      "itemloaders                   1.0.4\n",
      "itsdangerous                  2.0.1\n",
      "jaraco.classes                3.2.1\n",
      "jedi                          0.18.1\n",
      "jellyfish                     0.9.0\n",
      "jieba3k                       0.35.1\n",
      "Jinja2                        3.1.2\n",
      "jinja2-time                   0.2.0\n",
      "jmespath                      0.10.0\n",
      "joblib                        1.2.0\n",
      "json5                         0.9.6\n",
      "jsonpatch                     1.32\n",
      "jsonpointer                   2.1\n",
      "jsonschema                    4.17.3\n",
      "jupyter                       1.0.0\n",
      "jupyter_client                7.4.9\n",
      "jupyter-console               6.6.3\n",
      "jupyter_core                  5.3.0\n",
      "jupyter-events                0.6.3\n",
      "jupyter-server                1.23.4\n",
      "jupyter_server_fileid         0.9.0\n",
      "jupyter_server_ydoc           0.8.0\n",
      "jupyter-ydoc                  0.2.4\n",
      "jupyterlab                    3.6.3\n",
      "jupyterlab-pygments           0.1.2\n",
      "jupyterlab_server             2.22.0\n",
      "jupyterlab-widgets            3.0.5\n",
      "keyring                       23.13.1\n",
      "kiwisolver                    1.4.4\n",
      "lazy_loader                   0.2\n",
      "lazy-object-proxy             1.6.0\n",
      "libarchive-c                  2.9\n",
      "libmambapy                    1.4.1\n",
      "linkify-it-py                 2.0.0\n",
      "llvmlite                      0.40.0\n",
      "lmdb                          1.4.1\n",
      "locket                        1.0.0\n",
      "lxml                          4.9.2\n",
      "lz4                           4.3.2\n",
      "Markdown                      3.4.1\n",
      "markdown-it-py                2.2.0\n",
      "MarkupSafe                    2.1.1\n",
      "matplotlib                    3.7.1\n",
      "matplotlib-inline             0.1.6\n",
      "mccabe                        0.7.0\n",
      "mdit-py-plugins               0.3.0\n",
      "mdurl                         0.1.0\n",
      "mistune                       0.8.4\n",
      "monotonic                     1.6\n",
      "more-itertools                8.12.0\n",
      "mpfshell                      0.9.3\n",
      "mpmath                        1.3.0\n",
      "msgpack                       1.0.3\n",
      "multidict                     6.0.2\n",
      "multipledispatch              0.6.0\n",
      "munkres                       1.1.4\n",
      "mypy-extensions               0.4.3\n",
      "navigator-updater             0.4.0\n",
      "nbclassic                     0.5.5\n",
      "nbclient                      0.5.13\n",
      "nbconvert                     6.5.4\n",
      "nbformat                      5.7.0\n",
      "nest-asyncio                  1.5.6\n",
      "networkx                      3.1\n",
      "newspaper3k                   0.2.8\n",
      "nltk                          3.9.1\n",
      "notebook                      6.5.4\n",
      "notebook_shim                 0.2.2\n",
      "numba                         0.57.0\n",
      "numexpr                       2.8.4\n",
      "numpy                         1.24.3\n",
      "numpydoc                      1.5.0\n",
      "openpyxl                      3.0.10\n",
      "packaging                     23.0\n",
      "pandas                        1.5.3\n",
      "pandocfilters                 1.5.0\n",
      "panel                         1.2.1\n",
      "pansi                         2020.7.3\n",
      "param                         1.13.0\n",
      "parsel                        1.6.0\n",
      "parso                         0.8.3\n",
      "partd                         1.2.0\n",
      "pathlib                       1.0.1\n",
      "pathspec                      0.10.3\n",
      "patsy                         0.5.3\n",
      "pep8                          1.7.1\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.4.0\n",
      "pip                           23.2.1\n",
      "pkginfo                       1.9.6\n",
      "platformdirs                  2.5.2\n",
      "plotly                        5.9.0\n",
      "pluggy                        1.0.0\n",
      "ply                           3.11\n",
      "pooch                         1.4.0\n",
      "poyo                          0.5.0\n",
      "prettytable                   3.9.0\n",
      "prometheus-client             0.14.1\n",
      "prompt-toolkit                3.0.36\n",
      "Protego                       0.1.16\n",
      "psutil                        5.9.0\n",
      "ptyprocess                    0.7.0\n",
      "pure-eval                     0.2.2\n",
      "py-cpuinfo                    8.0.0\n",
      "py2neo                        2021.2.4\n",
      "pyarrow                       11.0.0\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pycodestyle                   2.10.0\n",
      "pycosat                       0.6.4\n",
      "pycparser                     2.21\n",
      "pyct                          0.5.0\n",
      "pycurl                        7.45.2\n",
      "PyDispatcher                  2.0.5\n",
      "pydocstyle                    6.3.0\n",
      "pyerfa                        2.0.0\n",
      "pyflakes                      3.0.1\n",
      "Pygments                      2.15.1\n",
      "PyJWT                         2.4.0\n",
      "pylint                        2.16.2\n",
      "pylint-venv                   2.3.0\n",
      "pyls-spyder                   0.4.0\n",
      "pymongo                       4.6.1\n",
      "PyMySQL                       1.1.0\n",
      "pyobjc-core                   9.0\n",
      "pyobjc-framework-Cocoa        9.0\n",
      "pyobjc-framework-CoreServices 9.0\n",
      "pyobjc-framework-FSEvents     9.0\n",
      "pyodbc                        4.0.34\n",
      "pyOpenSSL                     23.2.0\n",
      "pyparsing                     3.0.9\n",
      "PyQt5-sip                     12.11.0\n",
      "pyrsistent                    0.18.0\n",
      "pyserial                      3.5\n",
      "PySocks                       1.7.1\n",
      "pytest                        7.4.0\n",
      "python-dateutil               2.8.2\n",
      "python-json-logger            2.0.7\n",
      "python-lsp-black              1.2.1\n",
      "python-lsp-jsonrpc            1.0.0\n",
      "python-lsp-server             1.7.2\n",
      "python-slugify                5.0.2\n",
      "python-snappy                 0.6.1\n",
      "pytoolconfig                  1.2.5\n",
      "pytz                          2022.7\n",
      "pyviz-comms                   2.3.0\n",
      "PyWavelets                    1.4.1\n",
      "PyYAML                        6.0\n",
      "pyzmq                         23.2.0\n",
      "QDarkStyle                    3.0.2\n",
      "qstylizer                     0.2.2\n",
      "QtAwesome                     1.2.2\n",
      "qtconsole                     5.4.2\n",
      "QtPy                          2.2.0\n",
      "queuelib                      1.5.0\n",
      "reedsolo                      1.7.0\n",
      "regex                         2022.7.9\n",
      "requests                      2.31.0\n",
      "requests-file                 1.5.1\n",
      "requests-toolbelt             1.0.0\n",
      "rfc3339-validator             0.1.4\n",
      "rfc3986-validator             0.1.1\n",
      "rope                          1.7.0\n",
      "Rtree                         1.0.1\n",
      "ruamel.yaml                   0.17.21\n",
      "ruamel-yaml-conda             0.17.21\n",
      "s3fs                          2023.3.0\n",
      "s3transfer                    0.6.0\n",
      "sacremoses                    0.0.43\n",
      "safetensors                   0.4.2\n",
      "scikit-image                  0.20.0\n",
      "scikit-learn                  1.3.0\n",
      "scipy                         1.10.1\n",
      "Scrapy                        2.8.0\n",
      "seaborn                       0.12.2\n",
      "Send2Trash                    1.8.0\n",
      "service-identity              18.1.0\n",
      "setuptools                    68.0.0\n",
      "sgmllib3k                     1.0.0\n",
      "sip                           6.6.2\n",
      "six                           1.16.0\n",
      "smart-open                    5.2.1\n",
      "sniffio                       1.2.0\n",
      "snowballstemmer               2.2.0\n",
      "sortedcontainers              2.4.0\n",
      "soupsieve                     2.4\n",
      "Sphinx                        5.0.2\n",
      "sphinxcontrib-applehelp       1.0.2\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        2.0.0\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "spyder                        5.4.3\n",
      "spyder-kernels                2.4.3\n",
      "SQLAlchemy                    2.0.20\n",
      "sqlparse                      0.4.4\n",
      "stack-data                    0.2.0\n",
      "statsmodels                   0.14.0\n",
      "sympy                         1.11.1\n",
      "tables                        3.8.0\n",
      "tabulate                      0.8.10\n",
      "TBB                           0.2\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.2.2\n",
      "terminado                     0.17.1\n",
      "text-unidecode                1.3\n",
      "textblob                      0.18.0.post0\n",
      "textdistance                  4.2.1\n",
      "threadpoolctl                 2.2.0\n",
      "three-merge                   0.1.1\n",
      "tifffile                      2021.7.2\n",
      "timm                          0.9.12\n",
      "tinycss2                      1.2.1\n",
      "tinysegmenter                 0.3\n",
      "tldextract                    3.2.0\n",
      "toml                          0.10.2\n",
      "tomlkit                       0.11.1\n",
      "toolz                         0.12.0\n",
      "torch                         2.2.0\n",
      "torchvision                   0.17.0\n",
      "tornado                       6.3.2\n",
      "tqdm                          4.65.0\n",
      "traitlets                     5.7.1\n",
      "transformers                  2.1.1\n",
      "Twisted                       22.10.0\n",
      "typing_extensions             4.9.0\n",
      "uc-micro-py                   1.0.1\n",
      "ujson                         5.4.0\n",
      "Unidecode                     1.2.0\n",
      "urllib3                       1.26.16\n",
      "w3lib                         1.21.0\n",
      "watchdog                      2.1.6\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "websocket-client              0.58.0\n",
      "Werkzeug                      2.2.3\n",
      "whatthepatch                  1.0.2\n",
      "wheel                         0.38.4\n",
      "widgetsnbextension            4.0.5\n",
      "wrapt                         1.14.1\n",
      "wurlitzer                     3.0.2\n",
      "xarray                        2023.6.0\n",
      "xlwings                       0.29.1\n",
      "xyzservices                   2022.9.0\n",
      "y-py                          0.5.9\n",
      "yapf                          0.31.0\n",
      "yarl                          1.8.1\n",
      "ypy-websocket                 0.8.2\n",
      "zict                          2.2.0\n",
      "zipp                          3.11.0\n",
      "zope.interface                5.4.0\n",
      "zstandard                     0.19.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cb734b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newspaper3k\n",
      "  Obtaining dependency information for newspaper3k from https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl.metadata\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from newspaper3k) (4.12.2)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from newspaper3k) (9.4.0)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from newspaper3k) (6.0)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from newspaper3k) (4.9.2)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /Users/joezhou/.local/lib/python3.11/site-packages (from newspaper3k) (3.9.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from newspaper3k) (2.31.0)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "  Obtaining dependency information for feedparser>=5.2.1 from https://files.pythonhosted.org/packages/7c/d4/8c31aad9cc18f451c49f7f9cfb5799dadffc88177f7917bc90a66459b1d7/feedparser-6.0.11-py3-none-any.whl.metadata\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from newspaper3k) (3.2.0)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from newspaper3k) (2.8.2)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.4)\n",
      "Requirement already satisfied: six in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from nltk>=3.2.1->newspaper3k) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from nltk>=3.2.1->newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from nltk>=3.2.1->newspaper3k) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from nltk>=3.2.1->newspaper3k) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from requests>=2.10.0->newspaper3k) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from requests>=2.10.0->newspaper3k) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from requests>=2.10.0->newspaper3k) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from requests>=2.10.0->newspaper3k) (2023.7.22)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Users/joezhou/anaconda3/lib/python3.11/site-packages (from tldextract>=2.0.1->newspaper3k) (3.9.0)\n",
      "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=ad62a953f93d21ac0ed45bc1259763a61589d147d0b3da1cf5f65d0b4760c6bb\n",
      "  Stored in directory: /Users/joezhou/Library/Caches/pip/wheels/fc/ab/f8/cce3a9ae6d828bd346be695f7ff54612cd22b7cbd7208d68f3\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3339 sha256=cdade331aeecefbdc39ca127aaa8aa2f653e2f8d11440bda10d9e59b36a8274e\n",
      "  Stored in directory: /Users/joezhou/Library/Caches/pip/wheels/80/d5/72/9cd9eccc819636436c6a6e59c22a0fb1ec167beef141f56491\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398382 sha256=10ca4d4ca116e520c8fe2d7e4a4d26fa4ae56ad9473263b6e4db1905f31d31ef\n",
      "  Stored in directory: /Users/joezhou/Library/Caches/pip/wheels/3a/a1/46/8e68055c1713f9c4598774c15ad0541f26d5425ee7423b6493\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=fa8a951cfa7944cc1ba49ba7ca1133a79fd46791b821d023d6fee2e809f5bea7\n",
      "  Stored in directory: /Users/joezhou/Library/Caches/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, feedfinder2, newspaper3k\n",
      "Successfully installed feedfinder2-0.0.4 feedparser-6.0.11 jieba3k-0.35.1 newspaper3k-0.2.8 sgmllib3k-1.0.0 tinysegmenter-0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29c84ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from newspaper import Article\n",
    "from textblob.sentiments import NaiveBayesAnalyzer, PatternAnalyzer\n",
    "import requests as req\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "try:\n",
    "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
    "except LookupError:\n",
    "    nltk.download('vader_lexicon')\n",
    "    \n",
    "try:\n",
    "    nltk.data.find('corpora/movie_reviews')\n",
    "except LookupError:\n",
    "    nltk.download('movie_reviews')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2e39fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing, we extract from existing data's news link articles\n",
    "def get_news_links(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    url_list = df[\"article_url\"].dropna().tolist()\n",
    "    return url_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61fac17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_text(url):\n",
    "    article = Article(url)\n",
    "    try:\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.text\n",
    "    except Exception as error:\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80cb6ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"Error\"\n",
    "    else:\n",
    "        blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
    "        return blob.sentiment\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "562e5f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='pos', p_pos=0.9997272414111645, p_neg=0.00027275858882850636)\n",
      "Error\n",
      "Sentiment(classification='pos', p_pos=1.0, p_neg=4.965559666318901e-19)\n"
     ]
    }
   ],
   "source": [
    "url_list = get_news_links('dataset/news_maux/AAPL_main_2022-01-04_2022-01-06.csv')\n",
    "for url in url_list:\n",
    "    text = get_news_text(url)\n",
    "    sentiment = get_sentiment(text)\n",
    "    print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5100673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing accuracy for TextBlob, using a directory of data\n",
    "df_news = pd.read_csv('dataset/news/AAPL_main.csv')\n",
    "df_rela = pd.read_csv('dataset/news/AAPL_relation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d122cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes_with_time_range(main_df, relation_df, start_time, end_time):\n",
    "    start_time = pd.to_datetime(start_time)\n",
    "    end_time = pd.to_datetime(end_time)\n",
    "    \n",
    "    main_df['publish_time'] = pd.to_datetime(main_df['publish_time'])\n",
    "    relation_df['time'] = pd.to_datetime(relation_df['time'])\n",
    "    filtered_rel = relation_df[relation_df['ticker'] == relation_df['source_ticker']]\n",
    "    \n",
    "    merged_df = main_df.merge(filtered_rel, left_on='id', right_on='news_id', how='inner')\n",
    "    \n",
    "    filtered_df = merged_df\n",
    "    \n",
    "    time_filtered_df = filtered_df[(filtered_df['publish_time'] >= start_time) & (filtered_df['publish_time'] <= end_time)]\n",
    "    \n",
    "    result_df = time_filtered_df[['id', 'publish_time', 'article_url', 'sentiment']]\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "98bc051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = combine_dataframes_with_time_range(df_news, df_rela, \"2024-07-01\", \"2024-09-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7b659da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    id        publish_time  \\\n",
      "245  f9b58febeb4565a6dd607e3216decb281b237a1e76b9e9... 2024-08-31 11:15:00   \n",
      "246  9cc8d83bae696e5f0565a1a0391596b06171e5ed3e8402... 2024-08-31 10:24:00   \n",
      "247  f83a6765bf7b69e13cdef5999c8e5c99a26598acdce856... 2024-08-31 10:10:00   \n",
      "248  42cf4288fdeddba7d0846f4bdcdb97946c96f0849c11d0... 2024-08-31 07:01:00   \n",
      "249  d3e51924ac19db5ffb2f24d1621a9a213f30f9ed3aef5c... 2024-08-30 14:14:29   \n",
      "..                                                 ...                 ...   \n",
      "658  1fcac93fed0e133da96bfb1c8953aac2f52188cd442308... 2024-07-02 23:30:49   \n",
      "659  860ffff9a7f8e6ac55b2ddd19bd169ecd1a9f503e9f1dc... 2024-07-02 21:05:40   \n",
      "660  4d843941162f622729de3d2276012094d587ca8dfb916f... 2024-07-02 20:15:43   \n",
      "661  1d7b72c113d7c86046e8832efab111ddbc673a08a41547... 2024-07-02 20:14:53   \n",
      "662  61d80aa431470bc0a67ae461d70964cc7827fa8a37eefd... 2024-07-02 19:16:19   \n",
      "\n",
      "                                           article_url sentiment  \n",
      "245  https://www.fool.com/investing/2024/08/31/4-re...  negative  \n",
      "246  https://www.fool.com/investing/2024/08/31/warr...  positive  \n",
      "247  https://www.fool.com/investing/2024/08/31/will...  positive  \n",
      "248  https://www.fool.com/investing/2024/08/31/5-re...  positive  \n",
      "249  https://www.benzinga.com/analyst-ratings/analy...   neutral  \n",
      "..                                                 ...       ...  \n",
      "658  https://au.investing.com/news/stock-market-new...  positive  \n",
      "659  https://www.investing.com/news/stock-market-ne...  positive  \n",
      "660  https://www.benzinga.com/news/large-cap/24/07/...  positive  \n",
      "661  https://www.benzinga.com/news/retail-sales/24/...  positive  \n",
      "662  https://www.benzinga.com/markets/equities/24/0...  positive  \n",
      "\n",
      "[418 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "94ddf8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sentiments_blob(merged_df):\n",
    "    total_result = 0\n",
    "    correct_result = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    for row in merged_df.itertuples():\n",
    "        if total_result % 10 == 0:\n",
    "            print(\"processed: \" + str(total_result))\n",
    "        if row.sentiment != \"neutral\":\n",
    "            url = row.article_url\n",
    "            text = get_news_text(url)\n",
    "            # print(text)\n",
    "            sentiment = get_sentiment(text)\n",
    "            if sentiment != \"Error\":\n",
    "    #             print(sentiment)\n",
    "    #             print(row.sentiment)\n",
    "                blob_result = sentiment.classification\n",
    "                old = row.sentiment\n",
    "                if blob_result == \"pos\" and old == \"positive\":\n",
    "                    correct_result += 1\n",
    "                elif blob_result == \"pos\" and old == \"negative\":\n",
    "                    false_positive += 1\n",
    "                elif blob_result == \"neg\" and old == \"positive\":\n",
    "                    false_negative += 1\n",
    "                elif blob_result == \"neg\" and old == \"negative\":\n",
    "                    correct_result += 1\n",
    "                total_result += 1\n",
    "                \n",
    "    return total_result, correct_result, false_positive, false_negative\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1225a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 0\n",
      "processed: 0\n",
      "processed: 10\n",
      "processed: 10\n",
      "processed: 20\n",
      "processed: 20\n",
      "processed: 20\n",
      "processed: 20\n",
      "processed: 20\n",
      "processed: 20\n",
      "processed: 20\n",
      "processed: 30\n",
      "processed: 30\n",
      "processed: 40\n",
      "processed: 40\n"
     ]
    }
   ],
   "source": [
    "total_result, correct_result, false_positive, false_negative = compare_sentiments_blob(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "06b88123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9512195121951219\n",
      "0.04878048780487805\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(correct_result / total_result)\n",
    "print(false_positive / total_result)\n",
    "print(false_negative / total_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5f1fdaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-neutrals: 65\n",
      "positives: 60\n",
      "negatives: 5\n"
     ]
    }
   ],
   "source": [
    "counts = merged_df[\"sentiment\"].value_counts()\n",
    "\n",
    "print(\"non-neutrals: \" + str(counts.get('positive') + counts.get('negative')))\n",
    "print(\"positives: \" + str(counts.get('positive')))\n",
    "print(\"negatives: \" + str(counts.get('negative')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd94c6aa",
   "metadata": {},
   "source": [
    "Conclusion: bad performance, everything is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "69f07d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing accuracy for Vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c78dd362",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_vader(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"Error\"\n",
    "    else:\n",
    "        scores = analyzer.polarity_scores(text)\n",
    "        return scores\n",
    "    \n",
    "# def compare_sentiments_vader(merged_df):\n",
    "#     total_result = 0\n",
    "#     correct_result = 0\n",
    "#     compound_correct_result = 0\n",
    "#     false_positive = 0\n",
    "#     false_negative = 0\n",
    "#     false_neutral = 0\n",
    "\n",
    "#     for row in merged_df.itertuples():\n",
    "#         if total_result % 10 == 0:\n",
    "#             print(\"processed: \" + str(total_result))\n",
    "            \n",
    "#         url = row.article_url\n",
    "#         text = get_news_text(url)\n",
    "#         # print(text)\n",
    "#         sentiment = get_sentiment_vader(text)\n",
    "#         if sentiment != \"Error\":\n",
    "#             old = row.sentiment\n",
    "            \n",
    "#             # check compound scores\n",
    "#             if sentiment[\"compound\"] > 0.1 and old == \"positive\":\n",
    "#                 compound_correct_result += 1\n",
    "#             elif sentiment[\"compound\"] < 0.1 and old == \"negative\":\n",
    "#                 compound_correct_result += 1\n",
    "#             elif old == \"neutral\":\n",
    "#                 compound_correct_result += 1\n",
    "                \n",
    "            \n",
    "#             del sentiment[\"compound\"]\n",
    "            \n",
    "#             blob_result = max(sentiment, key=sentiment.get)\n",
    "            \n",
    "#             # check individual scores\n",
    "#             if blob_result == \"pos\" and old == \"positive\":\n",
    "#                 correct_result += 1\n",
    "#             elif blob_result == \"neg\" and old == \"negative\":\n",
    "#                 correct_result += 1\n",
    "#             elif blob_result == \"neu\" and old == \"neutral\":\n",
    "#                 correct_result += 1\n",
    "                \n",
    "            \n",
    "#             total_result += 1\n",
    "                \n",
    "#     return total_result, correct_result, compound_correct_result\n",
    "\n",
    "def compare_sentiments_vader(merged_df):\n",
    "    sentiment_matrix = {\n",
    "        \"positive\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "        \"neutral\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "        \"negative\": {\"positive\": 0, \"neutral\": 0, \"negative\": 0},\n",
    "    }\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    for row in merged_df.itertuples():\n",
    "        if i % 10 == 0:\n",
    "            print(\"Processing: \" + str(i))\n",
    "        url = row.article_url\n",
    "        text = get_news_text(url)\n",
    "        \n",
    "        sentiment = get_sentiment_vader(text)\n",
    "        if sentiment != \"Error\":\n",
    "            old = row.sentiment\n",
    "            \n",
    "            if sentiment[\"compound\"] > 0.1:\n",
    "                predicted = \"positive\"\n",
    "            elif sentiment[\"compound\"] < -0.1:\n",
    "                predicted = \"negative\"\n",
    "            else:\n",
    "                predicted = \"neutral\"\n",
    "\n",
    "            # Increment the corresponding matrix cell\n",
    "            if old in sentiment_matrix and predicted in sentiment_matrix:\n",
    "                sentiment_matrix[predicted][old] += 1\n",
    "        i += 1\n",
    "\n",
    "    result_matrix = pd.DataFrame(sentiment_matrix).T  \n",
    "\n",
    "    # Add explanations for rows and columns\n",
    "    result_matrix[\"Explanation\"] = [\n",
    "        \"Predicted as positive\",\n",
    "        \"Predicted as neutral\",\n",
    "        \"Predicted as negative\",\n",
    "    ]\n",
    "    explanation_row = {\n",
    "        \"positive\": \"Labeled positive from API\",\n",
    "        \"neutral\": \"Labeled neutral from API\",\n",
    "        \"negative\": \"Labeled negative from API\",\n",
    "        \"Explanation\": \"Column description\",\n",
    "    }\n",
    "    result_matrix = result_matrix.append(explanation_row, ignore_index=True)\n",
    "\n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3925c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_explanations_to_matrix(result_matrix):\n",
    "    result_matrix[\"Explanation\"] = [\n",
    "        \"Predicted as positive\",\n",
    "        \"Predicted as neutral\",\n",
    "        \"Predicted as negative\",\n",
    "        \"Column description\",  \n",
    "    ]\n",
    "\n",
    "    explanation_row = {\n",
    "        \"positive\": \"API labeled pos\",\n",
    "        \"neutral\": \"API labeled neu\",\n",
    "        \"negative\": \"API labeled neg\",\n",
    "        \"Explanation\": \"Column description\",\n",
    "    }\n",
    "\n",
    "    if not (result_matrix.iloc[-1] == pd.Series(explanation_row)).all():\n",
    "        result_matrix = result_matrix[:-1].append(explanation_row, ignore_index=True)\n",
    "    \n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a348354e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 0\n",
      "Processing: 10\n",
      "Processing: 20\n",
      "Processing: 30\n",
      "Processing: 40\n",
      "Processing: 50\n",
      "Processing: 60\n",
      "Processing: 70\n",
      "Processing: 80\n",
      "Processing: 90\n",
      "Processing: 100\n",
      "Processing: 110\n",
      "Processing: 120\n",
      "Processing: 130\n",
      "Processing: 140\n",
      "Processing: 150\n",
      "Processing: 160\n",
      "Processing: 170\n",
      "Processing: 180\n",
      "Processing: 190\n",
      "Processing: 200\n",
      "Processing: 210\n",
      "Processing: 220\n",
      "Processing: 230\n",
      "Processing: 240\n",
      "Processing: 250\n",
      "Processing: 260\n",
      "Processing: 270\n",
      "Processing: 280\n",
      "Processing: 290\n",
      "Processing: 300\n",
      "Processing: 310\n",
      "Processing: 320\n",
      "Processing: 330\n",
      "Processing: 340\n",
      "Processing: 350\n",
      "Processing: 360\n",
      "Processing: 370\n",
      "Processing: 380\n",
      "Processing: 390\n",
      "Processing: 400\n",
      "Processing: 410\n",
      "                                positive  \\\n",
      "0                                    175   \n",
      "1                                      0   \n",
      "2                                      5   \n",
      "3  Texts labeled positive in the dataset   \n",
      "\n",
      "                                neutral  \\\n",
      "0                                    93   \n",
      "1                                     1   \n",
      "2                                     5   \n",
      "3  Texts labeled neutral in the dataset   \n",
      "\n",
      "                                negative                        Explanation  \n",
      "0                                     26  Texts VADER predicted as positive  \n",
      "1                                      1   Texts VADER predicted as neutral  \n",
      "2                                      5  Texts VADER predicted as negative  \n",
      "3  Texts labeled negative in the dataset                 Column description  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/kv5wlvmd4wdc2_bz7dkwlj180000gn/T/ipykernel_93970/4009608091.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_matrix = result_matrix.append(explanation_row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "result_matrix = compare_sentiments_vader(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "42d6d7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          positive          neutral         negative            Explanation\n",
      "0              175               93               26  Predicted as positive\n",
      "1                0                1                1   Predicted as neutral\n",
      "2                5                5                5  Predicted as negative\n",
      "3  API labeled pos  API labeled neu  API labeled neg     Column description\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/kv5wlvmd4wdc2_bz7dkwlj180000gn/T/ipykernel_93970/3309517290.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_matrix = result_matrix[:-1].append(explanation_row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "result_matrix = add_explanations_to_matrix(result_matrix)\n",
    "print(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f30bd2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutrals: 128\n",
      "positives: 241\n",
      "negatives: 47\n"
     ]
    }
   ],
   "source": [
    "counts = merged_df[\"sentiment\"].value_counts()\n",
    "\n",
    "print(\"neutrals: \" + str(counts.get('neutral')))\n",
    "print(\"positives: \" + str(counts.get('positive')))\n",
    "print(\"negatives: \" + str(counts.get('negative')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e29c6",
   "metadata": {},
   "source": [
    "Conclusion: vader is terrible as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f6dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
