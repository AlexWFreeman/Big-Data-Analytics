{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_transform(label):\n",
    "    def func(series):\n",
    "        return series.isin(label).sum() / series.count()\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(ticker):\n",
    "    stock_price = pd.read_csv(f\"../dataset/stocks/{ticker}.csv\")\n",
    "    stock_price['time'] = pd.to_datetime(stock_price['time'])\n",
    "    stock_price['trade_date'] = stock_price['time'].dt.date\n",
    "    stock_price['delta'] = stock_price['close'].diff()\n",
    "    stock_price['prv_close'] = stock_price['close'].shift(periods=1, fill_value=None)\n",
    "    \n",
    "    stock_news = pd.read_csv(f\"../dataset/polygon_title_sentiment/{ticker}_title_sentiments.csv\")\n",
    "    stock_news['time'] = pd.to_datetime(stock_news['time'])\n",
    "    stock_news['trade_date'] = (stock_news['time'] + pd.to_timedelta(0, unit='h')).dt.date\n",
    "    stock_news['neg_score'] = stock_news['sentiment_score']\n",
    "    stock_news.loc[stock_news['sentiment'] != 'negative', 'neg_score'] = np.nan\n",
    "\n",
    "    news_comb = pd.merge(stock_price, stock_news, how='left', on='trade_date')\n",
    "    relation_gp = news_comb.groupby('trade_date').agg({\n",
    "        'prv_close': 'first', 'delta': 'first', 'close': 'first', 'open': 'first', 'high': 'first', 'low': 'first',\n",
    "        'sentiment': [sentiment_transform(['positive']), sentiment_transform(['negative'])], 'neg_score': 'mean'\n",
    "    }).fillna(0.0).reset_index()\n",
    "    relation_gp.columns = ['trade_date', 'prv_close', 'delta', 'close', 'open', 'high', 'low', 'positive', 'negative', 'neg_score']\n",
    "    return relation_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pj/znl5r0ln0hv_g1yjdthtr3f40000gn/T/ipykernel_25479/2186838793.py:3: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return series.isin(label).sum() / series.count()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(438, 502)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_gp = prepare_data(ticker='AAPL')\n",
    "relation_gp_t = relation_gp[relation_gp['negative'] > 0]\n",
    "len(relation_gp_t), len(relation_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_relevance(cols):\n",
    "    X, y = relation_gp_t[cols], relation_gp_t['delta']\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    return mse, r2, model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.942649011075657, 0.024855733697714877, array([-3.54940075]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_relevance(['negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.932500457710225, 0.02628116995551455, array([-3.60486329, -0.00377396]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_relevance(['negative', 'prv_close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.047464292706563, 0.010133684413618838, array([-2.44867333, -0.00374563]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_relevance(['neg_score', 'prv_close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.894677519076728,\n",
       " 0.03159366979301448,\n",
       " array([-3.34581544, -1.86528913, -0.00446983]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_relevance(['negative', 'neg_score', 'prv_close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.8115574211546654,\n",
       " 0.04326847673973999,\n",
       " array([ 2.69990973, -2.6930782 , -0.00746153]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_relevance(['positive', 'negative', 'prv_close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.767150295087289,\n",
       " 0.049505772374084045,\n",
       " array([ 2.77537596, -2.38660293, -2.02328201, -0.00831941]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_relevance(['positive', 'negative', 'neg_score', 'prv_close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1452105c0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(relation_gp_t['negative'], relation_gp_t['delta'], color='blue', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(relation_gp):\n",
    "    seq_length = 10\n",
    "    std_scaler = StandardScaler()\n",
    "    feat_cols = ['negative', 'close']\n",
    "    df = pd.DataFrame()\n",
    "    df[feat_cols] = std_scaler.fit_transform(relation_gp[feat_cols])\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(seq_length, len(df)):\n",
    "        X.append(df.iloc[i-seq_length:i])\n",
    "        y.append(df.iloc[i, -1])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    split_index = int(len(X) * 0.95)\n",
    "    X, X_test = X[:split_index], X[split_index:]\n",
    "    y, y_test = y[:split_index], y[split_index:]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=67)\n",
    "\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1) \n",
    "    y_val = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1) \n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1) \n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, layers, dropout):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        out = self.fc(hn[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([396, 10, 2]),\n",
       " torch.Size([71, 10, 2]),\n",
       " torch.Size([25, 10, 2]),\n",
       " torch.Size([396, 1]),\n",
       " torch.Size([71, 1]),\n",
       " torch.Size([25, 1]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleLSTM(input_size=2, hidden_size=64, output_size=1, layers=2, dropout=0.5)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = preprocess(relation_gp)\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, min_steps=0, mem_ratio=1, threshold=0):\n",
    "        self.min_steps = min_steps\n",
    "        self.mem_ratio = mem_ratio\n",
    "        self.threshold = threshold\n",
    "        self.aveg_loss = 0\n",
    "        self.steps = 0\n",
    "        self.min_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, loss):\n",
    "        self.steps += 1;\n",
    "        self.aveg_loss = self.aveg_loss * self.mem_ratio + loss * (1-self.mem_ratio)\n",
    "        if self.steps >= self.min_steps:\n",
    "            self.min_loss = min(self.min_loss, self.aveg_loss)\n",
    "            if self.aveg_loss >= self.min_loss * (1+self.threshold):\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.8476, Val Loss: 0.8214\n",
      "Epoch 2, Train Loss: 0.8311, Val Loss: 0.8088\n",
      "Epoch 3, Train Loss: 0.8149, Val Loss: 0.7957\n",
      "Epoch 4, Train Loss: 0.8003, Val Loss: 0.7817\n",
      "Epoch 5, Train Loss: 0.7830, Val Loss: 0.7664\n",
      "Epoch 6, Train Loss: 0.7656, Val Loss: 0.7493\n",
      "Epoch 7, Train Loss: 0.7476, Val Loss: 0.7302\n",
      "Epoch 8, Train Loss: 0.7259, Val Loss: 0.7085\n",
      "Epoch 9, Train Loss: 0.7026, Val Loss: 0.6836\n",
      "Epoch 10, Train Loss: 0.6758, Val Loss: 0.6549\n",
      "Epoch 11, Train Loss: 0.6439, Val Loss: 0.6218\n",
      "Epoch 12, Train Loss: 0.6080, Val Loss: 0.5835\n",
      "Epoch 13, Train Loss: 0.5693, Val Loss: 0.5395\n",
      "Epoch 14, Train Loss: 0.5198, Val Loss: 0.4893\n",
      "Epoch 15, Train Loss: 0.4670, Val Loss: 0.4327\n",
      "Epoch 16, Train Loss: 0.4105, Val Loss: 0.3701\n",
      "Epoch 17, Train Loss: 0.3430, Val Loss: 0.3032\n",
      "Epoch 18, Train Loss: 0.2732, Val Loss: 0.2350\n",
      "Epoch 19, Train Loss: 0.2112, Val Loss: 0.1704\n",
      "Epoch 20, Train Loss: 0.1522, Val Loss: 0.1167\n",
      "Epoch 21, Train Loss: 0.1046, Val Loss: 0.0812\n",
      "Epoch 22, Train Loss: 0.0768, Val Loss: 0.0687\n",
      "Epoch 23, Train Loss: 0.0837, Val Loss: 0.0765\n",
      "Epoch 24, Train Loss: 0.1091, Val Loss: 0.0954\n",
      "Epoch 25, Train Loss: 0.1394, Val Loss: 0.1102\n",
      "Epoch 26, Train Loss: 0.1580, Val Loss: 0.1109\n",
      "Epoch 27, Train Loss: 0.1518, Val Loss: 0.0996\n",
      "Epoch 28, Train Loss: 0.1364, Val Loss: 0.0834\n",
      "Epoch 29, Train Loss: 0.1086, Val Loss: 0.0697\n",
      "Epoch 30, Train Loss: 0.0903, Val Loss: 0.0621\n",
      "Epoch 31, Train Loss: 0.0680, Val Loss: 0.0614\n",
      "Epoch 32, Train Loss: 0.0612, Val Loss: 0.0661\n",
      "Epoch 33, Train Loss: 0.0573, Val Loss: 0.0736\n",
      "Epoch 34, Train Loss: 0.0591, Val Loss: 0.0814\n",
      "Epoch 35, Train Loss: 0.0648, Val Loss: 0.0880\n",
      "Epoch 36, Train Loss: 0.0705, Val Loss: 0.0922\n",
      "Epoch 37, Train Loss: 0.0789, Val Loss: 0.0935\n",
      "Epoch 38, Train Loss: 0.0827, Val Loss: 0.0921\n",
      "Epoch 39, Train Loss: 0.0806, Val Loss: 0.0883\n",
      "Epoch 40, Train Loss: 0.0769, Val Loss: 0.0829\n",
      "Epoch 41, Train Loss: 0.0734, Val Loss: 0.0769\n",
      "Epoch 42, Train Loss: 0.0674, Val Loss: 0.0709\n",
      "Epoch 43, Train Loss: 0.0653, Val Loss: 0.0658\n",
      "Epoch 44, Train Loss: 0.0609, Val Loss: 0.0620\n",
      "Epoch 45, Train Loss: 0.0563, Val Loss: 0.0598\n",
      "Epoch 46, Train Loss: 0.0530, Val Loss: 0.0590\n",
      "Epoch 47, Train Loss: 0.0559, Val Loss: 0.0594\n",
      "Epoch 48, Train Loss: 0.0544, Val Loss: 0.0602\n",
      "Epoch 49, Train Loss: 0.0543, Val Loss: 0.0607\n",
      "Epoch 50, Train Loss: 0.0548, Val Loss: 0.0600\n",
      "Epoch 51, Train Loss: 0.0541, Val Loss: 0.0582\n",
      "Epoch 52, Train Loss: 0.0510, Val Loss: 0.0554\n",
      "Epoch 53, Train Loss: 0.0529, Val Loss: 0.0520\n",
      "Epoch 54, Train Loss: 0.0503, Val Loss: 0.0488\n",
      "Epoch 55, Train Loss: 0.0449, Val Loss: 0.0464\n",
      "Epoch 56, Train Loss: 0.0462, Val Loss: 0.0449\n",
      "Epoch 57, Train Loss: 0.0442, Val Loss: 0.0443\n",
      "Epoch 58, Train Loss: 0.0476, Val Loss: 0.0445\n",
      "Epoch 59, Train Loss: 0.0453, Val Loss: 0.0449\n",
      "Epoch 60, Train Loss: 0.0473, Val Loss: 0.0454\n",
      "Epoch 61, Train Loss: 0.0460, Val Loss: 0.0457\n",
      "Epoch 62, Train Loss: 0.0452, Val Loss: 0.0460\n",
      "Epoch 63, Train Loss: 0.0452, Val Loss: 0.0461\n",
      "Epoch 64, Train Loss: 0.0438, Val Loss: 0.0461\n",
      "Epoch 65, Train Loss: 0.0439, Val Loss: 0.0457\n",
      "Epoch 66, Train Loss: 0.0426, Val Loss: 0.0451\n",
      "Epoch 67, Train Loss: 0.0415, Val Loss: 0.0444\n",
      "Epoch 68, Train Loss: 0.0393, Val Loss: 0.0438\n",
      "Epoch 69, Train Loss: 0.0407, Val Loss: 0.0432\n",
      "Epoch 70, Train Loss: 0.0395, Val Loss: 0.0426\n",
      "Epoch 71, Train Loss: 0.0417, Val Loss: 0.0422\n",
      "Epoch 72, Train Loss: 0.0400, Val Loss: 0.0419\n",
      "Epoch 73, Train Loss: 0.0389, Val Loss: 0.0417\n",
      "Epoch 74, Train Loss: 0.0418, Val Loss: 0.0418\n",
      "Epoch 75, Train Loss: 0.0399, Val Loss: 0.0419\n",
      "Epoch 76, Train Loss: 0.0379, Val Loss: 0.0422\n",
      "Epoch 77, Train Loss: 0.0375, Val Loss: 0.0425\n",
      "Epoch 78, Train Loss: 0.0416, Val Loss: 0.0429\n",
      "Epoch 79, Train Loss: 0.0380, Val Loss: 0.0432\n",
      "Epoch 80, Train Loss: 0.0381, Val Loss: 0.0434\n",
      "Epoch 81, Train Loss: 0.0383, Val Loss: 0.0432\n",
      "Epoch 82, Train Loss: 0.0354, Val Loss: 0.0427\n",
      "Epoch 83, Train Loss: 0.0354, Val Loss: 0.0417\n",
      "Epoch 84, Train Loss: 0.0352, Val Loss: 0.0406\n",
      "Epoch 85, Train Loss: 0.0357, Val Loss: 0.0396\n",
      "Epoch 86, Train Loss: 0.0351, Val Loss: 0.0389\n",
      "Epoch 87, Train Loss: 0.0346, Val Loss: 0.0384\n",
      "Epoch 88, Train Loss: 0.0360, Val Loss: 0.0382\n",
      "Epoch 89, Train Loss: 0.0352, Val Loss: 0.0382\n",
      "Epoch 90, Train Loss: 0.0363, Val Loss: 0.0382\n",
      "Epoch 91, Train Loss: 0.0359, Val Loss: 0.0383\n",
      "Epoch 92, Train Loss: 0.0353, Val Loss: 0.0383\n",
      "Epoch 93, Train Loss: 0.0343, Val Loss: 0.0383\n",
      "Epoch 94, Train Loss: 0.0357, Val Loss: 0.0382\n",
      "Epoch 95, Train Loss: 0.0380, Val Loss: 0.0381\n",
      "Epoch 96, Train Loss: 0.0362, Val Loss: 0.0378\n",
      "Epoch 97, Train Loss: 0.0376, Val Loss: 0.0375\n",
      "Epoch 98, Train Loss: 0.0324, Val Loss: 0.0372\n",
      "Epoch 99, Train Loss: 0.0333, Val Loss: 0.0370\n",
      "Epoch 100, Train Loss: 0.0338, Val Loss: 0.0369\n",
      "Epoch 101, Train Loss: 0.0305, Val Loss: 0.0369\n",
      "Epoch 102, Train Loss: 0.0352, Val Loss: 0.0370\n",
      "Epoch 103, Train Loss: 0.0341, Val Loss: 0.0372\n",
      "Epoch 104, Train Loss: 0.0358, Val Loss: 0.0375\n",
      "Epoch 105, Train Loss: 0.0339, Val Loss: 0.0375\n",
      "Epoch 106, Train Loss: 0.0343, Val Loss: 0.0375\n",
      "Epoch 107, Train Loss: 0.0331, Val Loss: 0.0374\n",
      "Epoch 108, Train Loss: 0.0335, Val Loss: 0.0374\n",
      "Epoch 109, Train Loss: 0.0356, Val Loss: 0.0372\n",
      "Epoch 110, Train Loss: 0.0300, Val Loss: 0.0370\n",
      "Epoch 111, Train Loss: 0.0358, Val Loss: 0.0368\n",
      "Epoch 112, Train Loss: 0.0337, Val Loss: 0.0367\n",
      "Epoch 113, Train Loss: 0.0341, Val Loss: 0.0366\n",
      "Epoch 114, Train Loss: 0.0341, Val Loss: 0.0363\n",
      "Epoch 115, Train Loss: 0.0319, Val Loss: 0.0359\n",
      "Epoch 116, Train Loss: 0.0317, Val Loss: 0.0355\n",
      "Epoch 117, Train Loss: 0.0348, Val Loss: 0.0351\n",
      "Epoch 118, Train Loss: 0.0328, Val Loss: 0.0348\n",
      "Epoch 119, Train Loss: 0.0333, Val Loss: 0.0348\n",
      "Epoch 120, Train Loss: 0.0345, Val Loss: 0.0348\n",
      "Epoch 121, Train Loss: 0.0336, Val Loss: 0.0349\n",
      "Epoch 122, Train Loss: 0.0345, Val Loss: 0.0350\n",
      "Epoch 123, Train Loss: 0.0323, Val Loss: 0.0351\n",
      "Epoch 124, Train Loss: 0.0326, Val Loss: 0.0352\n",
      "Epoch 125, Train Loss: 0.0323, Val Loss: 0.0352\n",
      "Epoch 126, Train Loss: 0.0318, Val Loss: 0.0350\n",
      "Epoch 127, Train Loss: 0.0325, Val Loss: 0.0349\n",
      "Epoch 128, Train Loss: 0.0322, Val Loss: 0.0347\n",
      "Epoch 129, Train Loss: 0.0317, Val Loss: 0.0345\n",
      "Epoch 130, Train Loss: 0.0314, Val Loss: 0.0343\n",
      "Epoch 131, Train Loss: 0.0298, Val Loss: 0.0341\n",
      "Epoch 132, Train Loss: 0.0332, Val Loss: 0.0340\n",
      "Epoch 133, Train Loss: 0.0308, Val Loss: 0.0339\n",
      "Epoch 134, Train Loss: 0.0295, Val Loss: 0.0340\n",
      "Epoch 135, Train Loss: 0.0295, Val Loss: 0.0342\n",
      "Epoch 136, Train Loss: 0.0311, Val Loss: 0.0344\n",
      "Epoch 137, Train Loss: 0.0314, Val Loss: 0.0347\n",
      "Epoch 138, Train Loss: 0.0307, Val Loss: 0.0349\n",
      "Epoch 139, Train Loss: 0.0311, Val Loss: 0.0350\n",
      "Epoch 140, Train Loss: 0.0325, Val Loss: 0.0348\n",
      "Epoch 141, Train Loss: 0.0303, Val Loss: 0.0345\n",
      "Epoch 142, Train Loss: 0.0294, Val Loss: 0.0339\n",
      "Epoch 143, Train Loss: 0.0306, Val Loss: 0.0333\n",
      "Epoch 144, Train Loss: 0.0294, Val Loss: 0.0328\n",
      "Epoch 145, Train Loss: 0.0311, Val Loss: 0.0326\n",
      "Epoch 146, Train Loss: 0.0293, Val Loss: 0.0324\n",
      "Epoch 147, Train Loss: 0.0315, Val Loss: 0.0325\n",
      "Epoch 148, Train Loss: 0.0319, Val Loss: 0.0327\n",
      "Epoch 149, Train Loss: 0.0317, Val Loss: 0.0331\n",
      "Epoch 150, Train Loss: 0.0305, Val Loss: 0.0336\n",
      "Epoch 151, Train Loss: 0.0306, Val Loss: 0.0341\n",
      "Epoch 152, Train Loss: 0.0287, Val Loss: 0.0345\n",
      "Epoch 153, Train Loss: 0.0288, Val Loss: 0.0344\n",
      "Epoch 154, Train Loss: 0.0308, Val Loss: 0.0337\n",
      "Epoch 155, Train Loss: 0.0299, Val Loss: 0.0328\n",
      "Epoch 156, Train Loss: 0.0295, Val Loss: 0.0320\n",
      "Epoch 157, Train Loss: 0.0311, Val Loss: 0.0314\n",
      "Epoch 158, Train Loss: 0.0292, Val Loss: 0.0311\n",
      "Epoch 159, Train Loss: 0.0308, Val Loss: 0.0311\n",
      "Epoch 160, Train Loss: 0.0298, Val Loss: 0.0313\n",
      "Epoch 161, Train Loss: 0.0314, Val Loss: 0.0316\n",
      "Epoch 162, Train Loss: 0.0297, Val Loss: 0.0319\n",
      "Epoch 163, Train Loss: 0.0297, Val Loss: 0.0322\n",
      "Epoch 164, Train Loss: 0.0318, Val Loss: 0.0325\n",
      "Epoch 165, Train Loss: 0.0299, Val Loss: 0.0326\n",
      "Epoch 166, Train Loss: 0.0287, Val Loss: 0.0327\n",
      "Epoch 167, Train Loss: 0.0286, Val Loss: 0.0326\n",
      "Epoch 168, Train Loss: 0.0290, Val Loss: 0.0323\n",
      "Epoch 169, Train Loss: 0.0300, Val Loss: 0.0320\n",
      "Epoch 170, Train Loss: 0.0279, Val Loss: 0.0316\n",
      "Epoch 171, Train Loss: 0.0281, Val Loss: 0.0313\n",
      "Epoch 172, Train Loss: 0.0299, Val Loss: 0.0312\n",
      "Epoch 173, Train Loss: 0.0271, Val Loss: 0.0312\n",
      "Epoch 174, Train Loss: 0.0290, Val Loss: 0.0311\n",
      "Epoch 175, Train Loss: 0.0263, Val Loss: 0.0311\n",
      "Epoch 176, Train Loss: 0.0281, Val Loss: 0.0312\n",
      "Epoch 177, Train Loss: 0.0313, Val Loss: 0.0316\n",
      "Epoch 178, Train Loss: 0.0272, Val Loss: 0.0319\n",
      "Epoch 179, Train Loss: 0.0283, Val Loss: 0.0318\n",
      "Epoch 180, Train Loss: 0.0288, Val Loss: 0.0317\n",
      "Epoch 181, Train Loss: 0.0266, Val Loss: 0.0314\n",
      "Epoch 182, Train Loss: 0.0269, Val Loss: 0.0312\n",
      "Epoch 183, Train Loss: 0.0311, Val Loss: 0.0309\n",
      "Epoch 184, Train Loss: 0.0295, Val Loss: 0.0308\n",
      "Epoch 185, Train Loss: 0.0291, Val Loss: 0.0307\n",
      "Epoch 186, Train Loss: 0.0282, Val Loss: 0.0305\n",
      "Epoch 187, Train Loss: 0.0295, Val Loss: 0.0306\n",
      "Epoch 188, Train Loss: 0.0295, Val Loss: 0.0305\n",
      "Epoch 189, Train Loss: 0.0280, Val Loss: 0.0301\n",
      "Epoch 190, Train Loss: 0.0286, Val Loss: 0.0297\n",
      "Epoch 191, Train Loss: 0.0279, Val Loss: 0.0297\n",
      "Epoch 192, Train Loss: 0.0272, Val Loss: 0.0300\n",
      "Epoch 193, Train Loss: 0.0280, Val Loss: 0.0305\n",
      "Epoch 194, Train Loss: 0.0288, Val Loss: 0.0310\n",
      "Epoch 195, Train Loss: 0.0287, Val Loss: 0.0315\n",
      "Epoch 196, Train Loss: 0.0283, Val Loss: 0.0317\n",
      "Epoch 197, Train Loss: 0.0276, Val Loss: 0.0313\n",
      "Epoch 198, Train Loss: 0.0257, Val Loss: 0.0307\n",
      "Epoch 199, Train Loss: 0.0251, Val Loss: 0.0300\n",
      "Epoch 200, Train Loss: 0.0265, Val Loss: 0.0295\n",
      "Epoch 201, Train Loss: 0.0279, Val Loss: 0.0293\n",
      "Epoch 202, Train Loss: 0.0264, Val Loss: 0.0293\n",
      "Epoch 203, Train Loss: 0.0264, Val Loss: 0.0295\n",
      "Epoch 204, Train Loss: 0.0268, Val Loss: 0.0298\n",
      "Epoch 205, Train Loss: 0.0275, Val Loss: 0.0302\n",
      "Epoch 206, Train Loss: 0.0272, Val Loss: 0.0301\n",
      "Epoch 207, Train Loss: 0.0267, Val Loss: 0.0300\n",
      "Epoch 208, Train Loss: 0.0279, Val Loss: 0.0297\n",
      "Epoch 209, Train Loss: 0.0250, Val Loss: 0.0292\n",
      "Epoch 210, Train Loss: 0.0272, Val Loss: 0.0286\n",
      "Epoch 211, Train Loss: 0.0265, Val Loss: 0.0283\n",
      "Epoch 212, Train Loss: 0.0247, Val Loss: 0.0282\n",
      "Epoch 213, Train Loss: 0.0278, Val Loss: 0.0284\n",
      "Epoch 214, Train Loss: 0.0276, Val Loss: 0.0287\n",
      "Epoch 215, Train Loss: 0.0259, Val Loss: 0.0292\n",
      "Epoch 216, Train Loss: 0.0251, Val Loss: 0.0295\n",
      "Epoch 217, Train Loss: 0.0272, Val Loss: 0.0296\n",
      "Epoch 218, Train Loss: 0.0266, Val Loss: 0.0294\n",
      "Epoch 219, Train Loss: 0.0268, Val Loss: 0.0291\n",
      "Epoch 220, Train Loss: 0.0268, Val Loss: 0.0284\n",
      "Epoch 221, Train Loss: 0.0257, Val Loss: 0.0280\n",
      "Epoch 222, Train Loss: 0.0254, Val Loss: 0.0278\n",
      "Epoch 223, Train Loss: 0.0266, Val Loss: 0.0278\n",
      "Epoch 224, Train Loss: 0.0262, Val Loss: 0.0278\n",
      "Epoch 225, Train Loss: 0.0270, Val Loss: 0.0280\n",
      "Epoch 226, Train Loss: 0.0268, Val Loss: 0.0282\n",
      "Epoch 227, Train Loss: 0.0276, Val Loss: 0.0283\n",
      "Epoch 228, Train Loss: 0.0248, Val Loss: 0.0283\n",
      "Epoch 229, Train Loss: 0.0257, Val Loss: 0.0280\n",
      "Epoch 230, Train Loss: 0.0263, Val Loss: 0.0276\n",
      "Epoch 231, Train Loss: 0.0267, Val Loss: 0.0274\n",
      "Epoch 232, Train Loss: 0.0266, Val Loss: 0.0272\n",
      "Epoch 233, Train Loss: 0.0265, Val Loss: 0.0274\n",
      "Epoch 234, Train Loss: 0.0260, Val Loss: 0.0279\n",
      "Epoch 235, Train Loss: 0.0262, Val Loss: 0.0284\n",
      "Epoch 236, Train Loss: 0.0264, Val Loss: 0.0288\n",
      "Epoch 237, Train Loss: 0.0250, Val Loss: 0.0288\n",
      "Epoch 238, Train Loss: 0.0249, Val Loss: 0.0286\n",
      "Epoch 239, Train Loss: 0.0241, Val Loss: 0.0281\n",
      "Epoch 240, Train Loss: 0.0261, Val Loss: 0.0278\n",
      "Epoch 241, Train Loss: 0.0276, Val Loss: 0.0276\n",
      "Epoch 242, Train Loss: 0.0256, Val Loss: 0.0274\n",
      "Epoch 243, Train Loss: 0.0265, Val Loss: 0.0272\n",
      "Epoch 244, Train Loss: 0.0238, Val Loss: 0.0273\n",
      "Epoch 245, Train Loss: 0.0257, Val Loss: 0.0272\n",
      "Epoch 246, Train Loss: 0.0245, Val Loss: 0.0271\n",
      "Epoch 247, Train Loss: 0.0250, Val Loss: 0.0269\n",
      "Epoch 248, Train Loss: 0.0260, Val Loss: 0.0268\n",
      "Epoch 249, Train Loss: 0.0247, Val Loss: 0.0267\n",
      "Epoch 250, Train Loss: 0.0250, Val Loss: 0.0267\n",
      "Epoch 251, Train Loss: 0.0243, Val Loss: 0.0267\n",
      "Epoch 252, Train Loss: 0.0235, Val Loss: 0.0267\n",
      "Epoch 253, Train Loss: 0.0260, Val Loss: 0.0268\n",
      "Epoch 254, Train Loss: 0.0260, Val Loss: 0.0270\n",
      "Epoch 255, Train Loss: 0.0266, Val Loss: 0.0271\n",
      "Epoch 256, Train Loss: 0.0252, Val Loss: 0.0270\n",
      "Epoch 257, Train Loss: 0.0244, Val Loss: 0.0268\n",
      "Epoch 258, Train Loss: 0.0233, Val Loss: 0.0267\n",
      "Epoch 259, Train Loss: 0.0264, Val Loss: 0.0265\n",
      "Epoch 260, Train Loss: 0.0239, Val Loss: 0.0262\n",
      "Epoch 261, Train Loss: 0.0235, Val Loss: 0.0260\n",
      "Epoch 262, Train Loss: 0.0255, Val Loss: 0.0261\n",
      "Epoch 263, Train Loss: 0.0240, Val Loss: 0.0262\n",
      "Epoch 264, Train Loss: 0.0234, Val Loss: 0.0264\n",
      "Epoch 265, Train Loss: 0.0250, Val Loss: 0.0266\n",
      "Epoch 266, Train Loss: 0.0264, Val Loss: 0.0267\n",
      "Epoch 267, Train Loss: 0.0249, Val Loss: 0.0266\n",
      "Epoch 268, Train Loss: 0.0234, Val Loss: 0.0264\n",
      "Epoch 269, Train Loss: 0.0229, Val Loss: 0.0259\n",
      "Epoch 270, Train Loss: 0.0251, Val Loss: 0.0256\n",
      "Epoch 271, Train Loss: 0.0247, Val Loss: 0.0255\n",
      "Epoch 272, Train Loss: 0.0256, Val Loss: 0.0254\n",
      "Epoch 273, Train Loss: 0.0250, Val Loss: 0.0254\n",
      "Epoch 274, Train Loss: 0.0248, Val Loss: 0.0256\n",
      "Epoch 275, Train Loss: 0.0234, Val Loss: 0.0258\n",
      "Epoch 276, Train Loss: 0.0233, Val Loss: 0.0259\n",
      "Epoch 277, Train Loss: 0.0238, Val Loss: 0.0260\n",
      "Epoch 278, Train Loss: 0.0212, Val Loss: 0.0263\n",
      "Epoch 279, Train Loss: 0.0226, Val Loss: 0.0264\n",
      "Epoch 280, Train Loss: 0.0233, Val Loss: 0.0260\n",
      "Epoch 281, Train Loss: 0.0248, Val Loss: 0.0255\n",
      "Epoch 282, Train Loss: 0.0234, Val Loss: 0.0248\n",
      "Epoch 283, Train Loss: 0.0253, Val Loss: 0.0242\n",
      "Epoch 284, Train Loss: 0.0238, Val Loss: 0.0241\n",
      "Epoch 285, Train Loss: 0.0245, Val Loss: 0.0243\n",
      "Epoch 286, Train Loss: 0.0256, Val Loss: 0.0246\n",
      "Epoch 287, Train Loss: 0.0242, Val Loss: 0.0250\n",
      "Epoch 288, Train Loss: 0.0235, Val Loss: 0.0254\n",
      "Epoch 289, Train Loss: 0.0228, Val Loss: 0.0255\n",
      "Epoch 290, Train Loss: 0.0239, Val Loss: 0.0253\n",
      "Epoch 291, Train Loss: 0.0245, Val Loss: 0.0250\n",
      "Epoch 292, Train Loss: 0.0250, Val Loss: 0.0247\n",
      "Epoch 293, Train Loss: 0.0237, Val Loss: 0.0246\n",
      "Epoch 294, Train Loss: 0.0243, Val Loss: 0.0246\n",
      "Epoch 295, Train Loss: 0.0235, Val Loss: 0.0245\n",
      "Epoch 296, Train Loss: 0.0221, Val Loss: 0.0247\n",
      "Epoch 297, Train Loss: 0.0239, Val Loss: 0.0249\n",
      "Epoch 298, Train Loss: 0.0216, Val Loss: 0.0251\n",
      "Epoch 299, Train Loss: 0.0226, Val Loss: 0.0251\n",
      "Epoch 300, Train Loss: 0.0228, Val Loss: 0.0249\n",
      "Epoch 301, Train Loss: 0.0226, Val Loss: 0.0247\n",
      "Epoch 302, Train Loss: 0.0226, Val Loss: 0.0243\n",
      "Epoch 303, Train Loss: 0.0230, Val Loss: 0.0240\n",
      "Epoch 304, Train Loss: 0.0227, Val Loss: 0.0238\n",
      "Epoch 305, Train Loss: 0.0227, Val Loss: 0.0237\n",
      "Epoch 306, Train Loss: 0.0251, Val Loss: 0.0237\n",
      "Epoch 307, Train Loss: 0.0231, Val Loss: 0.0238\n",
      "Epoch 308, Train Loss: 0.0220, Val Loss: 0.0237\n",
      "Epoch 309, Train Loss: 0.0222, Val Loss: 0.0238\n",
      "Epoch 310, Train Loss: 0.0217, Val Loss: 0.0240\n",
      "Epoch 311, Train Loss: 0.0218, Val Loss: 0.0241\n",
      "Epoch 312, Train Loss: 0.0238, Val Loss: 0.0242\n",
      "Epoch 313, Train Loss: 0.0218, Val Loss: 0.0241\n",
      "Epoch 314, Train Loss: 0.0250, Val Loss: 0.0240\n",
      "Epoch 315, Train Loss: 0.0224, Val Loss: 0.0238\n",
      "Epoch 316, Train Loss: 0.0233, Val Loss: 0.0236\n",
      "Epoch 317, Train Loss: 0.0234, Val Loss: 0.0236\n",
      "Epoch 318, Train Loss: 0.0221, Val Loss: 0.0237\n",
      "Epoch 319, Train Loss: 0.0224, Val Loss: 0.0238\n",
      "Epoch 320, Train Loss: 0.0219, Val Loss: 0.0237\n",
      "Epoch 321, Train Loss: 0.0219, Val Loss: 0.0235\n",
      "Epoch 322, Train Loss: 0.0234, Val Loss: 0.0231\n",
      "Epoch 323, Train Loss: 0.0221, Val Loss: 0.0227\n",
      "Epoch 324, Train Loss: 0.0238, Val Loss: 0.0224\n",
      "Epoch 325, Train Loss: 0.0223, Val Loss: 0.0222\n",
      "Epoch 326, Train Loss: 0.0202, Val Loss: 0.0223\n",
      "Epoch 327, Train Loss: 0.0222, Val Loss: 0.0226\n",
      "Epoch 328, Train Loss: 0.0213, Val Loss: 0.0229\n",
      "Epoch 329, Train Loss: 0.0234, Val Loss: 0.0232\n",
      "Epoch 330, Train Loss: 0.0223, Val Loss: 0.0235\n",
      "Epoch 331, Train Loss: 0.0224, Val Loss: 0.0234\n",
      "Epoch 332, Train Loss: 0.0228, Val Loss: 0.0231\n",
      "Epoch 333, Train Loss: 0.0215, Val Loss: 0.0228\n",
      "Epoch 334, Train Loss: 0.0227, Val Loss: 0.0226\n",
      "Epoch 335, Train Loss: 0.0210, Val Loss: 0.0224\n",
      "Epoch 336, Train Loss: 0.0218, Val Loss: 0.0223\n",
      "Epoch 337, Train Loss: 0.0217, Val Loss: 0.0222\n",
      "Epoch 338, Train Loss: 0.0211, Val Loss: 0.0221\n",
      "Epoch 339, Train Loss: 0.0218, Val Loss: 0.0222\n",
      "Epoch 340, Train Loss: 0.0199, Val Loss: 0.0224\n",
      "Epoch 341, Train Loss: 0.0205, Val Loss: 0.0222\n",
      "Epoch 342, Train Loss: 0.0207, Val Loss: 0.0219\n",
      "Epoch 343, Train Loss: 0.0211, Val Loss: 0.0219\n",
      "Epoch 344, Train Loss: 0.0222, Val Loss: 0.0219\n",
      "Epoch 345, Train Loss: 0.0218, Val Loss: 0.0220\n",
      "Epoch 346, Train Loss: 0.0224, Val Loss: 0.0224\n",
      "Epoch 347, Train Loss: 0.0193, Val Loss: 0.0227\n",
      "Epoch 348, Train Loss: 0.0198, Val Loss: 0.0224\n",
      "Epoch 349, Train Loss: 0.0204, Val Loss: 0.0217\n",
      "Epoch 350, Train Loss: 0.0209, Val Loss: 0.0214\n",
      "Epoch 351, Train Loss: 0.0213, Val Loss: 0.0216\n",
      "Epoch 352, Train Loss: 0.0214, Val Loss: 0.0221\n",
      "Epoch 353, Train Loss: 0.0206, Val Loss: 0.0224\n",
      "Epoch 354, Train Loss: 0.0209, Val Loss: 0.0225\n",
      "Epoch 355, Train Loss: 0.0215, Val Loss: 0.0221\n",
      "Epoch 356, Train Loss: 0.0206, Val Loss: 0.0216\n",
      "Epoch 357, Train Loss: 0.0196, Val Loss: 0.0214\n",
      "Epoch 358, Train Loss: 0.0216, Val Loss: 0.0215\n",
      "Epoch 359, Train Loss: 0.0210, Val Loss: 0.0217\n",
      "Epoch 360, Train Loss: 0.0222, Val Loss: 0.0218\n",
      "Epoch 361, Train Loss: 0.0202, Val Loss: 0.0217\n",
      "Epoch 362, Train Loss: 0.0197, Val Loss: 0.0215\n",
      "Epoch 363, Train Loss: 0.0213, Val Loss: 0.0215\n",
      "Epoch 364, Train Loss: 0.0203, Val Loss: 0.0216\n",
      "Epoch 365, Train Loss: 0.0206, Val Loss: 0.0219\n",
      "Epoch 366, Train Loss: 0.0205, Val Loss: 0.0220\n",
      "Epoch 367, Train Loss: 0.0208, Val Loss: 0.0220\n",
      "Epoch 368, Train Loss: 0.0206, Val Loss: 0.0216\n",
      "Epoch 369, Train Loss: 0.0215, Val Loss: 0.0214\n",
      "Epoch 370, Train Loss: 0.0204, Val Loss: 0.0212\n",
      "Epoch 371, Train Loss: 0.0203, Val Loss: 0.0215\n",
      "Epoch 372, Train Loss: 0.0205, Val Loss: 0.0216\n",
      "Epoch 373, Train Loss: 0.0200, Val Loss: 0.0212\n",
      "Epoch 374, Train Loss: 0.0212, Val Loss: 0.0208\n",
      "Epoch 375, Train Loss: 0.0205, Val Loss: 0.0208\n",
      "Epoch 376, Train Loss: 0.0201, Val Loss: 0.0209\n",
      "Epoch 377, Train Loss: 0.0202, Val Loss: 0.0212\n",
      "Epoch 378, Train Loss: 0.0193, Val Loss: 0.0218\n",
      "Epoch 379, Train Loss: 0.0202, Val Loss: 0.0217\n",
      "Epoch 380, Train Loss: 0.0215, Val Loss: 0.0211\n",
      "Epoch 381, Train Loss: 0.0211, Val Loss: 0.0208\n",
      "Epoch 382, Train Loss: 0.0198, Val Loss: 0.0208\n",
      "Epoch 383, Train Loss: 0.0193, Val Loss: 0.0209\n",
      "Epoch 384, Train Loss: 0.0214, Val Loss: 0.0213\n",
      "Epoch 385, Train Loss: 0.0188, Val Loss: 0.0218\n",
      "Epoch 386, Train Loss: 0.0195, Val Loss: 0.0216\n",
      "Epoch 387, Train Loss: 0.0196, Val Loss: 0.0211\n",
      "Epoch 388, Train Loss: 0.0194, Val Loss: 0.0209\n",
      "Epoch 389, Train Loss: 0.0198, Val Loss: 0.0208\n",
      "Epoch 390, Train Loss: 0.0199, Val Loss: 0.0208\n",
      "Epoch 391, Train Loss: 0.0214, Val Loss: 0.0210\n",
      "Epoch 392, Train Loss: 0.0194, Val Loss: 0.0212\n",
      "Epoch 393, Train Loss: 0.0202, Val Loss: 0.0213\n",
      "Epoch 394, Train Loss: 0.0206, Val Loss: 0.0210\n",
      "Epoch 395, Train Loss: 0.0204, Val Loss: 0.0209\n",
      "Epoch 396, Train Loss: 0.0182, Val Loss: 0.0208\n",
      "Epoch 397, Train Loss: 0.0198, Val Loss: 0.0208\n",
      "Epoch 398, Train Loss: 0.0182, Val Loss: 0.0212\n",
      "Epoch 399, Train Loss: 0.0198, Val Loss: 0.0215\n",
      "Epoch 400, Train Loss: 0.0207, Val Loss: 0.0210\n",
      "Epoch 401, Train Loss: 0.0180, Val Loss: 0.0204\n",
      "Epoch 402, Train Loss: 0.0190, Val Loss: 0.0202\n",
      "Epoch 403, Train Loss: 0.0196, Val Loss: 0.0202\n",
      "Epoch 404, Train Loss: 0.0197, Val Loss: 0.0203\n",
      "Epoch 405, Train Loss: 0.0189, Val Loss: 0.0206\n",
      "Epoch 406, Train Loss: 0.0176, Val Loss: 0.0206\n",
      "Epoch 407, Train Loss: 0.0180, Val Loss: 0.0206\n",
      "Epoch 408, Train Loss: 0.0197, Val Loss: 0.0203\n",
      "Epoch 409, Train Loss: 0.0194, Val Loss: 0.0200\n",
      "Epoch 410, Train Loss: 0.0206, Val Loss: 0.0199\n",
      "Epoch 411, Train Loss: 0.0186, Val Loss: 0.0199\n",
      "Epoch 412, Train Loss: 0.0180, Val Loss: 0.0200\n",
      "Epoch 413, Train Loss: 0.0185, Val Loss: 0.0204\n",
      "Epoch 414, Train Loss: 0.0188, Val Loss: 0.0205\n",
      "Epoch 415, Train Loss: 0.0183, Val Loss: 0.0203\n",
      "Epoch 416, Train Loss: 0.0192, Val Loss: 0.0200\n",
      "Epoch 417, Train Loss: 0.0189, Val Loss: 0.0199\n",
      "Epoch 418, Train Loss: 0.0195, Val Loss: 0.0199\n",
      "Epoch 419, Train Loss: 0.0181, Val Loss: 0.0198\n",
      "Epoch 420, Train Loss: 0.0177, Val Loss: 0.0198\n",
      "Epoch 421, Train Loss: 0.0181, Val Loss: 0.0199\n",
      "Epoch 422, Train Loss: 0.0212, Val Loss: 0.0202\n",
      "Epoch 423, Train Loss: 0.0196, Val Loss: 0.0204\n",
      "Epoch 424, Train Loss: 0.0187, Val Loss: 0.0205\n",
      "Epoch 425, Train Loss: 0.0186, Val Loss: 0.0208\n",
      "Epoch 426, Train Loss: 0.0182, Val Loss: 0.0206\n",
      "Epoch 427, Train Loss: 0.0175, Val Loss: 0.0202\n",
      "Epoch 428, Train Loss: 0.0185, Val Loss: 0.0197\n",
      "Epoch 429, Train Loss: 0.0184, Val Loss: 0.0195\n",
      "Epoch 430, Train Loss: 0.0183, Val Loss: 0.0194\n",
      "Epoch 431, Train Loss: 0.0173, Val Loss: 0.0196\n",
      "Epoch 432, Train Loss: 0.0171, Val Loss: 0.0198\n",
      "Epoch 433, Train Loss: 0.0176, Val Loss: 0.0196\n",
      "Epoch 434, Train Loss: 0.0172, Val Loss: 0.0194\n",
      "Epoch 435, Train Loss: 0.0191, Val Loss: 0.0194\n",
      "Epoch 436, Train Loss: 0.0187, Val Loss: 0.0195\n",
      "Epoch 437, Train Loss: 0.0172, Val Loss: 0.0198\n",
      "Epoch 438, Train Loss: 0.0176, Val Loss: 0.0197\n",
      "Epoch 439, Train Loss: 0.0171, Val Loss: 0.0196\n",
      "Epoch 440, Train Loss: 0.0187, Val Loss: 0.0195\n",
      "Epoch 441, Train Loss: 0.0177, Val Loss: 0.0198\n",
      "Epoch 442, Train Loss: 0.0181, Val Loss: 0.0203\n",
      "Epoch 443, Train Loss: 0.0179, Val Loss: 0.0203\n",
      "Epoch 444, Train Loss: 0.0184, Val Loss: 0.0197\n",
      "Epoch 445, Train Loss: 0.0197, Val Loss: 0.0190\n",
      "Epoch 446, Train Loss: 0.0177, Val Loss: 0.0187\n",
      "Epoch 447, Train Loss: 0.0175, Val Loss: 0.0186\n",
      "Epoch 448, Train Loss: 0.0175, Val Loss: 0.0187\n",
      "Epoch 449, Train Loss: 0.0174, Val Loss: 0.0191\n",
      "Epoch 450, Train Loss: 0.0183, Val Loss: 0.0194\n",
      "Epoch 451, Train Loss: 0.0182, Val Loss: 0.0190\n",
      "Epoch 452, Train Loss: 0.0182, Val Loss: 0.0189\n",
      "Epoch 453, Train Loss: 0.0197, Val Loss: 0.0192\n",
      "Epoch 454, Train Loss: 0.0182, Val Loss: 0.0196\n",
      "Epoch 455, Train Loss: 0.0183, Val Loss: 0.0203\n",
      "Epoch 456, Train Loss: 0.0179, Val Loss: 0.0206\n",
      "Epoch 457, Train Loss: 0.0182, Val Loss: 0.0199\n",
      "Epoch 458, Train Loss: 0.0175, Val Loss: 0.0193\n",
      "Epoch 459, Train Loss: 0.0174, Val Loss: 0.0190\n",
      "Epoch 460, Train Loss: 0.0177, Val Loss: 0.0190\n",
      "Epoch 461, Train Loss: 0.0183, Val Loss: 0.0191\n",
      "Epoch 462, Train Loss: 0.0174, Val Loss: 0.0188\n",
      "Epoch 463, Train Loss: 0.0195, Val Loss: 0.0187\n",
      "Epoch 464, Train Loss: 0.0176, Val Loss: 0.0187\n",
      "Epoch 465, Train Loss: 0.0162, Val Loss: 0.0187\n",
      "Epoch 466, Train Loss: 0.0179, Val Loss: 0.0189\n",
      "Epoch 467, Train Loss: 0.0179, Val Loss: 0.0191\n",
      "Epoch 468, Train Loss: 0.0163, Val Loss: 0.0191\n",
      "Epoch 469, Train Loss: 0.0178, Val Loss: 0.0189\n",
      "Epoch 470, Train Loss: 0.0171, Val Loss: 0.0188\n",
      "Epoch 471, Train Loss: 0.0167, Val Loss: 0.0189\n",
      "Epoch 472, Train Loss: 0.0183, Val Loss: 0.0193\n",
      "Epoch 473, Train Loss: 0.0166, Val Loss: 0.0195\n",
      "Epoch 474, Train Loss: 0.0188, Val Loss: 0.0187\n",
      "Epoch 475, Train Loss: 0.0171, Val Loss: 0.0183\n",
      "Epoch 476, Train Loss: 0.0185, Val Loss: 0.0183\n",
      "Epoch 477, Train Loss: 0.0189, Val Loss: 0.0188\n",
      "Epoch 478, Train Loss: 0.0157, Val Loss: 0.0197\n",
      "Epoch 479, Train Loss: 0.0172, Val Loss: 0.0196\n",
      "Epoch 480, Train Loss: 0.0172, Val Loss: 0.0184\n",
      "Epoch 481, Train Loss: 0.0163, Val Loss: 0.0181\n",
      "Epoch 482, Train Loss: 0.0173, Val Loss: 0.0181\n",
      "Epoch 483, Train Loss: 0.0173, Val Loss: 0.0186\n",
      "Epoch 484, Train Loss: 0.0153, Val Loss: 0.0193\n",
      "Epoch 485, Train Loss: 0.0156, Val Loss: 0.0192\n",
      "Epoch 486, Train Loss: 0.0168, Val Loss: 0.0185\n",
      "Epoch 487, Train Loss: 0.0161, Val Loss: 0.0181\n",
      "Epoch 488, Train Loss: 0.0169, Val Loss: 0.0180\n",
      "Epoch 489, Train Loss: 0.0157, Val Loss: 0.0181\n",
      "Epoch 490, Train Loss: 0.0187, Val Loss: 0.0184\n",
      "Epoch 491, Train Loss: 0.0157, Val Loss: 0.0183\n",
      "Epoch 492, Train Loss: 0.0166, Val Loss: 0.0182\n",
      "Epoch 493, Train Loss: 0.0165, Val Loss: 0.0182\n",
      "Epoch 494, Train Loss: 0.0160, Val Loss: 0.0183\n",
      "Epoch 495, Train Loss: 0.0163, Val Loss: 0.0184\n",
      "Epoch 496, Train Loss: 0.0170, Val Loss: 0.0184\n",
      "Epoch 497, Train Loss: 0.0176, Val Loss: 0.0186\n",
      "Epoch 498, Train Loss: 0.0154, Val Loss: 0.0186\n",
      "Epoch 499, Train Loss: 0.0160, Val Loss: 0.0182\n",
      "Epoch 500, Train Loss: 0.0168, Val Loss: 0.0183\n",
      "Epoch 501, Train Loss: 0.0158, Val Loss: 0.0184\n",
      "Epoch 502, Train Loss: 0.0171, Val Loss: 0.0187\n",
      "Epoch 503, Train Loss: 0.0161, Val Loss: 0.0181\n",
      "Epoch 504, Train Loss: 0.0162, Val Loss: 0.0176\n",
      "Epoch 505, Train Loss: 0.0160, Val Loss: 0.0175\n",
      "Epoch 506, Train Loss: 0.0161, Val Loss: 0.0176\n",
      "Epoch 507, Train Loss: 0.0163, Val Loss: 0.0176\n",
      "Epoch 508, Train Loss: 0.0149, Val Loss: 0.0178\n",
      "Epoch 509, Train Loss: 0.0171, Val Loss: 0.0182\n",
      "Epoch 510, Train Loss: 0.0171, Val Loss: 0.0185\n",
      "Epoch 511, Train Loss: 0.0156, Val Loss: 0.0182\n",
      "Epoch 512, Train Loss: 0.0163, Val Loss: 0.0180\n",
      "Epoch 513, Train Loss: 0.0168, Val Loss: 0.0181\n",
      "Epoch 514, Train Loss: 0.0151, Val Loss: 0.0184\n",
      "Epoch 515, Train Loss: 0.0160, Val Loss: 0.0185\n",
      "Epoch 516, Train Loss: 0.0162, Val Loss: 0.0184\n",
      "Epoch 517, Train Loss: 0.0151, Val Loss: 0.0180\n",
      "Epoch 518, Train Loss: 0.0172, Val Loss: 0.0177\n",
      "Epoch 519, Train Loss: 0.0159, Val Loss: 0.0177\n",
      "Epoch 520, Train Loss: 0.0159, Val Loss: 0.0177\n",
      "Epoch 521, Train Loss: 0.0156, Val Loss: 0.0174\n",
      "Epoch 522, Train Loss: 0.0151, Val Loss: 0.0172\n",
      "Epoch 523, Train Loss: 0.0165, Val Loss: 0.0172\n",
      "Epoch 524, Train Loss: 0.0164, Val Loss: 0.0174\n",
      "Epoch 525, Train Loss: 0.0163, Val Loss: 0.0176\n",
      "Epoch 526, Train Loss: 0.0160, Val Loss: 0.0177\n",
      "Epoch 527, Train Loss: 0.0158, Val Loss: 0.0175\n",
      "Epoch 528, Train Loss: 0.0165, Val Loss: 0.0176\n",
      "Epoch 529, Train Loss: 0.0165, Val Loss: 0.0177\n",
      "Epoch 530, Train Loss: 0.0164, Val Loss: 0.0179\n",
      "Epoch 531, Train Loss: 0.0153, Val Loss: 0.0184\n",
      "Epoch 532, Train Loss: 0.0159, Val Loss: 0.0183\n",
      "Epoch 533, Train Loss: 0.0161, Val Loss: 0.0178\n",
      "Epoch 534, Train Loss: 0.0150, Val Loss: 0.0172\n",
      "Epoch 535, Train Loss: 0.0152, Val Loss: 0.0171\n",
      "Epoch 536, Train Loss: 0.0172, Val Loss: 0.0170\n",
      "Epoch 537, Train Loss: 0.0150, Val Loss: 0.0173\n",
      "Epoch 538, Train Loss: 0.0150, Val Loss: 0.0176\n",
      "Epoch 539, Train Loss: 0.0158, Val Loss: 0.0173\n",
      "Epoch 540, Train Loss: 0.0161, Val Loss: 0.0167\n",
      "Epoch 541, Train Loss: 0.0160, Val Loss: 0.0168\n",
      "Epoch 542, Train Loss: 0.0151, Val Loss: 0.0175\n",
      "Epoch 543, Train Loss: 0.0170, Val Loss: 0.0184\n",
      "Epoch 544, Train Loss: 0.0160, Val Loss: 0.0178\n",
      "Epoch 545, Train Loss: 0.0147, Val Loss: 0.0172\n",
      "Epoch 546, Train Loss: 0.0154, Val Loss: 0.0169\n",
      "Epoch 547, Train Loss: 0.0152, Val Loss: 0.0173\n",
      "Epoch 548, Train Loss: 0.0149, Val Loss: 0.0188\n",
      "Epoch 549, Train Loss: 0.0156, Val Loss: 0.0184\n",
      "Epoch 550, Train Loss: 0.0162, Val Loss: 0.0167\n",
      "Epoch 551, Train Loss: 0.0157, Val Loss: 0.0169\n",
      "Epoch 552, Train Loss: 0.0168, Val Loss: 0.0168\n",
      "Epoch 553, Train Loss: 0.0159, Val Loss: 0.0174\n",
      "Epoch 554, Train Loss: 0.0157, Val Loss: 0.0188\n",
      "Epoch 555, Train Loss: 0.0158, Val Loss: 0.0180\n",
      "Epoch 556, Train Loss: 0.0155, Val Loss: 0.0166\n",
      "Epoch 557, Train Loss: 0.0154, Val Loss: 0.0165\n",
      "Epoch 558, Train Loss: 0.0151, Val Loss: 0.0171\n",
      "Epoch 559, Train Loss: 0.0144, Val Loss: 0.0172\n",
      "Epoch 560, Train Loss: 0.0159, Val Loss: 0.0168\n",
      "Epoch 561, Train Loss: 0.0157, Val Loss: 0.0166\n",
      "Epoch 562, Train Loss: 0.0141, Val Loss: 0.0166\n",
      "Epoch 563, Train Loss: 0.0146, Val Loss: 0.0170\n",
      "Epoch 564, Train Loss: 0.0156, Val Loss: 0.0178\n",
      "Epoch 565, Train Loss: 0.0164, Val Loss: 0.0171\n",
      "Epoch 566, Train Loss: 0.0154, Val Loss: 0.0165\n",
      "Epoch 567, Train Loss: 0.0166, Val Loss: 0.0168\n",
      "Epoch 568, Train Loss: 0.0151, Val Loss: 0.0174\n",
      "Epoch 569, Train Loss: 0.0164, Val Loss: 0.0171\n",
      "Epoch 570, Train Loss: 0.0157, Val Loss: 0.0166\n",
      "Epoch 571, Train Loss: 0.0145, Val Loss: 0.0166\n",
      "Epoch 572, Train Loss: 0.0145, Val Loss: 0.0166\n",
      "Epoch 573, Train Loss: 0.0150, Val Loss: 0.0167\n",
      "Epoch 574, Train Loss: 0.0147, Val Loss: 0.0172\n",
      "Epoch 575, Train Loss: 0.0141, Val Loss: 0.0172\n",
      "Epoch 576, Train Loss: 0.0154, Val Loss: 0.0166\n",
      "Epoch 577, Train Loss: 0.0162, Val Loss: 0.0164\n",
      "Epoch 578, Train Loss: 0.0167, Val Loss: 0.0169\n",
      "Epoch 579, Train Loss: 0.0154, Val Loss: 0.0170\n",
      "Epoch 580, Train Loss: 0.0152, Val Loss: 0.0169\n",
      "Epoch 581, Train Loss: 0.0149, Val Loss: 0.0169\n",
      "Epoch 582, Train Loss: 0.0152, Val Loss: 0.0164\n",
      "Epoch 583, Train Loss: 0.0150, Val Loss: 0.0167\n",
      "Epoch 584, Train Loss: 0.0159, Val Loss: 0.0167\n",
      "Epoch 585, Train Loss: 0.0155, Val Loss: 0.0167\n",
      "Epoch 586, Train Loss: 0.0149, Val Loss: 0.0170\n",
      "Epoch 587, Train Loss: 0.0151, Val Loss: 0.0168\n",
      "Epoch 588, Train Loss: 0.0150, Val Loss: 0.0164\n",
      "Epoch 589, Train Loss: 0.0143, Val Loss: 0.0163\n",
      "Epoch 590, Train Loss: 0.0142, Val Loss: 0.0169\n",
      "Epoch 591, Train Loss: 0.0151, Val Loss: 0.0173\n",
      "Epoch 592, Train Loss: 0.0158, Val Loss: 0.0172\n",
      "Epoch 593, Train Loss: 0.0151, Val Loss: 0.0168\n",
      "Epoch 594, Train Loss: 0.0159, Val Loss: 0.0166\n",
      "Epoch 595, Train Loss: 0.0147, Val Loss: 0.0165\n",
      "Epoch 596, Train Loss: 0.0149, Val Loss: 0.0173\n",
      "Epoch 597, Train Loss: 0.0144, Val Loss: 0.0172\n",
      "Epoch 598, Train Loss: 0.0151, Val Loss: 0.0165\n",
      "Epoch 599, Train Loss: 0.0133, Val Loss: 0.0162\n",
      "Epoch 600, Train Loss: 0.0147, Val Loss: 0.0171\n",
      "Epoch 601, Train Loss: 0.0145, Val Loss: 0.0171\n",
      "Epoch 602, Train Loss: 0.0143, Val Loss: 0.0164\n",
      "Epoch 603, Train Loss: 0.0143, Val Loss: 0.0165\n",
      "Epoch 604, Train Loss: 0.0155, Val Loss: 0.0168\n",
      "Epoch 605, Train Loss: 0.0131, Val Loss: 0.0168\n",
      "Epoch 606, Train Loss: 0.0145, Val Loss: 0.0164\n",
      "Epoch 607, Train Loss: 0.0143, Val Loss: 0.0162\n",
      "Epoch 608, Train Loss: 0.0148, Val Loss: 0.0163\n",
      "Epoch 609, Train Loss: 0.0139, Val Loss: 0.0169\n",
      "Epoch 610, Train Loss: 0.0141, Val Loss: 0.0167\n",
      "Epoch 611, Train Loss: 0.0139, Val Loss: 0.0165\n",
      "Epoch 612, Train Loss: 0.0141, Val Loss: 0.0161\n",
      "Epoch 613, Train Loss: 0.0141, Val Loss: 0.0161\n",
      "Epoch 614, Train Loss: 0.0141, Val Loss: 0.0162\n",
      "Epoch 615, Train Loss: 0.0143, Val Loss: 0.0165\n",
      "Epoch 616, Train Loss: 0.0142, Val Loss: 0.0168\n",
      "Epoch 617, Train Loss: 0.0154, Val Loss: 0.0168\n",
      "Epoch 618, Train Loss: 0.0135, Val Loss: 0.0160\n",
      "Epoch 619, Train Loss: 0.0151, Val Loss: 0.0161\n",
      "Epoch 620, Train Loss: 0.0152, Val Loss: 0.0164\n",
      "Epoch 621, Train Loss: 0.0143, Val Loss: 0.0166\n",
      "Epoch 622, Train Loss: 0.0138, Val Loss: 0.0165\n",
      "Epoch 623, Train Loss: 0.0143, Val Loss: 0.0168\n",
      "Epoch 624, Train Loss: 0.0142, Val Loss: 0.0166\n",
      "Epoch 625, Train Loss: 0.0141, Val Loss: 0.0164\n",
      "Epoch 626, Train Loss: 0.0146, Val Loss: 0.0162\n",
      "Epoch 627, Train Loss: 0.0139, Val Loss: 0.0158\n",
      "Epoch 628, Train Loss: 0.0144, Val Loss: 0.0158\n",
      "Epoch 629, Train Loss: 0.0137, Val Loss: 0.0163\n",
      "Epoch 630, Train Loss: 0.0139, Val Loss: 0.0170\n",
      "Epoch 631, Train Loss: 0.0136, Val Loss: 0.0169\n",
      "Epoch 632, Train Loss: 0.0135, Val Loss: 0.0163\n",
      "Epoch 633, Train Loss: 0.0143, Val Loss: 0.0162\n",
      "Epoch 634, Train Loss: 0.0134, Val Loss: 0.0170\n",
      "Epoch 635, Train Loss: 0.0142, Val Loss: 0.0171\n",
      "Epoch 636, Train Loss: 0.0143, Val Loss: 0.0160\n",
      "Epoch 637, Train Loss: 0.0151, Val Loss: 0.0157\n",
      "Epoch 638, Train Loss: 0.0158, Val Loss: 0.0163\n",
      "Epoch 639, Train Loss: 0.0148, Val Loss: 0.0179\n",
      "Epoch 640, Train Loss: 0.0140, Val Loss: 0.0173\n",
      "Epoch 641, Train Loss: 0.0151, Val Loss: 0.0159\n",
      "Epoch 642, Train Loss: 0.0129, Val Loss: 0.0156\n",
      "Epoch 643, Train Loss: 0.0144, Val Loss: 0.0163\n",
      "Epoch 644, Train Loss: 0.0138, Val Loss: 0.0174\n",
      "Epoch 645, Train Loss: 0.0137, Val Loss: 0.0163\n",
      "Epoch 646, Train Loss: 0.0135, Val Loss: 0.0155\n",
      "Epoch 647, Train Loss: 0.0148, Val Loss: 0.0158\n",
      "Epoch 648, Train Loss: 0.0139, Val Loss: 0.0171\n",
      "Epoch 649, Train Loss: 0.0147, Val Loss: 0.0169\n",
      "Epoch 650, Train Loss: 0.0132, Val Loss: 0.0163\n",
      "Epoch 651, Train Loss: 0.0130, Val Loss: 0.0160\n",
      "Epoch 652, Train Loss: 0.0141, Val Loss: 0.0161\n",
      "Epoch 653, Train Loss: 0.0132, Val Loss: 0.0167\n",
      "Epoch 654, Train Loss: 0.0138, Val Loss: 0.0159\n",
      "Epoch 655, Train Loss: 0.0138, Val Loss: 0.0157\n",
      "Epoch 656, Train Loss: 0.0139, Val Loss: 0.0164\n",
      "Epoch 657, Train Loss: 0.0129, Val Loss: 0.0175\n",
      "Epoch 658, Train Loss: 0.0137, Val Loss: 0.0168\n",
      "Epoch 659, Train Loss: 0.0144, Val Loss: 0.0162\n",
      "Epoch 660, Train Loss: 0.0136, Val Loss: 0.0157\n",
      "Epoch 661, Train Loss: 0.0144, Val Loss: 0.0158\n",
      "Epoch 662, Train Loss: 0.0141, Val Loss: 0.0159\n",
      "Epoch 663, Train Loss: 0.0144, Val Loss: 0.0161\n",
      "Epoch 664, Train Loss: 0.0134, Val Loss: 0.0162\n",
      "Epoch 665, Train Loss: 0.0131, Val Loss: 0.0162\n",
      "Epoch 666, Train Loss: 0.0144, Val Loss: 0.0161\n",
      "Epoch 667, Train Loss: 0.0136, Val Loss: 0.0162\n",
      "Epoch 668, Train Loss: 0.0145, Val Loss: 0.0161\n",
      "Epoch 669, Train Loss: 0.0126, Val Loss: 0.0166\n",
      "Epoch 670, Train Loss: 0.0133, Val Loss: 0.0165\n",
      "Epoch 671, Train Loss: 0.0141, Val Loss: 0.0158\n",
      "Epoch 672, Train Loss: 0.0136, Val Loss: 0.0165\n",
      "Epoch 673, Train Loss: 0.0128, Val Loss: 0.0169\n",
      "Epoch 674, Train Loss: 0.0141, Val Loss: 0.0157\n",
      "Epoch 675, Train Loss: 0.0135, Val Loss: 0.0157\n",
      "Epoch 676, Train Loss: 0.0128, Val Loss: 0.0168\n",
      "Epoch 677, Train Loss: 0.0143, Val Loss: 0.0173\n",
      "Epoch 678, Train Loss: 0.0134, Val Loss: 0.0164\n",
      "Epoch 679, Train Loss: 0.0141, Val Loss: 0.0156\n",
      "Epoch 680, Train Loss: 0.0137, Val Loss: 0.0156\n",
      "Epoch 681, Train Loss: 0.0130, Val Loss: 0.0170\n",
      "Epoch 682, Train Loss: 0.0129, Val Loss: 0.0172\n",
      "Epoch 683, Train Loss: 0.0153, Val Loss: 0.0160\n",
      "Epoch 684, Train Loss: 0.0128, Val Loss: 0.0156\n",
      "Epoch 685, Train Loss: 0.0137, Val Loss: 0.0164\n",
      "Epoch 686, Train Loss: 0.0123, Val Loss: 0.0166\n",
      "Epoch 687, Train Loss: 0.0141, Val Loss: 0.0156\n",
      "Epoch 688, Train Loss: 0.0144, Val Loss: 0.0157\n",
      "Epoch 689, Train Loss: 0.0136, Val Loss: 0.0171\n",
      "Epoch 690, Train Loss: 0.0133, Val Loss: 0.0168\n",
      "Epoch 691, Train Loss: 0.0137, Val Loss: 0.0156\n",
      "Epoch 692, Train Loss: 0.0127, Val Loss: 0.0155\n",
      "Epoch 693, Train Loss: 0.0136, Val Loss: 0.0163\n",
      "Epoch 694, Train Loss: 0.0125, Val Loss: 0.0165\n",
      "Epoch 695, Train Loss: 0.0144, Val Loss: 0.0159\n",
      "Epoch 696, Train Loss: 0.0127, Val Loss: 0.0158\n",
      "Epoch 697, Train Loss: 0.0132, Val Loss: 0.0159\n",
      "Epoch 698, Train Loss: 0.0132, Val Loss: 0.0167\n",
      "Epoch 699, Train Loss: 0.0130, Val Loss: 0.0164\n",
      "Epoch 700, Train Loss: 0.0127, Val Loss: 0.0158\n",
      "Epoch 701, Train Loss: 0.0139, Val Loss: 0.0157\n",
      "Epoch 702, Train Loss: 0.0143, Val Loss: 0.0157\n",
      "Epoch 703, Train Loss: 0.0118, Val Loss: 0.0157\n",
      "Epoch 704, Train Loss: 0.0123, Val Loss: 0.0160\n",
      "Epoch 705, Train Loss: 0.0127, Val Loss: 0.0168\n",
      "Epoch 706, Train Loss: 0.0129, Val Loss: 0.0158\n",
      "Epoch 707, Train Loss: 0.0116, Val Loss: 0.0156\n",
      "Epoch 708, Train Loss: 0.0129, Val Loss: 0.0162\n",
      "Epoch 709, Train Loss: 0.0127, Val Loss: 0.0164\n",
      "Epoch 710, Train Loss: 0.0128, Val Loss: 0.0157\n",
      "Epoch 711, Train Loss: 0.0131, Val Loss: 0.0154\n",
      "Epoch 712, Train Loss: 0.0116, Val Loss: 0.0157\n",
      "Epoch 713, Train Loss: 0.0130, Val Loss: 0.0160\n",
      "Epoch 714, Train Loss: 0.0127, Val Loss: 0.0158\n",
      "Epoch 715, Train Loss: 0.0129, Val Loss: 0.0161\n",
      "Epoch 716, Train Loss: 0.0130, Val Loss: 0.0162\n",
      "Epoch 717, Train Loss: 0.0139, Val Loss: 0.0158\n",
      "Epoch 718, Train Loss: 0.0131, Val Loss: 0.0160\n",
      "Epoch 719, Train Loss: 0.0132, Val Loss: 0.0159\n",
      "Epoch 720, Train Loss: 0.0126, Val Loss: 0.0161\n",
      "Epoch 721, Train Loss: 0.0133, Val Loss: 0.0161\n",
      "Epoch 722, Train Loss: 0.0132, Val Loss: 0.0160\n",
      "Epoch 723, Train Loss: 0.0126, Val Loss: 0.0157\n",
      "Epoch 724, Train Loss: 0.0124, Val Loss: 0.0153\n",
      "Epoch 725, Train Loss: 0.0133, Val Loss: 0.0159\n",
      "Epoch 726, Train Loss: 0.0139, Val Loss: 0.0170\n",
      "Epoch 727, Train Loss: 0.0128, Val Loss: 0.0163\n",
      "Epoch 728, Train Loss: 0.0135, Val Loss: 0.0153\n",
      "Epoch 729, Train Loss: 0.0128, Val Loss: 0.0154\n",
      "Epoch 730, Train Loss: 0.0129, Val Loss: 0.0170\n",
      "Epoch 731, Train Loss: 0.0137, Val Loss: 0.0161\n",
      "Epoch 732, Train Loss: 0.0132, Val Loss: 0.0150\n",
      "Epoch 733, Train Loss: 0.0139, Val Loss: 0.0154\n",
      "Epoch 734, Train Loss: 0.0126, Val Loss: 0.0167\n",
      "Epoch 735, Train Loss: 0.0130, Val Loss: 0.0163\n",
      "Epoch 736, Train Loss: 0.0128, Val Loss: 0.0152\n",
      "Epoch 737, Train Loss: 0.0124, Val Loss: 0.0156\n",
      "Epoch 738, Train Loss: 0.0126, Val Loss: 0.0165\n",
      "Epoch 739, Train Loss: 0.0128, Val Loss: 0.0158\n",
      "Epoch 740, Train Loss: 0.0126, Val Loss: 0.0155\n",
      "Epoch 741, Train Loss: 0.0117, Val Loss: 0.0158\n",
      "Epoch 742, Train Loss: 0.0124, Val Loss: 0.0168\n",
      "Epoch 743, Train Loss: 0.0136, Val Loss: 0.0156\n",
      "Epoch 744, Train Loss: 0.0129, Val Loss: 0.0145\n",
      "Epoch 745, Train Loss: 0.0131, Val Loss: 0.0153\n",
      "Epoch 746, Train Loss: 0.0129, Val Loss: 0.0165\n",
      "Epoch 747, Train Loss: 0.0135, Val Loss: 0.0149\n",
      "Epoch 748, Train Loss: 0.0123, Val Loss: 0.0148\n",
      "Epoch 749, Train Loss: 0.0123, Val Loss: 0.0158\n",
      "Epoch 750, Train Loss: 0.0124, Val Loss: 0.0160\n",
      "Epoch 751, Train Loss: 0.0128, Val Loss: 0.0153\n",
      "Epoch 752, Train Loss: 0.0124, Val Loss: 0.0158\n",
      "Epoch 753, Train Loss: 0.0126, Val Loss: 0.0163\n",
      "Epoch 754, Train Loss: 0.0129, Val Loss: 0.0156\n",
      "Epoch 755, Train Loss: 0.0123, Val Loss: 0.0148\n",
      "Epoch 756, Train Loss: 0.0132, Val Loss: 0.0157\n",
      "Epoch 757, Train Loss: 0.0117, Val Loss: 0.0163\n",
      "Epoch 758, Train Loss: 0.0121, Val Loss: 0.0152\n",
      "Epoch 759, Train Loss: 0.0132, Val Loss: 0.0148\n",
      "Epoch 760, Train Loss: 0.0128, Val Loss: 0.0154\n",
      "Epoch 761, Train Loss: 0.0108, Val Loss: 0.0158\n",
      "Epoch 762, Train Loss: 0.0138, Val Loss: 0.0154\n",
      "Epoch 763, Train Loss: 0.0120, Val Loss: 0.0154\n",
      "Epoch 764, Train Loss: 0.0126, Val Loss: 0.0160\n",
      "Epoch 765, Train Loss: 0.0123, Val Loss: 0.0152\n",
      "Epoch 766, Train Loss: 0.0125, Val Loss: 0.0147\n",
      "Epoch 767, Train Loss: 0.0125, Val Loss: 0.0152\n",
      "Epoch 768, Train Loss: 0.0120, Val Loss: 0.0155\n",
      "Epoch 769, Train Loss: 0.0123, Val Loss: 0.0151\n",
      "Epoch 770, Train Loss: 0.0129, Val Loss: 0.0145\n",
      "Epoch 771, Train Loss: 0.0117, Val Loss: 0.0149\n",
      "Epoch 772, Train Loss: 0.0120, Val Loss: 0.0174\n",
      "Epoch 773, Train Loss: 0.0124, Val Loss: 0.0159\n",
      "Epoch 774, Train Loss: 0.0123, Val Loss: 0.0152\n",
      "Epoch 775, Train Loss: 0.0125, Val Loss: 0.0159\n",
      "Epoch 776, Train Loss: 0.0119, Val Loss: 0.0169\n",
      "Epoch 777, Train Loss: 0.0121, Val Loss: 0.0149\n",
      "Epoch 778, Train Loss: 0.0124, Val Loss: 0.0141\n",
      "Epoch 779, Train Loss: 0.0128, Val Loss: 0.0154\n",
      "Epoch 780, Train Loss: 0.0118, Val Loss: 0.0165\n",
      "Epoch 781, Train Loss: 0.0123, Val Loss: 0.0144\n",
      "Epoch 782, Train Loss: 0.0115, Val Loss: 0.0145\n",
      "Epoch 783, Train Loss: 0.0129, Val Loss: 0.0164\n",
      "Epoch 784, Train Loss: 0.0126, Val Loss: 0.0167\n",
      "Epoch 785, Train Loss: 0.0133, Val Loss: 0.0150\n",
      "Epoch 786, Train Loss: 0.0122, Val Loss: 0.0146\n",
      "Epoch 787, Train Loss: 0.0134, Val Loss: 0.0174\n",
      "Epoch 788, Train Loss: 0.0137, Val Loss: 0.0146\n",
      "Epoch 789, Train Loss: 0.0127, Val Loss: 0.0144\n",
      "Epoch 790, Train Loss: 0.0133, Val Loss: 0.0165\n",
      "Epoch 791, Train Loss: 0.0122, Val Loss: 0.0171\n",
      "Epoch 792, Train Loss: 0.0128, Val Loss: 0.0147\n",
      "Epoch 793, Train Loss: 0.0123, Val Loss: 0.0145\n",
      "Epoch 794, Train Loss: 0.0124, Val Loss: 0.0165\n",
      "Epoch 795, Train Loss: 0.0119, Val Loss: 0.0159\n",
      "Epoch 796, Train Loss: 0.0138, Val Loss: 0.0142\n",
      "Epoch 797, Train Loss: 0.0121, Val Loss: 0.0142\n",
      "Epoch 798, Train Loss: 0.0123, Val Loss: 0.0171\n",
      "Epoch 799, Train Loss: 0.0125, Val Loss: 0.0164\n",
      "Epoch 800, Train Loss: 0.0116, Val Loss: 0.0148\n",
      "Epoch 801, Train Loss: 0.0130, Val Loss: 0.0148\n",
      "Epoch 802, Train Loss: 0.0106, Val Loss: 0.0164\n",
      "Epoch 803, Train Loss: 0.0114, Val Loss: 0.0161\n",
      "Epoch 804, Train Loss: 0.0116, Val Loss: 0.0143\n",
      "Epoch 805, Train Loss: 0.0122, Val Loss: 0.0142\n",
      "Epoch 806, Train Loss: 0.0113, Val Loss: 0.0156\n",
      "Epoch 807, Train Loss: 0.0122, Val Loss: 0.0158\n",
      "Epoch 808, Train Loss: 0.0121, Val Loss: 0.0146\n",
      "Epoch 809, Train Loss: 0.0125, Val Loss: 0.0146\n",
      "Epoch 810, Train Loss: 0.0128, Val Loss: 0.0157\n",
      "Epoch 811, Train Loss: 0.0129, Val Loss: 0.0155\n",
      "Epoch 812, Train Loss: 0.0128, Val Loss: 0.0147\n",
      "Epoch 813, Train Loss: 0.0115, Val Loss: 0.0149\n",
      "Epoch 814, Train Loss: 0.0112, Val Loss: 0.0156\n",
      "Epoch 815, Train Loss: 0.0119, Val Loss: 0.0155\n",
      "Epoch 816, Train Loss: 0.0127, Val Loss: 0.0146\n",
      "Epoch 817, Train Loss: 0.0125, Val Loss: 0.0149\n",
      "Epoch 818, Train Loss: 0.0119, Val Loss: 0.0153\n",
      "Epoch 819, Train Loss: 0.0120, Val Loss: 0.0157\n",
      "Epoch 820, Train Loss: 0.0111, Val Loss: 0.0148\n",
      "Epoch 821, Train Loss: 0.0120, Val Loss: 0.0142\n",
      "Epoch 822, Train Loss: 0.0109, Val Loss: 0.0143\n",
      "Epoch 823, Train Loss: 0.0119, Val Loss: 0.0155\n",
      "Epoch 824, Train Loss: 0.0119, Val Loss: 0.0156\n",
      "Epoch 825, Train Loss: 0.0118, Val Loss: 0.0148\n",
      "Epoch 826, Train Loss: 0.0117, Val Loss: 0.0153\n",
      "Epoch 827, Train Loss: 0.0123, Val Loss: 0.0159\n",
      "Epoch 828, Train Loss: 0.0116, Val Loss: 0.0147\n",
      "Epoch 829, Train Loss: 0.0115, Val Loss: 0.0140\n",
      "Epoch 830, Train Loss: 0.0119, Val Loss: 0.0145\n",
      "Epoch 831, Train Loss: 0.0113, Val Loss: 0.0165\n",
      "Epoch 832, Train Loss: 0.0122, Val Loss: 0.0150\n",
      "Epoch 833, Train Loss: 0.0115, Val Loss: 0.0143\n",
      "Epoch 834, Train Loss: 0.0124, Val Loss: 0.0146\n",
      "Epoch 835, Train Loss: 0.0108, Val Loss: 0.0156\n",
      "Epoch 836, Train Loss: 0.0124, Val Loss: 0.0151\n",
      "Epoch 837, Train Loss: 0.0117, Val Loss: 0.0145\n",
      "Epoch 838, Train Loss: 0.0114, Val Loss: 0.0147\n",
      "Epoch 839, Train Loss: 0.0113, Val Loss: 0.0153\n",
      "Epoch 840, Train Loss: 0.0120, Val Loss: 0.0153\n",
      "Epoch 841, Train Loss: 0.0118, Val Loss: 0.0141\n",
      "Epoch 842, Train Loss: 0.0128, Val Loss: 0.0140\n",
      "Epoch 843, Train Loss: 0.0127, Val Loss: 0.0153\n",
      "Epoch 844, Train Loss: 0.0116, Val Loss: 0.0153\n",
      "Epoch 845, Train Loss: 0.0120, Val Loss: 0.0143\n",
      "Epoch 846, Train Loss: 0.0116, Val Loss: 0.0145\n",
      "Epoch 847, Train Loss: 0.0122, Val Loss: 0.0160\n",
      "Epoch 848, Train Loss: 0.0123, Val Loss: 0.0147\n",
      "Epoch 849, Train Loss: 0.0116, Val Loss: 0.0139\n",
      "Epoch 850, Train Loss: 0.0111, Val Loss: 0.0143\n",
      "Epoch 851, Train Loss: 0.0114, Val Loss: 0.0158\n",
      "Epoch 852, Train Loss: 0.0120, Val Loss: 0.0146\n",
      "Epoch 853, Train Loss: 0.0116, Val Loss: 0.0147\n",
      "Epoch 854, Train Loss: 0.0119, Val Loss: 0.0152\n",
      "Epoch 855, Train Loss: 0.0111, Val Loss: 0.0157\n",
      "Epoch 856, Train Loss: 0.0118, Val Loss: 0.0143\n",
      "Epoch 857, Train Loss: 0.0122, Val Loss: 0.0136\n",
      "Epoch 858, Train Loss: 0.0116, Val Loss: 0.0148\n",
      "Epoch 859, Train Loss: 0.0113, Val Loss: 0.0162\n",
      "Epoch 860, Train Loss: 0.0125, Val Loss: 0.0142\n",
      "Epoch 861, Train Loss: 0.0126, Val Loss: 0.0139\n",
      "Epoch 862, Train Loss: 0.0114, Val Loss: 0.0154\n",
      "Epoch 863, Train Loss: 0.0120, Val Loss: 0.0150\n",
      "Epoch 864, Train Loss: 0.0118, Val Loss: 0.0140\n",
      "Epoch 865, Train Loss: 0.0112, Val Loss: 0.0140\n",
      "Epoch 866, Train Loss: 0.0126, Val Loss: 0.0147\n",
      "Epoch 867, Train Loss: 0.0115, Val Loss: 0.0159\n",
      "Epoch 868, Train Loss: 0.0117, Val Loss: 0.0140\n",
      "Epoch 869, Train Loss: 0.0120, Val Loss: 0.0139\n",
      "Epoch 870, Train Loss: 0.0116, Val Loss: 0.0150\n",
      "Epoch 871, Train Loss: 0.0118, Val Loss: 0.0156\n",
      "Epoch 872, Train Loss: 0.0123, Val Loss: 0.0146\n",
      "Epoch 873, Train Loss: 0.0116, Val Loss: 0.0141\n",
      "Epoch 874, Train Loss: 0.0106, Val Loss: 0.0140\n",
      "Epoch 875, Train Loss: 0.0107, Val Loss: 0.0145\n",
      "Epoch 876, Train Loss: 0.0114, Val Loss: 0.0148\n",
      "Epoch 877, Train Loss: 0.0126, Val Loss: 0.0139\n",
      "Epoch 878, Train Loss: 0.0116, Val Loss: 0.0144\n",
      "Epoch 879, Train Loss: 0.0119, Val Loss: 0.0152\n",
      "Epoch 880, Train Loss: 0.0106, Val Loss: 0.0146\n",
      "Epoch 881, Train Loss: 0.0122, Val Loss: 0.0140\n",
      "Epoch 882, Train Loss: 0.0114, Val Loss: 0.0147\n",
      "Epoch 883, Train Loss: 0.0114, Val Loss: 0.0159\n",
      "Epoch 884, Train Loss: 0.0112, Val Loss: 0.0143\n",
      "Epoch 885, Train Loss: 0.0114, Val Loss: 0.0137\n",
      "Epoch 886, Train Loss: 0.0121, Val Loss: 0.0147\n",
      "Epoch 887, Train Loss: 0.0107, Val Loss: 0.0158\n",
      "Epoch 888, Train Loss: 0.0117, Val Loss: 0.0144\n",
      "Epoch 889, Train Loss: 0.0097, Val Loss: 0.0141\n",
      "Epoch 890, Train Loss: 0.0110, Val Loss: 0.0149\n",
      "Epoch 891, Train Loss: 0.0113, Val Loss: 0.0161\n",
      "Epoch 892, Train Loss: 0.0112, Val Loss: 0.0143\n",
      "Epoch 893, Train Loss: 0.0113, Val Loss: 0.0140\n",
      "Epoch 894, Train Loss: 0.0118, Val Loss: 0.0147\n",
      "Epoch 895, Train Loss: 0.0117, Val Loss: 0.0146\n",
      "Epoch 896, Train Loss: 0.0106, Val Loss: 0.0146\n",
      "Epoch 897, Train Loss: 0.0119, Val Loss: 0.0144\n",
      "Epoch 898, Train Loss: 0.0118, Val Loss: 0.0141\n",
      "Epoch 899, Train Loss: 0.0116, Val Loss: 0.0155\n",
      "Epoch 900, Train Loss: 0.0110, Val Loss: 0.0150\n",
      "Epoch 901, Train Loss: 0.0114, Val Loss: 0.0141\n",
      "Epoch 902, Train Loss: 0.0120, Val Loss: 0.0144\n",
      "Epoch 903, Train Loss: 0.0120, Val Loss: 0.0151\n",
      "Epoch 904, Train Loss: 0.0128, Val Loss: 0.0146\n",
      "Epoch 905, Train Loss: 0.0106, Val Loss: 0.0146\n",
      "Epoch 906, Train Loss: 0.0118, Val Loss: 0.0146\n",
      "Epoch 907, Train Loss: 0.0103, Val Loss: 0.0149\n",
      "Epoch 908, Train Loss: 0.0113, Val Loss: 0.0144\n",
      "Epoch 909, Train Loss: 0.0110, Val Loss: 0.0150\n",
      "Epoch 910, Train Loss: 0.0113, Val Loss: 0.0153\n",
      "Epoch 911, Train Loss: 0.0109, Val Loss: 0.0144\n",
      "Epoch 912, Train Loss: 0.0111, Val Loss: 0.0137\n",
      "Epoch 913, Train Loss: 0.0109, Val Loss: 0.0142\n",
      "Epoch 914, Train Loss: 0.0102, Val Loss: 0.0146\n",
      "Epoch 915, Train Loss: 0.0117, Val Loss: 0.0139\n",
      "Epoch 916, Train Loss: 0.0114, Val Loss: 0.0139\n",
      "Epoch 917, Train Loss: 0.0118, Val Loss: 0.0147\n",
      "Epoch 918, Train Loss: 0.0113, Val Loss: 0.0147\n",
      "Epoch 919, Train Loss: 0.0113, Val Loss: 0.0142\n",
      "Epoch 920, Train Loss: 0.0105, Val Loss: 0.0142\n",
      "Epoch 921, Train Loss: 0.0110, Val Loss: 0.0148\n",
      "Epoch 922, Train Loss: 0.0110, Val Loss: 0.0140\n",
      "Epoch 923, Train Loss: 0.0106, Val Loss: 0.0140\n",
      "Epoch 924, Train Loss: 0.0115, Val Loss: 0.0150\n",
      "Epoch 925, Train Loss: 0.0112, Val Loss: 0.0153\n",
      "Epoch 926, Train Loss: 0.0117, Val Loss: 0.0142\n",
      "Epoch 927, Train Loss: 0.0108, Val Loss: 0.0142\n",
      "Epoch 928, Train Loss: 0.0113, Val Loss: 0.0146\n",
      "Epoch 929, Train Loss: 0.0102, Val Loss: 0.0143\n",
      "Epoch 930, Train Loss: 0.0110, Val Loss: 0.0139\n",
      "Epoch 931, Train Loss: 0.0108, Val Loss: 0.0141\n",
      "Epoch 932, Train Loss: 0.0109, Val Loss: 0.0143\n",
      "Epoch 933, Train Loss: 0.0112, Val Loss: 0.0143\n",
      "Epoch 934, Train Loss: 0.0111, Val Loss: 0.0139\n",
      "Epoch 935, Train Loss: 0.0109, Val Loss: 0.0141\n",
      "Epoch 936, Train Loss: 0.0109, Val Loss: 0.0149\n",
      "Epoch 937, Train Loss: 0.0124, Val Loss: 0.0144\n",
      "Epoch 938, Train Loss: 0.0107, Val Loss: 0.0144\n",
      "Epoch 939, Train Loss: 0.0111, Val Loss: 0.0144\n",
      "Epoch 940, Train Loss: 0.0111, Val Loss: 0.0140\n",
      "Epoch 941, Train Loss: 0.0111, Val Loss: 0.0137\n",
      "Epoch 942, Train Loss: 0.0115, Val Loss: 0.0144\n",
      "Epoch 943, Train Loss: 0.0112, Val Loss: 0.0153\n",
      "Epoch 944, Train Loss: 0.0107, Val Loss: 0.0142\n",
      "Epoch 945, Train Loss: 0.0108, Val Loss: 0.0141\n",
      "Epoch 946, Train Loss: 0.0112, Val Loss: 0.0153\n",
      "Epoch 947, Train Loss: 0.0117, Val Loss: 0.0143\n",
      "Epoch 948, Train Loss: 0.0110, Val Loss: 0.0136\n",
      "Epoch 949, Train Loss: 0.0115, Val Loss: 0.0142\n",
      "Epoch 950, Train Loss: 0.0106, Val Loss: 0.0158\n",
      "Epoch 951, Train Loss: 0.0114, Val Loss: 0.0138\n",
      "Epoch 952, Train Loss: 0.0113, Val Loss: 0.0134\n",
      "Epoch 953, Train Loss: 0.0112, Val Loss: 0.0149\n",
      "Epoch 954, Train Loss: 0.0107, Val Loss: 0.0145\n",
      "Epoch 955, Train Loss: 0.0103, Val Loss: 0.0136\n",
      "Epoch 956, Train Loss: 0.0114, Val Loss: 0.0147\n",
      "Epoch 957, Train Loss: 0.0106, Val Loss: 0.0158\n",
      "Epoch 958, Train Loss: 0.0117, Val Loss: 0.0144\n",
      "Epoch 959, Train Loss: 0.0111, Val Loss: 0.0145\n",
      "Epoch 960, Train Loss: 0.0104, Val Loss: 0.0157\n",
      "Epoch 961, Train Loss: 0.0112, Val Loss: 0.0138\n",
      "Epoch 962, Train Loss: 0.0098, Val Loss: 0.0136\n",
      "Epoch 963, Train Loss: 0.0111, Val Loss: 0.0150\n",
      "Epoch 964, Train Loss: 0.0109, Val Loss: 0.0150\n",
      "Epoch 965, Train Loss: 0.0105, Val Loss: 0.0140\n",
      "Epoch 966, Train Loss: 0.0109, Val Loss: 0.0143\n",
      "Epoch 967, Train Loss: 0.0117, Val Loss: 0.0149\n",
      "Epoch 968, Train Loss: 0.0104, Val Loss: 0.0136\n",
      "Epoch 969, Train Loss: 0.0103, Val Loss: 0.0134\n",
      "Epoch 970, Train Loss: 0.0114, Val Loss: 0.0150\n",
      "Epoch 971, Train Loss: 0.0110, Val Loss: 0.0156\n",
      "Epoch 972, Train Loss: 0.0097, Val Loss: 0.0138\n",
      "Epoch 973, Train Loss: 0.0097, Val Loss: 0.0135\n",
      "Epoch 974, Train Loss: 0.0106, Val Loss: 0.0151\n",
      "Epoch 975, Train Loss: 0.0112, Val Loss: 0.0143\n",
      "Epoch 976, Train Loss: 0.0114, Val Loss: 0.0132\n",
      "Epoch 977, Train Loss: 0.0115, Val Loss: 0.0139\n",
      "Epoch 978, Train Loss: 0.0115, Val Loss: 0.0152\n",
      "Epoch 979, Train Loss: 0.0111, Val Loss: 0.0135\n",
      "Epoch 980, Train Loss: 0.0104, Val Loss: 0.0137\n",
      "Epoch 981, Train Loss: 0.0118, Val Loss: 0.0155\n",
      "Epoch 982, Train Loss: 0.0107, Val Loss: 0.0151\n",
      "Epoch 983, Train Loss: 0.0110, Val Loss: 0.0134\n",
      "Epoch 984, Train Loss: 0.0105, Val Loss: 0.0143\n",
      "Epoch 985, Train Loss: 0.0106, Val Loss: 0.0152\n",
      "Epoch 986, Train Loss: 0.0117, Val Loss: 0.0136\n",
      "Epoch 987, Train Loss: 0.0099, Val Loss: 0.0134\n",
      "Epoch 988, Train Loss: 0.0108, Val Loss: 0.0152\n",
      "Epoch 989, Train Loss: 0.0109, Val Loss: 0.0148\n",
      "Epoch 990, Train Loss: 0.0106, Val Loss: 0.0142\n",
      "Epoch 991, Train Loss: 0.0108, Val Loss: 0.0138\n",
      "Epoch 992, Train Loss: 0.0101, Val Loss: 0.0152\n",
      "Epoch 993, Train Loss: 0.0111, Val Loss: 0.0139\n",
      "Epoch 994, Train Loss: 0.0103, Val Loss: 0.0133\n",
      "Epoch 995, Train Loss: 0.0109, Val Loss: 0.0152\n",
      "Epoch 996, Train Loss: 0.0116, Val Loss: 0.0156\n",
      "Epoch 997, Train Loss: 0.0100, Val Loss: 0.0136\n",
      "Epoch 998, Train Loss: 0.0105, Val Loss: 0.0139\n",
      "Epoch 999, Train Loss: 0.0114, Val Loss: 0.0158\n",
      "Epoch 1000, Train Loss: 0.0108, Val Loss: 0.0149\n",
      "Epoch 1001, Train Loss: 0.0112, Val Loss: 0.0142\n",
      "Epoch 1002, Train Loss: 0.0111, Val Loss: 0.0138\n",
      "Epoch 1003, Train Loss: 0.0101, Val Loss: 0.0172\n",
      "Epoch 1004, Train Loss: 0.0123, Val Loss: 0.0142\n",
      "Epoch 1005, Train Loss: 0.0111, Val Loss: 0.0143\n",
      "Epoch 1006, Train Loss: 0.0120, Val Loss: 0.0154\n",
      "Epoch 1007, Train Loss: 0.0102, Val Loss: 0.0160\n",
      "Epoch 1008, Train Loss: 0.0111, Val Loss: 0.0136\n",
      "Epoch 1009, Train Loss: 0.0112, Val Loss: 0.0132\n",
      "Epoch 1010, Train Loss: 0.0116, Val Loss: 0.0150\n",
      "Epoch 1011, Train Loss: 0.0103, Val Loss: 0.0162\n",
      "Epoch 1012, Train Loss: 0.0113, Val Loss: 0.0141\n",
      "Epoch 1013, Train Loss: 0.0107, Val Loss: 0.0137\n",
      "Epoch 1014, Train Loss: 0.0110, Val Loss: 0.0146\n",
      "Epoch 1015, Train Loss: 0.0105, Val Loss: 0.0158\n",
      "Epoch 1016, Train Loss: 0.0114, Val Loss: 0.0139\n",
      "Epoch 1017, Train Loss: 0.0107, Val Loss: 0.0140\n",
      "Epoch 1018, Train Loss: 0.0108, Val Loss: 0.0141\n",
      "Epoch 1019, Train Loss: 0.0112, Val Loss: 0.0154\n",
      "Epoch 1020, Train Loss: 0.0107, Val Loss: 0.0140\n",
      "Epoch 1021, Train Loss: 0.0106, Val Loss: 0.0136\n",
      "Epoch 1022, Train Loss: 0.0106, Val Loss: 0.0144\n",
      "Epoch 1023, Train Loss: 0.0101, Val Loss: 0.0158\n",
      "Epoch 1024, Train Loss: 0.0116, Val Loss: 0.0143\n",
      "Epoch 1025, Train Loss: 0.0108, Val Loss: 0.0137\n",
      "Epoch 1026, Train Loss: 0.0101, Val Loss: 0.0143\n",
      "Epoch 1027, Train Loss: 0.0103, Val Loss: 0.0145\n",
      "Epoch 1028, Train Loss: 0.0109, Val Loss: 0.0141\n",
      "Epoch 1029, Train Loss: 0.0115, Val Loss: 0.0144\n",
      "Epoch 1030, Train Loss: 0.0118, Val Loss: 0.0146\n",
      "Epoch 1031, Train Loss: 0.0103, Val Loss: 0.0151\n",
      "Epoch 1032, Train Loss: 0.0112, Val Loss: 0.0142\n",
      "Epoch 1033, Train Loss: 0.0106, Val Loss: 0.0140\n",
      "Epoch 1034, Train Loss: 0.0099, Val Loss: 0.0149\n",
      "Epoch 1035, Train Loss: 0.0098, Val Loss: 0.0150\n",
      "Epoch 1036, Train Loss: 0.0115, Val Loss: 0.0136\n",
      "Epoch 1037, Train Loss: 0.0108, Val Loss: 0.0139\n",
      "Epoch 1038, Train Loss: 0.0104, Val Loss: 0.0146\n",
      "Epoch 1039, Train Loss: 0.0112, Val Loss: 0.0152\n",
      "Epoch 1040, Train Loss: 0.0113, Val Loss: 0.0144\n",
      "Epoch 1041, Train Loss: 0.0110, Val Loss: 0.0137\n",
      "Epoch 1042, Train Loss: 0.0110, Val Loss: 0.0155\n",
      "Epoch 1043, Train Loss: 0.0112, Val Loss: 0.0149\n",
      "Epoch 1044, Train Loss: 0.0105, Val Loss: 0.0146\n",
      "Epoch 1045, Train Loss: 0.0113, Val Loss: 0.0151\n",
      "Epoch 1046, Train Loss: 0.0115, Val Loss: 0.0153\n",
      "Epoch 1047, Train Loss: 0.0104, Val Loss: 0.0142\n",
      "Epoch 1048, Train Loss: 0.0108, Val Loss: 0.0131\n",
      "Epoch 1049, Train Loss: 0.0112, Val Loss: 0.0136\n",
      "Epoch 1050, Train Loss: 0.0103, Val Loss: 0.0155\n",
      "Epoch 1051, Train Loss: 0.0114, Val Loss: 0.0141\n",
      "Epoch 1052, Train Loss: 0.0102, Val Loss: 0.0135\n",
      "Epoch 1053, Train Loss: 0.0111, Val Loss: 0.0142\n",
      "Epoch 1054, Train Loss: 0.0105, Val Loss: 0.0160\n",
      "Epoch 1055, Train Loss: 0.0106, Val Loss: 0.0142\n",
      "Epoch 1056, Train Loss: 0.0098, Val Loss: 0.0135\n",
      "Epoch 1057, Train Loss: 0.0109, Val Loss: 0.0135\n",
      "Epoch 1058, Train Loss: 0.0098, Val Loss: 0.0149\n",
      "Epoch 1059, Train Loss: 0.0101, Val Loss: 0.0135\n",
      "Epoch 1060, Train Loss: 0.0098, Val Loss: 0.0133\n",
      "Epoch 1061, Train Loss: 0.0098, Val Loss: 0.0146\n",
      "Epoch 1062, Train Loss: 0.0097, Val Loss: 0.0156\n",
      "Epoch 1063, Train Loss: 0.0111, Val Loss: 0.0137\n",
      "Epoch 1064, Train Loss: 0.0110, Val Loss: 0.0136\n",
      "Epoch 1065, Train Loss: 0.0107, Val Loss: 0.0142\n",
      "Epoch 1066, Train Loss: 0.0103, Val Loss: 0.0150\n",
      "Epoch 1067, Train Loss: 0.0095, Val Loss: 0.0145\n",
      "Epoch 1068, Train Loss: 0.0101, Val Loss: 0.0137\n",
      "Epoch 1069, Train Loss: 0.0104, Val Loss: 0.0141\n",
      "Epoch 1070, Train Loss: 0.0107, Val Loss: 0.0149\n",
      "Epoch 1071, Train Loss: 0.0103, Val Loss: 0.0140\n",
      "Epoch 1072, Train Loss: 0.0097, Val Loss: 0.0145\n",
      "Epoch 1073, Train Loss: 0.0114, Val Loss: 0.0145\n",
      "Epoch 1074, Train Loss: 0.0107, Val Loss: 0.0145\n",
      "Epoch 1075, Train Loss: 0.0096, Val Loss: 0.0144\n",
      "Epoch 1076, Train Loss: 0.0107, Val Loss: 0.0138\n",
      "Epoch 1077, Train Loss: 0.0098, Val Loss: 0.0140\n",
      "Epoch 1078, Train Loss: 0.0107, Val Loss: 0.0145\n",
      "Epoch 1079, Train Loss: 0.0100, Val Loss: 0.0142\n",
      "Epoch 1080, Train Loss: 0.0103, Val Loss: 0.0133\n",
      "Epoch 1081, Train Loss: 0.0106, Val Loss: 0.0135\n",
      "Epoch 1082, Train Loss: 0.0099, Val Loss: 0.0144\n",
      "Epoch 1083, Train Loss: 0.0091, Val Loss: 0.0147\n",
      "Epoch 1084, Train Loss: 0.0105, Val Loss: 0.0137\n",
      "Epoch 1085, Train Loss: 0.0105, Val Loss: 0.0135\n",
      "Epoch 1086, Train Loss: 0.0105, Val Loss: 0.0143\n",
      "Epoch 1087, Train Loss: 0.0115, Val Loss: 0.0145\n",
      "Epoch 1088, Train Loss: 0.0099, Val Loss: 0.0143\n",
      "Epoch 1089, Train Loss: 0.0107, Val Loss: 0.0147\n",
      "Epoch 1090, Train Loss: 0.0103, Val Loss: 0.0141\n",
      "Epoch 1091, Train Loss: 0.0105, Val Loss: 0.0135\n",
      "Epoch 1092, Train Loss: 0.0097, Val Loss: 0.0134\n",
      "Epoch 1093, Train Loss: 0.0091, Val Loss: 0.0140\n",
      "Epoch 1094, Train Loss: 0.0095, Val Loss: 0.0146\n",
      "Epoch 1095, Train Loss: 0.0107, Val Loss: 0.0136\n",
      "Epoch 1096, Train Loss: 0.0110, Val Loss: 0.0138\n",
      "Epoch 1097, Train Loss: 0.0095, Val Loss: 0.0151\n",
      "Epoch 1098, Train Loss: 0.0118, Val Loss: 0.0147\n",
      "Epoch 1099, Train Loss: 0.0100, Val Loss: 0.0143\n",
      "Epoch 1100, Train Loss: 0.0097, Val Loss: 0.0141\n",
      "Epoch 1101, Train Loss: 0.0102, Val Loss: 0.0141\n",
      "Epoch 1102, Train Loss: 0.0100, Val Loss: 0.0138\n",
      "Epoch 1103, Train Loss: 0.0100, Val Loss: 0.0141\n",
      "Epoch 1104, Train Loss: 0.0102, Val Loss: 0.0140\n",
      "Epoch 1105, Train Loss: 0.0093, Val Loss: 0.0141\n",
      "Epoch 1106, Train Loss: 0.0099, Val Loss: 0.0140\n",
      "Epoch 1107, Train Loss: 0.0101, Val Loss: 0.0139\n",
      "Epoch 1108, Train Loss: 0.0105, Val Loss: 0.0142\n",
      "Epoch 1109, Train Loss: 0.0098, Val Loss: 0.0145\n",
      "Epoch 1110, Train Loss: 0.0109, Val Loss: 0.0137\n",
      "Epoch 1111, Train Loss: 0.0101, Val Loss: 0.0142\n",
      "Epoch 1112, Train Loss: 0.0098, Val Loss: 0.0142\n",
      "Epoch 1113, Train Loss: 0.0107, Val Loss: 0.0133\n",
      "Epoch 1114, Train Loss: 0.0092, Val Loss: 0.0134\n",
      "Epoch 1115, Train Loss: 0.0108, Val Loss: 0.0144\n",
      "Epoch 1116, Train Loss: 0.0112, Val Loss: 0.0139\n",
      "Epoch 1117, Train Loss: 0.0102, Val Loss: 0.0135\n",
      "Epoch 1118, Train Loss: 0.0106, Val Loss: 0.0142\n",
      "Epoch 1119, Train Loss: 0.0100, Val Loss: 0.0150\n",
      "Epoch 1120, Train Loss: 0.0105, Val Loss: 0.0141\n",
      "Epoch 1121, Train Loss: 0.0103, Val Loss: 0.0139\n",
      "Epoch 1122, Train Loss: 0.0104, Val Loss: 0.0143\n",
      "Epoch 1123, Train Loss: 0.0104, Val Loss: 0.0141\n",
      "Epoch 1124, Train Loss: 0.0103, Val Loss: 0.0132\n",
      "Epoch 1125, Train Loss: 0.0106, Val Loss: 0.0140\n",
      "Epoch 1126, Train Loss: 0.0097, Val Loss: 0.0152\n",
      "Epoch 1127, Train Loss: 0.0109, Val Loss: 0.0138\n",
      "Epoch 1128, Train Loss: 0.0091, Val Loss: 0.0135\n",
      "Epoch 1129, Train Loss: 0.0105, Val Loss: 0.0145\n",
      "Epoch 1130, Train Loss: 0.0105, Val Loss: 0.0145\n",
      "Epoch 1131, Train Loss: 0.0105, Val Loss: 0.0136\n",
      "Epoch 1132, Train Loss: 0.0111, Val Loss: 0.0135\n",
      "Epoch 1133, Train Loss: 0.0101, Val Loss: 0.0157\n",
      "Epoch 1134, Train Loss: 0.0115, Val Loss: 0.0143\n",
      "Epoch 1135, Train Loss: 0.0102, Val Loss: 0.0136\n",
      "Epoch 1136, Train Loss: 0.0101, Val Loss: 0.0142\n",
      "Epoch 1137, Train Loss: 0.0097, Val Loss: 0.0160\n",
      "Epoch 1138, Train Loss: 0.0108, Val Loss: 0.0145\n",
      "Epoch 1139, Train Loss: 0.0096, Val Loss: 0.0133\n",
      "Epoch 1140, Train Loss: 0.0113, Val Loss: 0.0137\n",
      "Epoch 1141, Train Loss: 0.0101, Val Loss: 0.0151\n",
      "Epoch 1142, Train Loss: 0.0113, Val Loss: 0.0140\n",
      "Epoch 1143, Train Loss: 0.0097, Val Loss: 0.0136\n",
      "Epoch 1144, Train Loss: 0.0115, Val Loss: 0.0142\n",
      "Epoch 1145, Train Loss: 0.0095, Val Loss: 0.0151\n",
      "Epoch 1146, Train Loss: 0.0096, Val Loss: 0.0134\n",
      "Epoch 1147, Train Loss: 0.0104, Val Loss: 0.0138\n",
      "Epoch 1148, Train Loss: 0.0102, Val Loss: 0.0154\n",
      "Epoch 1149, Train Loss: 0.0109, Val Loss: 0.0145\n",
      "Epoch 1150, Train Loss: 0.0110, Val Loss: 0.0134\n",
      "Epoch 1151, Train Loss: 0.0119, Val Loss: 0.0134\n",
      "Epoch 1152, Train Loss: 0.0110, Val Loss: 0.0150\n",
      "Epoch 1153, Train Loss: 0.0103, Val Loss: 0.0148\n",
      "Epoch 1154, Train Loss: 0.0102, Val Loss: 0.0132\n",
      "Epoch 1155, Train Loss: 0.0096, Val Loss: 0.0136\n",
      "Epoch 1156, Train Loss: 0.0115, Val Loss: 0.0152\n",
      "Epoch 1157, Train Loss: 0.0102, Val Loss: 0.0155\n",
      "Epoch 1158, Train Loss: 0.0108, Val Loss: 0.0144\n",
      "Epoch 1159, Train Loss: 0.0108, Val Loss: 0.0135\n",
      "Epoch 1160, Train Loss: 0.0103, Val Loss: 0.0141\n",
      "Epoch 1161, Train Loss: 0.0094, Val Loss: 0.0138\n",
      "Epoch 1162, Train Loss: 0.0100, Val Loss: 0.0137\n",
      "Epoch 1163, Train Loss: 0.0095, Val Loss: 0.0142\n",
      "Epoch 1164, Train Loss: 0.0109, Val Loss: 0.0151\n",
      "Epoch 1165, Train Loss: 0.0096, Val Loss: 0.0144\n",
      "Epoch 1166, Train Loss: 0.0092, Val Loss: 0.0135\n",
      "Epoch 1167, Train Loss: 0.0095, Val Loss: 0.0137\n",
      "Epoch 1168, Train Loss: 0.0098, Val Loss: 0.0155\n",
      "Epoch 1169, Train Loss: 0.0102, Val Loss: 0.0144\n",
      "Epoch 1170, Train Loss: 0.0095, Val Loss: 0.0136\n",
      "Epoch 1171, Train Loss: 0.0108, Val Loss: 0.0136\n",
      "Epoch 1172, Train Loss: 0.0098, Val Loss: 0.0153\n",
      "Epoch 1173, Train Loss: 0.0100, Val Loss: 0.0144\n",
      "Epoch 1174, Train Loss: 0.0096, Val Loss: 0.0142\n",
      "Epoch 1175, Train Loss: 0.0103, Val Loss: 0.0141\n",
      "Epoch 1176, Train Loss: 0.0099, Val Loss: 0.0143\n",
      "Epoch 1177, Train Loss: 0.0098, Val Loss: 0.0138\n",
      "Epoch 1178, Train Loss: 0.0094, Val Loss: 0.0134\n",
      "Epoch 1179, Train Loss: 0.0108, Val Loss: 0.0139\n",
      "Epoch 1180, Train Loss: 0.0100, Val Loss: 0.0154\n",
      "Epoch 1181, Train Loss: 0.0103, Val Loss: 0.0139\n",
      "Epoch 1182, Train Loss: 0.0094, Val Loss: 0.0135\n",
      "Epoch 1183, Train Loss: 0.0114, Val Loss: 0.0141\n",
      "Epoch 1184, Train Loss: 0.0089, Val Loss: 0.0154\n",
      "Epoch 1185, Train Loss: 0.0105, Val Loss: 0.0137\n",
      "Epoch 1186, Train Loss: 0.0091, Val Loss: 0.0135\n",
      "Epoch 1187, Train Loss: 0.0102, Val Loss: 0.0144\n",
      "Epoch 1188, Train Loss: 0.0098, Val Loss: 0.0147\n",
      "Epoch 1189, Train Loss: 0.0098, Val Loss: 0.0137\n",
      "Epoch 1190, Train Loss: 0.0097, Val Loss: 0.0137\n",
      "Epoch 1191, Train Loss: 0.0097, Val Loss: 0.0137\n",
      "Epoch 1192, Train Loss: 0.0106, Val Loss: 0.0137\n",
      "Epoch 1193, Train Loss: 0.0091, Val Loss: 0.0138\n",
      "Epoch 1194, Train Loss: 0.0094, Val Loss: 0.0143\n",
      "Epoch 1195, Train Loss: 0.0095, Val Loss: 0.0145\n",
      "Epoch 1196, Train Loss: 0.0096, Val Loss: 0.0138\n",
      "Epoch 1197, Train Loss: 0.0101, Val Loss: 0.0135\n",
      "Epoch 1198, Train Loss: 0.0104, Val Loss: 0.0139\n",
      "Epoch 1199, Train Loss: 0.0095, Val Loss: 0.0143\n",
      "Epoch 1200, Train Loss: 0.0101, Val Loss: 0.0135\n",
      "Epoch 1201, Train Loss: 0.0091, Val Loss: 0.0134\n",
      "Epoch 1202, Train Loss: 0.0097, Val Loss: 0.0144\n",
      "Epoch 1203, Train Loss: 0.0102, Val Loss: 0.0151\n",
      "Epoch 1204, Train Loss: 0.0098, Val Loss: 0.0143\n",
      "Epoch 1205, Train Loss: 0.0090, Val Loss: 0.0141\n",
      "Epoch 1206, Train Loss: 0.0100, Val Loss: 0.0139\n",
      "Epoch 1207, Train Loss: 0.0091, Val Loss: 0.0140\n",
      "Epoch 1208, Train Loss: 0.0103, Val Loss: 0.0144\n",
      "Epoch 1209, Train Loss: 0.0092, Val Loss: 0.0145\n",
      "Epoch 1210, Train Loss: 0.0099, Val Loss: 0.0141\n",
      "Epoch 1211, Train Loss: 0.0096, Val Loss: 0.0140\n",
      "Epoch 1212, Train Loss: 0.0094, Val Loss: 0.0141\n",
      "Epoch 1213, Train Loss: 0.0099, Val Loss: 0.0147\n",
      "Epoch 1214, Train Loss: 0.0100, Val Loss: 0.0142\n",
      "Epoch 1215, Train Loss: 0.0097, Val Loss: 0.0143\n",
      "Epoch 1216, Train Loss: 0.0091, Val Loss: 0.0140\n",
      "Epoch 1217, Train Loss: 0.0100, Val Loss: 0.0140\n",
      "Epoch 1218, Train Loss: 0.0094, Val Loss: 0.0145\n",
      "Epoch 1219, Train Loss: 0.0107, Val Loss: 0.0147\n",
      "Epoch 1220, Train Loss: 0.0105, Val Loss: 0.0140\n",
      "Epoch 1221, Train Loss: 0.0096, Val Loss: 0.0139\n",
      "Epoch 1222, Train Loss: 0.0103, Val Loss: 0.0149\n",
      "Epoch 1223, Train Loss: 0.0098, Val Loss: 0.0142\n",
      "Epoch 1224, Train Loss: 0.0098, Val Loss: 0.0136\n",
      "Epoch 1225, Train Loss: 0.0095, Val Loss: 0.0147\n",
      "Epoch 1226, Train Loss: 0.0103, Val Loss: 0.0143\n",
      "Epoch 1227, Train Loss: 0.0094, Val Loss: 0.0137\n",
      "Epoch 1228, Train Loss: 0.0095, Val Loss: 0.0138\n",
      "Epoch 1229, Train Loss: 0.0100, Val Loss: 0.0152\n",
      "Epoch 1230, Train Loss: 0.0095, Val Loss: 0.0145\n",
      "Epoch 1231, Train Loss: 0.0095, Val Loss: 0.0141\n",
      "Epoch 1232, Train Loss: 0.0101, Val Loss: 0.0148\n",
      "Epoch 1233, Train Loss: 0.0097, Val Loss: 0.0150\n",
      "Epoch 1234, Train Loss: 0.0099, Val Loss: 0.0140\n",
      "Epoch 1235, Train Loss: 0.0094, Val Loss: 0.0135\n",
      "Epoch 1236, Train Loss: 0.0103, Val Loss: 0.0133\n",
      "Epoch 1237, Train Loss: 0.0095, Val Loss: 0.0142\n",
      "Epoch 1238, Train Loss: 0.0102, Val Loss: 0.0144\n",
      "Epoch 1239, Train Loss: 0.0097, Val Loss: 0.0142\n",
      "Epoch 1240, Train Loss: 0.0095, Val Loss: 0.0146\n",
      "Epoch 1241, Train Loss: 0.0091, Val Loss: 0.0149\n",
      "Epoch 1242, Train Loss: 0.0098, Val Loss: 0.0146\n",
      "Epoch 1243, Train Loss: 0.0095, Val Loss: 0.0142\n",
      "Epoch 1244, Train Loss: 0.0099, Val Loss: 0.0137\n",
      "Epoch 1245, Train Loss: 0.0092, Val Loss: 0.0135\n",
      "Epoch 1246, Train Loss: 0.0096, Val Loss: 0.0135\n",
      "Epoch 1247, Train Loss: 0.0097, Val Loss: 0.0138\n",
      "Epoch 1248, Train Loss: 0.0089, Val Loss: 0.0145\n",
      "Epoch 1249, Train Loss: 0.0101, Val Loss: 0.0144\n",
      "Epoch 1250, Train Loss: 0.0098, Val Loss: 0.0143\n",
      "Epoch 1251, Train Loss: 0.0095, Val Loss: 0.0138\n",
      "Epoch 1252, Train Loss: 0.0098, Val Loss: 0.0143\n",
      "Epoch 1253, Train Loss: 0.0104, Val Loss: 0.0134\n",
      "Epoch 1254, Train Loss: 0.0100, Val Loss: 0.0133\n",
      "Epoch 1255, Train Loss: 0.0090, Val Loss: 0.0142\n",
      "Epoch 1256, Train Loss: 0.0098, Val Loss: 0.0148\n",
      "Epoch 1257, Train Loss: 0.0086, Val Loss: 0.0140\n",
      "Epoch 1258, Train Loss: 0.0096, Val Loss: 0.0141\n",
      "Epoch 1259, Train Loss: 0.0095, Val Loss: 0.0140\n",
      "Epoch 1260, Train Loss: 0.0094, Val Loss: 0.0142\n",
      "Epoch 1261, Train Loss: 0.0103, Val Loss: 0.0140\n",
      "Epoch 1262, Train Loss: 0.0100, Val Loss: 0.0137\n",
      "Epoch 1263, Train Loss: 0.0094, Val Loss: 0.0141\n",
      "Epoch 1264, Train Loss: 0.0096, Val Loss: 0.0138\n",
      "Epoch 1265, Train Loss: 0.0094, Val Loss: 0.0143\n",
      "Epoch 1266, Train Loss: 0.0100, Val Loss: 0.0143\n",
      "Epoch 1267, Train Loss: 0.0096, Val Loss: 0.0138\n",
      "Epoch 1268, Train Loss: 0.0090, Val Loss: 0.0139\n",
      "Epoch 1269, Train Loss: 0.0096, Val Loss: 0.0141\n",
      "Epoch 1270, Train Loss: 0.0094, Val Loss: 0.0144\n",
      "Epoch 1271, Train Loss: 0.0108, Val Loss: 0.0138\n",
      "Epoch 1272, Train Loss: 0.0099, Val Loss: 0.0138\n",
      "Epoch 1273, Train Loss: 0.0095, Val Loss: 0.0144\n",
      "Epoch 1274, Train Loss: 0.0098, Val Loss: 0.0139\n",
      "Epoch 1275, Train Loss: 0.0103, Val Loss: 0.0137\n",
      "Epoch 1276, Train Loss: 0.0096, Val Loss: 0.0146\n",
      "Epoch 1277, Train Loss: 0.0095, Val Loss: 0.0152\n",
      "Epoch 1278, Train Loss: 0.0092, Val Loss: 0.0137\n",
      "Epoch 1279, Train Loss: 0.0096, Val Loss: 0.0137\n",
      "Epoch 1280, Train Loss: 0.0088, Val Loss: 0.0142\n",
      "Epoch 1281, Train Loss: 0.0089, Val Loss: 0.0141\n",
      "Epoch 1282, Train Loss: 0.0093, Val Loss: 0.0138\n",
      "Epoch 1283, Train Loss: 0.0096, Val Loss: 0.0134\n",
      "Epoch 1284, Train Loss: 0.0097, Val Loss: 0.0139\n",
      "Epoch 1285, Train Loss: 0.0088, Val Loss: 0.0152\n",
      "Epoch 1286, Train Loss: 0.0097, Val Loss: 0.0142\n",
      "Epoch 1287, Train Loss: 0.0106, Val Loss: 0.0135\n",
      "Epoch 1288, Train Loss: 0.0096, Val Loss: 0.0145\n",
      "Epoch 1289, Train Loss: 0.0108, Val Loss: 0.0150\n",
      "Epoch 1290, Train Loss: 0.0100, Val Loss: 0.0141\n",
      "Epoch 1291, Train Loss: 0.0096, Val Loss: 0.0144\n",
      "Epoch 1292, Train Loss: 0.0096, Val Loss: 0.0145\n",
      "Epoch 1293, Train Loss: 0.0092, Val Loss: 0.0139\n",
      "Epoch 1294, Train Loss: 0.0097, Val Loss: 0.0135\n",
      "Epoch 1295, Train Loss: 0.0100, Val Loss: 0.0149\n",
      "Epoch 1296, Train Loss: 0.0100, Val Loss: 0.0138\n",
      "Epoch 1297, Train Loss: 0.0094, Val Loss: 0.0133\n",
      "Epoch 1298, Train Loss: 0.0101, Val Loss: 0.0141\n",
      "Epoch 1299, Train Loss: 0.0092, Val Loss: 0.0155\n",
      "Epoch 1300, Train Loss: 0.0104, Val Loss: 0.0140\n",
      "Epoch 1301, Train Loss: 0.0095, Val Loss: 0.0144\n",
      "Epoch 1302, Train Loss: 0.0102, Val Loss: 0.0151\n",
      "Epoch 1303, Train Loss: 0.0100, Val Loss: 0.0147\n",
      "Epoch 1304, Train Loss: 0.0103, Val Loss: 0.0132\n",
      "Epoch 1305, Train Loss: 0.0101, Val Loss: 0.0136\n",
      "Epoch 1306, Train Loss: 0.0102, Val Loss: 0.0165\n",
      "Epoch 1307, Train Loss: 0.0101, Val Loss: 0.0150\n",
      "Epoch 1308, Train Loss: 0.0097, Val Loss: 0.0138\n",
      "Epoch 1309, Train Loss: 0.0113, Val Loss: 0.0139\n",
      "Epoch 1310, Train Loss: 0.0097, Val Loss: 0.0160\n",
      "Epoch 1311, Train Loss: 0.0106, Val Loss: 0.0135\n",
      "Epoch 1312, Train Loss: 0.0100, Val Loss: 0.0137\n",
      "Epoch 1313, Train Loss: 0.0103, Val Loss: 0.0141\n",
      "Epoch 1314, Train Loss: 0.0095, Val Loss: 0.0151\n",
      "Epoch 1315, Train Loss: 0.0101, Val Loss: 0.0138\n",
      "Epoch 1316, Train Loss: 0.0103, Val Loss: 0.0138\n",
      "Epoch 1317, Train Loss: 0.0101, Val Loss: 0.0146\n",
      "Epoch 1318, Train Loss: 0.0097, Val Loss: 0.0144\n",
      "Epoch 1319, Train Loss: 0.0096, Val Loss: 0.0137\n",
      "Epoch 1320, Train Loss: 0.0102, Val Loss: 0.0138\n",
      "Epoch 1321, Train Loss: 0.0094, Val Loss: 0.0140\n",
      "Epoch 1322, Train Loss: 0.0102, Val Loss: 0.0145\n",
      "Epoch 1323, Train Loss: 0.0088, Val Loss: 0.0143\n",
      "Epoch 1324, Train Loss: 0.0092, Val Loss: 0.0140\n",
      "Epoch 1325, Train Loss: 0.0091, Val Loss: 0.0142\n",
      "Epoch 1326, Train Loss: 0.0097, Val Loss: 0.0151\n",
      "Epoch 1327, Train Loss: 0.0091, Val Loss: 0.0143\n",
      "Epoch 1328, Train Loss: 0.0090, Val Loss: 0.0137\n",
      "Epoch 1329, Train Loss: 0.0102, Val Loss: 0.0145\n",
      "Epoch 1330, Train Loss: 0.0097, Val Loss: 0.0147\n",
      "Epoch 1331, Train Loss: 0.0095, Val Loss: 0.0144\n",
      "Epoch 1332, Train Loss: 0.0098, Val Loss: 0.0144\n",
      "Epoch 1333, Train Loss: 0.0100, Val Loss: 0.0147\n",
      "Epoch 1334, Train Loss: 0.0091, Val Loss: 0.0145\n",
      "Epoch 1335, Train Loss: 0.0099, Val Loss: 0.0137\n",
      "Epoch 1336, Train Loss: 0.0089, Val Loss: 0.0138\n",
      "Epoch 1337, Train Loss: 0.0102, Val Loss: 0.0150\n",
      "Epoch 1338, Train Loss: 0.0097, Val Loss: 0.0144\n",
      "Epoch 1339, Train Loss: 0.0090, Val Loss: 0.0139\n",
      "Epoch 1340, Train Loss: 0.0094, Val Loss: 0.0146\n",
      "Epoch 1341, Train Loss: 0.0092, Val Loss: 0.0156\n",
      "Epoch 1342, Train Loss: 0.0100, Val Loss: 0.0142\n",
      "Epoch 1343, Train Loss: 0.0092, Val Loss: 0.0141\n",
      "Epoch 1344, Train Loss: 0.0096, Val Loss: 0.0150\n",
      "Epoch 1345, Train Loss: 0.0092, Val Loss: 0.0137\n",
      "Epoch 1346, Train Loss: 0.0088, Val Loss: 0.0133\n",
      "Epoch 1347, Train Loss: 0.0089, Val Loss: 0.0137\n",
      "Epoch 1348, Train Loss: 0.0086, Val Loss: 0.0146\n",
      "Epoch 1349, Train Loss: 0.0103, Val Loss: 0.0143\n",
      "Epoch 1350, Train Loss: 0.0098, Val Loss: 0.0139\n",
      "Epoch 1351, Train Loss: 0.0102, Val Loss: 0.0142\n",
      "Epoch 1352, Train Loss: 0.0101, Val Loss: 0.0149\n",
      "Epoch 1353, Train Loss: 0.0098, Val Loss: 0.0139\n",
      "Epoch 1354, Train Loss: 0.0094, Val Loss: 0.0138\n",
      "Epoch 1355, Train Loss: 0.0092, Val Loss: 0.0146\n",
      "Epoch 1356, Train Loss: 0.0100, Val Loss: 0.0146\n",
      "Epoch 1357, Train Loss: 0.0090, Val Loss: 0.0138\n",
      "Epoch 1358, Train Loss: 0.0098, Val Loss: 0.0137\n",
      "Epoch 1359, Train Loss: 0.0097, Val Loss: 0.0144\n",
      "Epoch 1360, Train Loss: 0.0092, Val Loss: 0.0146\n",
      "Epoch 1361, Train Loss: 0.0089, Val Loss: 0.0141\n",
      "Epoch 1362, Train Loss: 0.0091, Val Loss: 0.0142\n",
      "Epoch 1363, Train Loss: 0.0092, Val Loss: 0.0148\n",
      "Epoch 1364, Train Loss: 0.0088, Val Loss: 0.0144\n",
      "Epoch 1365, Train Loss: 0.0095, Val Loss: 0.0139\n",
      "Epoch 1366, Train Loss: 0.0098, Val Loss: 0.0140\n",
      "Epoch 1367, Train Loss: 0.0091, Val Loss: 0.0141\n",
      "Epoch 1368, Train Loss: 0.0096, Val Loss: 0.0135\n",
      "Epoch 1369, Train Loss: 0.0090, Val Loss: 0.0141\n",
      "Epoch 1370, Train Loss: 0.0100, Val Loss: 0.0150\n",
      "Epoch 1371, Train Loss: 0.0090, Val Loss: 0.0148\n",
      "Epoch 1372, Train Loss: 0.0091, Val Loss: 0.0142\n",
      "Epoch 1373, Train Loss: 0.0091, Val Loss: 0.0138\n",
      "Epoch 1374, Train Loss: 0.0087, Val Loss: 0.0143\n",
      "Epoch 1375, Train Loss: 0.0096, Val Loss: 0.0142\n",
      "Epoch 1376, Train Loss: 0.0088, Val Loss: 0.0135\n",
      "Epoch 1377, Train Loss: 0.0089, Val Loss: 0.0138\n",
      "Epoch 1378, Train Loss: 0.0093, Val Loss: 0.0147\n",
      "Epoch 1379, Train Loss: 0.0104, Val Loss: 0.0143\n",
      "Epoch 1380, Train Loss: 0.0096, Val Loss: 0.0141\n",
      "Epoch 1381, Train Loss: 0.0095, Val Loss: 0.0143\n",
      "Epoch 1382, Train Loss: 0.0099, Val Loss: 0.0149\n",
      "Epoch 1383, Train Loss: 0.0104, Val Loss: 0.0139\n",
      "Epoch 1384, Train Loss: 0.0085, Val Loss: 0.0137\n",
      "Epoch 1385, Train Loss: 0.0093, Val Loss: 0.0145\n",
      "Epoch 1386, Train Loss: 0.0094, Val Loss: 0.0151\n",
      "Epoch 1387, Train Loss: 0.0094, Val Loss: 0.0141\n",
      "Epoch 1388, Train Loss: 0.0101, Val Loss: 0.0140\n",
      "Epoch 1389, Train Loss: 0.0100, Val Loss: 0.0149\n",
      "Epoch 1390, Train Loss: 0.0091, Val Loss: 0.0150\n",
      "Epoch 1391, Train Loss: 0.0097, Val Loss: 0.0144\n",
      "Epoch 1392, Train Loss: 0.0094, Val Loss: 0.0142\n",
      "Epoch 1393, Train Loss: 0.0089, Val Loss: 0.0142\n",
      "Epoch 1394, Train Loss: 0.0095, Val Loss: 0.0136\n",
      "Epoch 1395, Train Loss: 0.0101, Val Loss: 0.0136\n",
      "Epoch 1396, Train Loss: 0.0094, Val Loss: 0.0146\n",
      "Epoch 1397, Train Loss: 0.0096, Val Loss: 0.0149\n",
      "Epoch 1398, Train Loss: 0.0098, Val Loss: 0.0141\n",
      "Epoch 1399, Train Loss: 0.0105, Val Loss: 0.0139\n",
      "Epoch 1400, Train Loss: 0.0092, Val Loss: 0.0145\n",
      "Epoch 1401, Train Loss: 0.0090, Val Loss: 0.0146\n",
      "Epoch 1402, Train Loss: 0.0102, Val Loss: 0.0134\n",
      "Epoch 1403, Train Loss: 0.0093, Val Loss: 0.0136\n",
      "Epoch 1404, Train Loss: 0.0099, Val Loss: 0.0145\n",
      "Epoch 1405, Train Loss: 0.0095, Val Loss: 0.0140\n",
      "Epoch 1406, Train Loss: 0.0096, Val Loss: 0.0144\n",
      "Epoch 1407, Train Loss: 0.0097, Val Loss: 0.0151\n",
      "Epoch 1408, Train Loss: 0.0094, Val Loss: 0.0147\n",
      "Epoch 1409, Train Loss: 0.0093, Val Loss: 0.0140\n",
      "Epoch 1410, Train Loss: 0.0096, Val Loss: 0.0137\n",
      "Epoch 1411, Train Loss: 0.0098, Val Loss: 0.0139\n",
      "Epoch 1412, Train Loss: 0.0093, Val Loss: 0.0140\n",
      "Epoch 1413, Train Loss: 0.0095, Val Loss: 0.0137\n",
      "Epoch 1414, Train Loss: 0.0099, Val Loss: 0.0145\n",
      "Epoch 1415, Train Loss: 0.0085, Val Loss: 0.0145\n",
      "Epoch 1416, Train Loss: 0.0096, Val Loss: 0.0141\n",
      "Epoch 1417, Train Loss: 0.0096, Val Loss: 0.0140\n",
      "Epoch 1418, Train Loss: 0.0088, Val Loss: 0.0146\n",
      "Epoch 1419, Train Loss: 0.0093, Val Loss: 0.0140\n",
      "Epoch 1420, Train Loss: 0.0089, Val Loss: 0.0138\n",
      "Epoch 1421, Train Loss: 0.0096, Val Loss: 0.0147\n",
      "Epoch 1422, Train Loss: 0.0096, Val Loss: 0.0152\n",
      "Epoch 1423, Train Loss: 0.0098, Val Loss: 0.0142\n",
      "Epoch 1424, Train Loss: 0.0087, Val Loss: 0.0140\n",
      "Epoch 1425, Train Loss: 0.0097, Val Loss: 0.0151\n",
      "Epoch 1426, Train Loss: 0.0092, Val Loss: 0.0147\n",
      "Epoch 1427, Train Loss: 0.0093, Val Loss: 0.0145\n",
      "Epoch 1428, Train Loss: 0.0106, Val Loss: 0.0145\n",
      "Epoch 1429, Train Loss: 0.0091, Val Loss: 0.0155\n",
      "Epoch 1430, Train Loss: 0.0096, Val Loss: 0.0140\n",
      "Epoch 1431, Train Loss: 0.0097, Val Loss: 0.0139\n",
      "Epoch 1432, Train Loss: 0.0097, Val Loss: 0.0156\n",
      "Epoch 1433, Train Loss: 0.0099, Val Loss: 0.0150\n",
      "Epoch 1434, Train Loss: 0.0096, Val Loss: 0.0136\n",
      "Epoch 1435, Train Loss: 0.0091, Val Loss: 0.0138\n",
      "Epoch 1436, Train Loss: 0.0089, Val Loss: 0.0145\n",
      "Epoch 1437, Train Loss: 0.0099, Val Loss: 0.0143\n",
      "Epoch 1438, Train Loss: 0.0097, Val Loss: 0.0138\n",
      "Epoch 1439, Train Loss: 0.0088, Val Loss: 0.0141\n",
      "Epoch 1440, Train Loss: 0.0090, Val Loss: 0.0150\n",
      "Epoch 1441, Train Loss: 0.0090, Val Loss: 0.0143\n",
      "Epoch 1442, Train Loss: 0.0094, Val Loss: 0.0140\n",
      "Epoch 1443, Train Loss: 0.0094, Val Loss: 0.0141\n",
      "Epoch 1444, Train Loss: 0.0098, Val Loss: 0.0147\n",
      "Epoch 1445, Train Loss: 0.0098, Val Loss: 0.0139\n",
      "Epoch 1446, Train Loss: 0.0090, Val Loss: 0.0142\n",
      "Epoch 1447, Train Loss: 0.0095, Val Loss: 0.0152\n",
      "Epoch 1448, Train Loss: 0.0095, Val Loss: 0.0147\n",
      "Epoch 1449, Train Loss: 0.0090, Val Loss: 0.0142\n",
      "Epoch 1450, Train Loss: 0.0096, Val Loss: 0.0140\n",
      "Epoch 1451, Train Loss: 0.0093, Val Loss: 0.0143\n",
      "Epoch 1452, Train Loss: 0.0092, Val Loss: 0.0143\n",
      "Epoch 1453, Train Loss: 0.0087, Val Loss: 0.0142\n",
      "Epoch 1454, Train Loss: 0.0091, Val Loss: 0.0144\n",
      "Epoch 1455, Train Loss: 0.0088, Val Loss: 0.0145\n",
      "Epoch 1456, Train Loss: 0.0091, Val Loss: 0.0143\n",
      "Epoch 1457, Train Loss: 0.0089, Val Loss: 0.0141\n",
      "Epoch 1458, Train Loss: 0.0094, Val Loss: 0.0142\n",
      "Epoch 1459, Train Loss: 0.0090, Val Loss: 0.0144\n",
      "Epoch 1460, Train Loss: 0.0093, Val Loss: 0.0142\n",
      "Epoch 1461, Train Loss: 0.0090, Val Loss: 0.0141\n",
      "Epoch 1462, Train Loss: 0.0095, Val Loss: 0.0143\n",
      "Epoch 1463, Train Loss: 0.0094, Val Loss: 0.0148\n",
      "Epoch 1464, Train Loss: 0.0102, Val Loss: 0.0139\n",
      "Epoch 1465, Train Loss: 0.0093, Val Loss: 0.0141\n",
      "Epoch 1466, Train Loss: 0.0087, Val Loss: 0.0149\n",
      "Epoch 1467, Train Loss: 0.0094, Val Loss: 0.0142\n",
      "Epoch 1468, Train Loss: 0.0084, Val Loss: 0.0140\n",
      "Epoch 1469, Train Loss: 0.0095, Val Loss: 0.0146\n",
      "Epoch 1470, Train Loss: 0.0088, Val Loss: 0.0144\n",
      "Epoch 1471, Train Loss: 0.0091, Val Loss: 0.0143\n",
      "Epoch 1472, Train Loss: 0.0097, Val Loss: 0.0140\n",
      "Epoch 1473, Train Loss: 0.0092, Val Loss: 0.0140\n",
      "Epoch 1474, Train Loss: 0.0088, Val Loss: 0.0146\n",
      "Epoch 1475, Train Loss: 0.0094, Val Loss: 0.0147\n",
      "Epoch 1476, Train Loss: 0.0097, Val Loss: 0.0138\n",
      "Epoch 1477, Train Loss: 0.0091, Val Loss: 0.0144\n",
      "Epoch 1478, Train Loss: 0.0089, Val Loss: 0.0152\n",
      "Epoch 1479, Train Loss: 0.0098, Val Loss: 0.0143\n",
      "Epoch 1480, Train Loss: 0.0092, Val Loss: 0.0139\n",
      "Epoch 1481, Train Loss: 0.0092, Val Loss: 0.0143\n",
      "Epoch 1482, Train Loss: 0.0098, Val Loss: 0.0141\n",
      "Epoch 1483, Train Loss: 0.0083, Val Loss: 0.0143\n",
      "Epoch 1484, Train Loss: 0.0089, Val Loss: 0.0148\n",
      "Epoch 1485, Train Loss: 0.0094, Val Loss: 0.0147\n",
      "Epoch 1486, Train Loss: 0.0086, Val Loss: 0.0143\n",
      "Epoch 1487, Train Loss: 0.0094, Val Loss: 0.0147\n",
      "Epoch 1488, Train Loss: 0.0091, Val Loss: 0.0144\n",
      "Epoch 1489, Train Loss: 0.0092, Val Loss: 0.0139\n",
      "Epoch 1490, Train Loss: 0.0091, Val Loss: 0.0142\n",
      "Epoch 1491, Train Loss: 0.0098, Val Loss: 0.0140\n",
      "Epoch 1492, Train Loss: 0.0098, Val Loss: 0.0143\n",
      "Epoch 1493, Train Loss: 0.0090, Val Loss: 0.0145\n",
      "Epoch 1494, Train Loss: 0.0088, Val Loss: 0.0147\n",
      "Epoch 1495, Train Loss: 0.0090, Val Loss: 0.0145\n",
      "Epoch 1496, Train Loss: 0.0096, Val Loss: 0.0141\n",
      "Epoch 1497, Train Loss: 0.0091, Val Loss: 0.0146\n",
      "Epoch 1498, Train Loss: 0.0085, Val Loss: 0.0144\n",
      "Epoch 1499, Train Loss: 0.0095, Val Loss: 0.0140\n",
      "Epoch 1500, Train Loss: 0.0086, Val Loss: 0.0139\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1500\n",
    "early_stopping = EarlyStopper(min_steps=200, mem_ratio=0.9, threshold=0.1)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    # if early_stopping.early_stop(val_loss):\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0134\n",
      "Std: 0.1417\n",
      "Error Range: 0.8158\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    loss = criterion(outputs, y_test)\n",
    "    std = y_test.std()\n",
    "    print(f'Test Loss: {loss.item():.4f}')\n",
    "    print(f'Std: {std:.4f}')\n",
    "    print(f'Error Range: {loss.sqrt() / std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
