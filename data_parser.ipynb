{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0675fa9e-bd26-4f82-b5d5-5b0a0a7133ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "285f02f4-2c48-4d97-8d11-98b314dc69be",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = 'https://api.polygon.io/v2'\n",
    "apiKey = 'LQeVT4355IbDNjGP2HKvAFlagtPfJPL4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d9c3060-31f3-44fa-864e-d178cc4f1ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_stock(ticker, start, end):\n",
    "    url = f'{baseUrl}/aggs/ticker/{ticker}/range/1/day/{start}/{end}?apiKey={apiKey}'\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Request Stock Error {resp.status_code}\")\n",
    "        return None\n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f13201fb-4483-4ea4-8803-168e22bc6d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(tickers):\n",
    "    rsl = {}\n",
    "    for i in range(len(tickers)):\n",
    "        if i > 0 and i % 5 == 0:\n",
    "            print(\"wait 60 secs...\")\n",
    "            time.sleep(60)\n",
    "        resp = request_stock(tickers[i], '2022-01-01', '2024-12-31')\n",
    "        df = pd.DataFrame(resp['results'])\n",
    "        df['t'] = pd.to_datetime(df['t'], unit='ms')\n",
    "        df.columns = ['volumn', 'vwap', 'open', 'close', 'high', 'low', 'time', 'num_trades']\n",
    "        rsl[tickers[i]] = df\n",
    "    return rsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f83523-6495-4fbd-b2f2-d9deb1530e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL', 'MSFT', 'IBM', 'ORCL', 'NVDA', 'INTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85438b3e-5154-456c-b679-f780c17de6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait 60 secs...\n"
     ]
    }
   ],
   "source": [
    "stock_dfs = get_csv(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959b8d77-43bd-44af-8b6f-b93a77584bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in stock_dfs.items():\n",
    "    df.to_csv(f'dataset/stocks/{key}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cc88078-1fc7-4428-aaa4-471c81743cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_news(ticker, end='2024-12-31'):\n",
    "    url = f'{baseUrl}/reference/news?ticker={ticker}&published_utc.lte={end}&limit=1000&apiKey={apiKey}'\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Request News Error {resp.status_code}\")\n",
    "        return None\n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1c1f66d-ed70-438c-9b4d-2e9c392e6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(ticker):\n",
    "    main_list = []\n",
    "    relation_list = []\n",
    "    last_date = '2024-12-31'\n",
    "    for i in range(100):\n",
    "        if i > 0 and i % 5 == 0:\n",
    "            print(\"wait 60 secs...\")\n",
    "            time.sleep(60)\n",
    "        raw_data = request_news(ticker, last_date)['results']\n",
    "        last_date = raw_data[-1]['published_utc'][:10]\n",
    "        \n",
    "        for item in raw_data:\n",
    "            if item['published_utc'].startswith(last_date):\n",
    "                break\n",
    "            item['ticker'] = ticker\n",
    "            item['publish_time'] = datetime.fromisoformat(item['published_utc'][:-1])\n",
    "            item['publisher'] = item['publisher']['name'] if 'publisher' in item else \"\"\n",
    "            item['keywords'] = \",\".join(item['keywords']) if 'keywords' in item else \"\"\n",
    "            \n",
    "            main_cols = ['id', 'publish_time', 'title', 'article_url', \n",
    "                         'ticker', 'publisher', 'description', 'keywords']\n",
    "            main_list.append({k: item[k] if k in item else \"\" for k in main_cols})\n",
    "            \n",
    "            if 'insights' in item:\n",
    "                for relation in item['insights']:\n",
    "                    relation['news_id'] = item['id']\n",
    "                    relation['source_ticker'] = item['ticker']\n",
    "                    relation['time'] = item['publish_time']\n",
    "                    relation_list.append(relation)\n",
    "        if len(raw_data) < 1000 or last_date < '2022-11-01':\n",
    "            break\n",
    "    main_df = pd.DataFrame(main_list)\n",
    "    relation_df = pd.DataFrame(relation_list)\n",
    "    return main_df, relation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8681704-73b2-423c-87be-f552f322e513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n",
      "wait 60 secs...\n"
     ]
    }
   ],
   "source": [
    "news_main_dfs = {}\n",
    "news_relation_dfs = {}\n",
    "for i in range(len(tickers)):\n",
    "    main_df, relation_df = get_news(tickers[i])\n",
    "    news_main_dfs[tickers[i]] = main_df\n",
    "    news_relation_dfs[tickers[i]] = relation_df\n",
    "    if i < len(tickers) - 1:\n",
    "        print(\"wait 60 secs...\")\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c8f699a-3652-4bc8-941b-c2601454ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in news_main_dfs.items():\n",
    "    df.to_csv(f'dataset/news/{key}_main.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab804542-6a5c-417c-b38c-c45bd118e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in news_relation_dfs.items():\n",
    "    df.to_csv(f'dataset/news/{key}_relation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312dad59-f404-4af0-a1b7-76fcb0f6ec2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
