{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903365a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test finBERT outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30bc945",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d05513da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa609c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL', 'MSFT', 'IBM', 'ORCL', 'NVDA', 'INTC']\n",
    "original_data = \"dataset/news\"\n",
    "new_data = \"dataset/polygon_title_sentiment\"\n",
    "start_time = \"2024-07-01\"\n",
    "end_time = \"2024-09-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6401aca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META: 178 / 379\n",
      "AAPL: 321 / 663\n",
      "AMZN: 344 / 767\n",
      "NFLX: 81 / 147\n",
      "GOOGL: 288 / 671\n",
      "MSFT: 343 / 722\n",
      "IBM: 104 / 150\n",
      "ORCL: 98 / 145\n",
      "NVDA: 631 / 1272\n",
      "INTC: 136 / 268\n"
     ]
    }
   ],
   "source": [
    "merged_dfs = []\n",
    "for ticker in tickers:\n",
    "#     old_df_news = pd.read_csv(f\"{original_data}/{ticker}_main.csv\")\n",
    "    old_df_rela = pd.read_csv(f\"{original_data}/{ticker}_relation.csv\")\n",
    "    new_df = pd.read_csv(f\"{new_data}/{ticker}_title_sentiments.csv\")\n",
    "    filtered_rela = old_df_rela[old_df_rela['ticker'] == old_df_rela['source_ticker']]\n",
    "#     print(new_df)\n",
    "#     print(filtered_rela)\n",
    "    merged_df = pd.merge(new_df, filtered_rela, on=\"news_id\", how=\"left\")\n",
    "    # print(merged_df)\n",
    "#     merged_df = merged_df[(merged_df[\"time_x\"] >= start_time) & (merged_df[\"time_x\"] <= end_time)]\n",
    "    merged_df = merged_df.dropna()\n",
    "    # print(merged_df)\n",
    "    correct_val = len(merged_df[merged_df[\"sentiment_x\"] == merged_df[\"sentiment_y\"]])\n",
    "    total_val = len(merged_df)\n",
    "    print(f\"{ticker}: {correct_val} / {total_val}\")\n",
    "    merged_dfs.append(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f256dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL', 'MSFT', 'IBM', 'ORCL', 'NVDA', 'INTC']\n",
    "original_data = \"dataset/news\"\n",
    "new_data = \"dataset/polygon_title_sentiment_2\"\n",
    "start_time = \"2024-07-01\"\n",
    "end_time = \"2024-09-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40ba48fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META: 178 / 379\n",
      "AAPL: 321 / 663\n",
      "AMZN: 344 / 767\n",
      "NFLX: 81 / 147\n",
      "GOOGL: 288 / 671\n",
      "MSFT: 343 / 722\n",
      "IBM: 104 / 150\n",
      "ORCL: 98 / 145\n",
      "NVDA: 631 / 1272\n",
      "INTC: 136 / 268\n"
     ]
    }
   ],
   "source": [
    "merged_dfs = []\n",
    "for ticker in tickers:\n",
    "#     old_df_news = pd.read_csv(f\"{original_data}/{ticker}_main.csv\")\n",
    "    old_df_rela = pd.read_csv(f\"{original_data}/{ticker}_relation.csv\")\n",
    "    new_df = pd.read_csv(f\"{new_data}/{ticker}_title_sentiments.csv\")\n",
    "    filtered_rela = old_df_rela[old_df_rela['ticker'] == old_df_rela['source_ticker']]\n",
    "#     print(new_df)\n",
    "#     print(filtered_rela)\n",
    "    merged_df = pd.merge(new_df, filtered_rela, on=\"news_id\", how=\"left\")\n",
    "    # print(merged_df)\n",
    "#     merged_df = merged_df[(merged_df[\"time_x\"] >= start_time) & (merged_df[\"time_x\"] <= end_time)]\n",
    "    merged_df = merged_df.dropna()\n",
    "    # print(merged_df)\n",
    "    correct_val = len(merged_df[merged_df[\"sentiment_x\"] == merged_df[\"sentiment_y\"]])\n",
    "    total_val = len(merged_df)\n",
    "    print(f\"{ticker}: {correct_val} / {total_val}\")\n",
    "    merged_dfs.append(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52479052",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL', 'MSFT', 'IBM', 'ORCL', 'NVDA', 'INTC']\n",
    "original_data = \"dataset/news\"\n",
    "new_data = \"dataset/polygon_title_sentiment_3\"\n",
    "start_time = \"2024-07-01\"\n",
    "end_time = \"2024-09-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d79c3a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META: 178 / 379\n",
      "AAPL: 321 / 663\n",
      "AMZN: 344 / 767\n",
      "NFLX: 81 / 147\n",
      "GOOGL: 288 / 671\n",
      "MSFT: 343 / 722\n",
      "IBM: 104 / 150\n",
      "ORCL: 98 / 145\n",
      "NVDA: 631 / 1272\n",
      "INTC: 136 / 268\n"
     ]
    }
   ],
   "source": [
    "merged_dfs = []\n",
    "for ticker in tickers:\n",
    "#     old_df_news = pd.read_csv(f\"{original_data}/{ticker}_main.csv\")\n",
    "    old_df_rela = pd.read_csv(f\"{original_data}/{ticker}_relation.csv\")\n",
    "    new_df = pd.read_csv(f\"{new_data}/{ticker}_title_sentiments.csv\")\n",
    "    filtered_rela = old_df_rela[old_df_rela['ticker'] == old_df_rela['source_ticker']]\n",
    "#     print(new_df)\n",
    "#     print(filtered_rela)\n",
    "    merged_df = pd.merge(new_df, filtered_rela, on=\"news_id\", how=\"left\")\n",
    "    # print(merged_df)\n",
    "#     merged_df = merged_df[(merged_df[\"time_x\"] >= start_time) & (merged_df[\"time_x\"] <= end_time)]\n",
    "    merged_df = merged_df.dropna()\n",
    "    # print(merged_df)\n",
    "    correct_val = len(merged_df[merged_df[\"sentiment_x\"] == merged_df[\"sentiment_y\"]])\n",
    "    total_val = len(merged_df)\n",
    "    print(f\"{ticker}: {correct_val} / {total_val}\")\n",
    "    merged_dfs.append(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "daf78943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker_x sentiment_x  sentiment_score  \\\n",
      "0       META    positive         0.823642   \n",
      "1       META    positive         0.793241   \n",
      "2       META     neutral         0.933679   \n",
      "3       META    positive         0.793828   \n",
      "4       META    positive         0.799031   \n",
      "..       ...         ...              ...   \n",
      "374     META    positive         0.936538   \n",
      "375     META    positive         0.922167   \n",
      "376     META     neutral         0.852299   \n",
      "377     META     neutral         0.906837   \n",
      "378     META    positive         0.944227   \n",
      "\n",
      "                                               news_id               time_x  \\\n",
      "0    1d9a233266513e7565c8aa26700bc8a7fad1acb0eb8f8f...  2024-10-31 04:26:28   \n",
      "1    40f6f17a31ea6dce828171990cd72377669fa26cabd02b...  2024-10-30 08:57:00   \n",
      "2    73b4269117fe7fd0fa590192ba9f9f02d679451ed01ba3...  2024-10-28 13:12:33   \n",
      "3    f915e8aa2b9ca173f97217e3e20c823c846a9efba9db16...  2024-10-28 09:37:00   \n",
      "4    4d4e504f51033ab67f1ac8848dec47d44d11f1f2206107...  2024-10-27 11:52:00   \n",
      "..                                                 ...                  ...   \n",
      "374  b54e93d1a3408f0158f5432d0e8ea2bdfd871329c01eb4...  2024-07-03 12:45:00   \n",
      "375  59138833ea343b4497e5a0c00be01d6a5d475e9fe0bc4d...  2024-07-03 09:49:00   \n",
      "376  c6a0195a94b70970dbe9c85e757374edec5329b2a8a149...  2024-07-03 09:29:00   \n",
      "377  292756ba7e603a197e999f984e4f020f4c4c6424411b51...  2024-07-03 09:15:00   \n",
      "378  21be967fb343c874cf942b9abe2cb4089d4500c43dc31b...  2024-07-02 18:31:08   \n",
      "\n",
      "                                                 title  \\\n",
      "0    AMD CEO Lisa Su: No 'One Size Fits All' In $50...   \n",
      "1    46% of Nvidia's Revenue Came From 4 Mystery Cu...   \n",
      "2      This Week Is Crucial for Nvidia Stock Investors   \n",
      "3    This 1 Simple ETF Could Turn $250 a Month Into...   \n",
      "4      What Is the Dividend Payout for Meta Platforms?   \n",
      "..                                                 ...   \n",
      "374  The Nasdaq is Up 20% Halfway Through 2024. Her...   \n",
      "375  These 4 Vanguard ETFs Soared Over 20% in the F...   \n",
      "376  2 Unstoppable Vanguard ETFs to Buy With $700 D...   \n",
      "377  3 Top Tech Stocks to Buy in July - The Motley ...   \n",
      "378  Broadcom Up 24% in a Month: How to Play AVGO A...   \n",
      "\n",
      "                                           article_url ticker_y sentiment_y  \\\n",
      "0    https://www.benzinga.com/markets/equities/24/1...     META     neutral   \n",
      "1    https://www.fool.com/investing/2024/10/30/46-n...     META    positive   \n",
      "2    https://www.fool.com/investing/2024/10/28/this...     META     neutral   \n",
      "3    https://www.fool.com/investing/2024/10/28/this...     META    positive   \n",
      "4    https://www.fool.com/investing/2024/10/27/what...     META    positive   \n",
      "..                                                 ...      ...         ...   \n",
      "374  https://www.fool.com/investing/2024/07/03/the-...     META    positive   \n",
      "375  https://www.fool.com/investing/2024/07/03/thes...     META    positive   \n",
      "376  https://www.fool.com/investing/2024/07/03/vang...     META     neutral   \n",
      "377  https://www.fool.com/investing/2024/07/03/3-to...     META    positive   \n",
      "378  https://www.zacks.com/stock/news/2296379/broad...     META    positive   \n",
      "\n",
      "                                   sentiment_reasoning source_ticker  \\\n",
      "0    The article mentions Meta Platforms' developme...          META   \n",
      "1    Meta Platforms is planning to spend up to $40 ...          META   \n",
      "2    The article mentions that a former director of...          META   \n",
      "3    Meta Platforms is one of the seven most valuab...          META   \n",
      "4    The article highlights that Meta Platforms has...          META   \n",
      "..                                                 ...           ...   \n",
      "374  The Nasdaq Composite index, which tracks the p...          META   \n",
      "375  Meta Platforms is a top holding in all the Van...          META   \n",
      "376  The article does not provide any specific info...          META   \n",
      "377  Meta Platforms aims to become an AI leader, in...          META   \n",
      "378  Meta Platforms has also become an important cu...          META   \n",
      "\n",
      "                  time_y  \n",
      "0    2024-10-31 04:26:28  \n",
      "1    2024-10-30 08:57:00  \n",
      "2    2024-10-28 13:12:33  \n",
      "3    2024-10-28 09:37:00  \n",
      "4    2024-10-27 11:52:00  \n",
      "..                   ...  \n",
      "374  2024-07-03 12:45:00  \n",
      "375  2024-07-03 09:49:00  \n",
      "376  2024-07-03 09:29:00  \n",
      "377  2024-07-03 09:15:00  \n",
      "378  2024-07-02 18:31:08  \n",
      "\n",
      "[379 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_dfs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2306a80",
   "metadata": {},
   "source": [
    "Comparing data between old and new with averaged scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0df3694",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_1 = \"dataset/polygon_title_sentiment\"\n",
    "new_data_2 = \"dataset/polygon_title_sentiment_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2943e271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sentiment           sentiment_score          \n",
      "          self     other            self     other\n",
      "466   positive  negative        0.711180 -0.319964\n",
      "474   positive  negative        0.891433 -0.515851\n",
      "614   positive  negative        0.825404 -0.255227\n",
      "621   positive  negative        0.907342  0.005383\n",
      "764        NaN       NaN        0.872426  0.298928\n",
      "...        ...       ...             ...       ...\n",
      "6481  positive  negative        0.743996 -0.381865\n",
      "6601  positive  negative        0.771556 -0.531506\n",
      "6625  positive  negative        0.835485 -0.158694\n",
      "6673  positive  negative        0.751891 -0.362421\n",
      "6735       NaN       NaN        0.771394  0.668098\n",
      "\n",
      "[91 rows x 4 columns]\n",
      "     sentiment           sentiment_score          \n",
      "          self     other            self     other\n",
      "863   positive  negative        0.711180 -0.319964\n",
      "887   positive  negative        0.891433 -0.515851\n",
      "1146  positive  negative        0.825404 -0.255227\n",
      "1157  positive  negative        0.907342  0.005383\n",
      "1252  positive  negative        0.922170 -0.204906\n",
      "...        ...       ...             ...       ...\n",
      "9053  positive  negative        0.895608 -0.895608\n",
      "9463  positive  negative        0.932825 -0.527749\n",
      "9596       NaN       NaN        0.811575  0.205716\n",
      "9622       NaN       NaN        0.925066  0.678834\n",
      "9765  positive  negative        0.764307 -0.361849\n",
      "\n",
      "[74 rows x 4 columns]\n",
      "      sentiment           sentiment_score          \n",
      "           self     other            self     other\n",
      "954    positive  negative        0.711180 -0.319964\n",
      "963    positive  negative        0.891433 -0.515851\n",
      "1077   positive  negative        0.815658 -0.452915\n",
      "1239   positive  negative        0.825404 -0.255227\n",
      "1251   positive  negative        0.907342  0.005383\n",
      "...         ...       ...             ...       ...\n",
      "10478       NaN       NaN        0.925066  0.678834\n",
      "10748  positive  negative        0.771556 -0.531506\n",
      "10771  positive  negative        0.832436  0.023202\n",
      "10790  positive  negative        0.835485 -0.158694\n",
      "10819       NaN       NaN        0.803393  0.479780\n",
      "\n",
      "[77 rows x 4 columns]\n",
      "     sentiment           sentiment_score          \n",
      "          self     other            self     other\n",
      "406   positive  negative        0.823610 -0.365524\n",
      "1069       NaN       NaN        0.762314  0.491594\n",
      "1075  positive  negative        0.682213 -0.436039\n",
      "1144  positive  negative        0.670117 -0.303326\n",
      "1146  positive  negative        0.858955 -0.061776\n",
      "1170  positive  negative        0.699473 -0.316545\n",
      "1172  positive  negative        0.749817 -0.151216\n",
      "1197  positive  negative        0.686757 -0.117848\n",
      "1309  positive  negative        0.704641 -0.162431\n",
      "1415  positive  negative        0.737416 -0.315056\n",
      "1554  positive  negative        0.743452 -0.273674\n",
      "1667       NaN       NaN        0.806473  0.598185\n",
      "1846  positive  negative        0.805237 -0.237318\n",
      "1876       NaN       NaN        0.843227  0.275621\n",
      "1968  positive  negative        0.895494  0.000000\n",
      "1997  positive  negative        0.722737 -0.121114\n",
      "2029       NaN       NaN        0.810658  0.530367\n",
      "2160       NaN       NaN        0.715036  0.229785\n",
      "2284  positive  negative        0.839298  0.070045\n",
      "2422  positive  negative        0.679213 -0.264867\n",
      "2719  positive  negative        0.808302 -0.183844\n",
      "2761  positive  negative        0.895608 -0.895608\n",
      "2828  positive  negative        0.679304 -0.582285\n",
      "2879       NaN       NaN        0.859002  0.555996\n",
      "2900  positive  negative        0.804800 -0.652185\n",
      "     sentiment           sentiment_score          \n",
      "          self     other            self     other\n",
      "716   positive  negative        0.812705  0.000000\n",
      "1367       NaN       NaN        0.909701  0.629386\n",
      "1380       NaN       NaN        0.872426  0.298928\n",
      "1391  positive  negative        0.869315 -0.072933\n",
      "1399  positive  negative        0.863573 -0.663355\n",
      "1808       NaN       NaN        0.925298  0.206729\n",
      "2389       NaN       NaN        0.947492  0.466832\n",
      "2589       NaN       NaN        0.934644  0.551812\n",
      "3013  positive  negative        0.726897 -0.342548\n",
      "3054       NaN       NaN        0.945751  0.555352\n",
      "3460       NaN       NaN        0.894370  0.629727\n",
      "3497  positive  negative        0.636580 -0.163634\n",
      "3640  positive  negative        0.858955 -0.061776\n",
      "3733       NaN       NaN        0.694484  0.451256\n",
      "3816  positive  negative        0.686757 -0.117848\n",
      "3846       NaN       NaN        0.861025  0.718868\n",
      "3990       NaN       NaN        0.937652  0.747459\n",
      "4174  positive  negative        0.649600 -0.093177\n",
      "4433       NaN       NaN        0.920832  0.585092\n",
      "4436  positive  negative        0.820640 -0.328787\n",
      "4691  positive  negative        0.913402 -0.479433\n",
      "4759       NaN       NaN        0.744896  0.151782\n",
      "4770  positive  negative        0.774728 -0.374127\n",
      "5438  positive  negative        0.853890 -0.057661\n",
      "5728  positive  negative        0.819080 -0.051595\n",
      "5751  positive  negative        0.895494  0.000000\n",
      "5911  positive  negative        0.862574 -0.734816\n",
      "5952  positive  negative        0.719471 -0.101452\n",
      "6759  positive  negative        0.880871 -0.602564\n",
      "6850  positive  negative        0.679213 -0.264867\n",
      "7067       NaN       NaN        0.744318  0.277741\n",
      "7179       NaN       NaN        0.865986  0.272607\n",
      "7272  positive  negative        0.808302 -0.183844\n",
      "7858  positive  negative        0.771556 -0.531506\n",
      "7870  positive  negative        0.832436  0.023202\n",
      "7877  positive  negative        0.835485 -0.158694\n",
      "     sentiment           sentiment_score          \n",
      "          self     other            self     other\n",
      "932   positive  negative        0.711180 -0.319964\n",
      "947   positive  negative        0.891433 -0.515851\n",
      "1267  positive  negative        0.825404 -0.255227\n",
      "1278  positive  negative        0.907342  0.005383\n",
      "1474       NaN       NaN        0.835013  0.543822\n",
      "...        ...       ...             ...       ...\n",
      "8687  positive  negative        0.808302 -0.183844\n",
      "8732       NaN       NaN        0.884076  0.654713\n",
      "8739       NaN       NaN        0.934338  0.777886\n",
      "8756  positive  negative        0.895608 -0.895608\n",
      "8816  positive  negative        0.752395 -0.636743\n",
      "\n",
      "[74 rows x 4 columns]\n",
      "     sentiment           sentiment_score          \n",
      "          self     other            self     other\n",
      "190   positive  negative        0.856786 -0.150143\n",
      "194        NaN       NaN        0.921071  0.306974\n",
      "237   positive  negative        0.863573 -0.663355\n",
      "246        NaN       NaN        0.917154  0.346889\n",
      "416        NaN       NaN        0.932491  0.201078\n",
      "702   positive  negative        0.689207 -0.208185\n",
      "838   positive  negative        0.672114 -0.181227\n",
      "980   positive  negative        0.856677 -0.576290\n",
      "1093  positive  negative        0.764614 -0.244181\n",
      "1120       NaN       NaN        0.886437  0.626151\n",
      "1161  positive  negative        0.804271 -0.733448\n",
      "1167  positive  negative        0.774543 -0.398282\n",
      "1401  positive  negative        0.900881  0.000000\n",
      "1648  positive  negative        0.750596 -0.513778\n",
      "1821       NaN       NaN        0.862053  0.399870\n",
      "1841  positive  negative        0.938224 -0.938224\n",
      "1853  positive  negative        0.734562 -0.174933\n",
      "1874       NaN       NaN        0.930333  0.380176\n",
      "1892  positive  negative        0.929998 -0.387193\n",
      "1895  positive  negative        0.868273 -0.074562\n",
      "1910  positive  negative        0.938374 -0.157638\n",
      "     sentiment           sentiment_score          \n",
      "          self     other            self     other\n",
      "302   positive  negative        0.859520  0.000000\n",
      "388        NaN       NaN        0.801053  0.121705\n",
      "406        NaN       NaN        0.935449  0.197739\n",
      "542        NaN       NaN        0.824316  0.336899\n",
      "641        NaN       NaN        0.809567  0.504836\n",
      "660   positive  negative        0.779153 -0.547277\n",
      "717   positive  negative        0.697235 -0.505374\n",
      "722   positive  negative        0.631808 -0.214400\n",
      "726   positive  negative        0.858924 -0.623225\n",
      "738        NaN       NaN        0.914694  0.734558\n",
      "744   positive  negative        0.843681 -0.588161\n",
      "768   positive  negative        0.804814 -0.292151\n",
      "783   positive  negative        0.733034 -0.219002\n",
      "797   positive  negative        0.594261 -0.315005\n",
      "911        NaN       NaN        0.914780  0.502726\n",
      "916   positive  negative        0.592445 -0.268792\n",
      "939   positive  negative        0.702944 -0.083615\n",
      "1154  positive  negative        0.774543 -0.398282\n",
      "1162  positive  negative        0.647863 -0.328774\n",
      "1164  positive  negative        0.686960 -0.256678\n",
      "1168  positive  negative        0.806884 -0.452102\n",
      "1283  positive  negative        0.724374 -0.292106\n",
      "1333  positive  negative        0.783866 -0.534451\n",
      "1409  positive  negative        0.743733 -0.483432\n",
      "1563  positive  negative        0.721991 -0.296360\n",
      "1588  positive  negative        0.796667 -0.361944\n",
      "1612  positive  negative        0.871159 -0.121361\n",
      "1734  positive  negative        0.848863  0.000000\n",
      "1750  positive  negative        0.929998 -0.387193\n",
      "1831  positive  negative        0.766542 -0.503558\n",
      "1844  positive  negative        0.903386 -0.793621\n",
      "1869  positive  negative        0.753945 -0.100574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sentiment           sentiment_score          \n",
      "           self     other            self     other\n",
      "1308   positive  negative        0.852683 -0.327602\n",
      "1781   positive  negative        0.711180 -0.319964\n",
      "1811   positive  negative        0.891433 -0.515851\n",
      "2000        NaN       NaN        0.891097  0.187251\n",
      "2251        NaN       NaN        0.748015  0.299043\n",
      "...         ...       ...             ...       ...\n",
      "10833  positive  negative        0.738271 -0.165730\n",
      "11177  positive  negative        0.731132 -0.119553\n",
      "11289  positive  negative        0.735044 -0.511112\n",
      "11424  positive  negative        0.818876 -0.549222\n",
      "11685       NaN       NaN        0.925066  0.678834\n",
      "\n",
      "[82 rows x 4 columns]\n",
      "     sentiment           sentiment_score          \n",
      "          self     other            self     other\n",
      "428   positive  negative        0.766203 -0.293093\n",
      "501   positive  negative        0.826460 -0.690952\n",
      "509        NaN       NaN        0.872426  0.298928\n",
      "521   positive  negative        0.863573 -0.663355\n",
      "648        NaN       NaN        0.926014  0.539500\n",
      "840   positive  negative        0.921314 -0.006484\n",
      "842   positive  negative        0.807679  0.092906\n",
      "929   positive  negative        0.918266  0.025649\n",
      "965   positive  negative        0.710604 -0.194574\n",
      "995   positive  negative        0.783676  0.000000\n",
      "1391       NaN       NaN        0.867849  0.690246\n",
      "1517  positive  negative        0.749817 -0.151216\n",
      "1624  positive  negative        0.804814 -0.292151\n",
      "1787       NaN       NaN        0.784710  0.286712\n",
      "1842  positive  negative        0.810372 -0.559075\n",
      "1917       NaN       NaN        0.744896  0.151782\n",
      "2042       NaN       NaN        0.828095  0.601868\n",
      "2071       NaN       NaN        0.926840  0.358503\n",
      "2126  positive  negative        0.774324 -0.079698\n",
      "2159  positive  negative        0.708666 -0.184424\n",
      "2174       NaN       NaN        0.912055  0.389291\n",
      "2256  positive  negative        0.784323 -0.211336\n",
      "2316  positive  negative        0.663660  0.051649\n",
      "2354  positive  negative        0.835850 -0.146514\n",
      "2380  positive  negative        0.738271 -0.165730\n",
      "2831  positive  negative        0.808302 -0.183844\n",
      "2883  positive  negative        0.673234 -0.410702\n",
      "2906  positive  negative        0.756374 -0.482221\n",
      "2937  positive  negative        0.752633 -0.360823\n",
      "2958  positive  negative        0.932825 -0.527749\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    df_1 = pd.read_csv(f\"{new_data_1}/{ticker}_title_sentiments.csv\")\n",
    "    df_2 = pd.read_csv(f\"{new_data_2}/{ticker}_title_sentiments.csv\")\n",
    "    \n",
    "    df_diff = df_1.compare(df_2, align_axis=1)\n",
    "#     columns = [\"sentiment\", \"sentiment_score\", \"news_id\"]\n",
    "    \n",
    "#     print(df_diff[columns])\n",
    "    print(df_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e83dd4",
   "metadata": {},
   "source": [
    "Compare data with old average scores and new with negative set to negative scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "74751703",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_3 = \"dataset/polygon_title_sentiment_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d2876ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    df_2 = pd.read_csv(f\"{new_data_2}/{ticker}_title_sentiments.csv\")\n",
    "    df_3 = pd.read_csv(f\"{new_data_3}/{ticker}_title_sentiments.csv\")\n",
    "    df_2.drop('sentiment_score', axis=1, inplace=True)\n",
    "    df_3.drop('sentiment_score', axis=1, inplace=True)\n",
    "    df_diff = df_2.compare(df_3, align_axis=1)\n",
    "#     columns = [\"sentiment\", \"sentiment_score\", \"news_id\"]\n",
    "    \n",
    "#     print(df_diff[columns])\n",
    "    print(df_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2890c970",
   "metadata": {},
   "source": [
    "Below are for a separate test not for title data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea8b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe9e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_csv('dataset/news/AAPL_main.csv')\n",
    "df_rela = pd.read_csv('dataset/AAPL_rel_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d4f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aapl = pd.read_csv('dataset/stocks/AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae268d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news_t = df_rela[df_rela['ticker'] == df_rela['source_ticker']]\n",
    "df_news_t['time'] = pd.to_datetime(df_news_t['time']).dt.tz_localize(\"UTC\") \\\n",
    "                    .dt.tz_convert(\"America/New_York\")\n",
    "df_news_t['sentiment'] = df_news_t['sentiment'].map(\n",
    "    {'neutral':0, 'positive':1, 'negative':-4.22} # maybe\n",
    ")\n",
    "df_news_t['date'] = df_news_t['time'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "339f015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_senti = df_news_t.groupby('date')['sentiment'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad93d6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/kv5wlvmd4wdc2_bz7dkwlj180000gn/T/ipykernel_51877/3429688966.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_aapl_t['time'] = pd.to_datetime(df_aapl_t['time']).dt.tz_localize(\"UTC\") \\\n",
      "/var/folders/0q/kv5wlvmd4wdc2_bz7dkwlj180000gn/T/ipykernel_51877/3429688966.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_aapl_t['change'] = df_aapl['close'].diff()\n",
      "/var/folders/0q/kv5wlvmd4wdc2_bz7dkwlj180000gn/T/ipykernel_51877/3429688966.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_aapl_t['date'] = df_aapl_t['time'].dt.date\n"
     ]
    }
   ],
   "source": [
    "df_aapl_t = df_aapl[df_aapl['time'] >= \"2024-07-02\"]\n",
    "df_aapl_t['time'] = pd.to_datetime(df_aapl_t['time']).dt.tz_localize(\"UTC\") \\\n",
    "                    .dt.tz_convert(\"America/New_York\")\n",
    "df_aapl_t['change'] = df_aapl['close'].diff()\n",
    "df_aapl_t['date'] = df_aapl_t['time'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96b2fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stock = df_aapl_t[['date', 'change']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b848d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_corr = pd.merge(s_stock, s_senti, on=\"date\", how=\"left\")\n",
    "s_corr['sentiment'] = s_corr['sentiment'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3167ed8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.06728981144642374, pvalue=0.5430744928395074)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(s_corr['change'], s_corr['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6af656be",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(len(s_corr) * 0.8)\n",
    "s_corr_train = s_corr.iloc[:split_index] \n",
    "s_corr_test = s_corr.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "926fb1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0572883252716194, 0.20694630541925169)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(s_corr_train[['sentiment']], s_corr_train['change'])\n",
    "model.coef_[0], model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014224b",
   "metadata": {},
   "source": [
    "Confusion matrix for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4bdcaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL', 'MSFT', 'IBM', 'ORCL', 'NVDA', 'INTC']\n",
    "original_data = \"dataset/news\"\n",
    "new_data = \"dataset/polygon_title_sentiment_3\"\n",
    "start_time = \"2024-07-01\"\n",
    "end_time = \"2024-09-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78294a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_to_time(df, start_time, end_time):\n",
    "    return df[(df['time'] >= start_time) & (df['time'] <= end_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e2f2272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_confusion_matrix(ticker, old_data, new_data):\n",
    "#     old_data[\"old_sentiment\"] = old_data[\"sentiment\"]\n",
    "#     new_data[\"new_sentiment\"] = new_data[\"sentiment\"]\n",
    "\n",
    "#     old_data.drop('sentiment', axis=1, inplace=True)\n",
    "#     new_data.drop('sentiment', axis=1, inplace=True)\n",
    "    merged_df = pd.merge(old_data, new_data, on=\"news_id\", how=\"left\")\n",
    "    # print(merged_df)\n",
    "    merged_df.dropna(subset=[\"old_sentiment\", \"new_sentiment\"])\n",
    "    \n",
    "    cross_tab = pd.crosstab(\n",
    "        merged_df[\"old_sentiment\"],\n",
    "        merged_df[\"new_sentiment\"],\n",
    "        rownames=[\"Old Sentiment\"],\n",
    "        colnames=[\"New Sentiment\"]\n",
    "    )\n",
    "    print(ticker)\n",
    "    print(cross_tab)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38e4cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_confusion_matrix(ticker, old_data, new_data):\n",
    "    merged_df = pd.merge(old_data, new_data, on=\"news_id\", how=\"left\")\n",
    "    merged_df.dropna(subset=[\"old_sentiment\", \"new_sentiment\"])\n",
    "    \n",
    "    # Define possible sentiment categories\n",
    "    sentiments = [\"positive\", \"neutral\", \"negative\"]\n",
    "    \n",
    "    # Initialize the confusion matrix as a dictionary of dictionaries\n",
    "    confusion_matrix = {old: {new: 0 for new in sentiments} for old in sentiments}\n",
    "    \n",
    "    # Populate the confusion matrix\n",
    "    for _, row in merged_df.iterrows():\n",
    "        old = row[\"old_sentiment\"]\n",
    "        new = row[\"new_sentiment\"]\n",
    "        if old in sentiments and new in sentiments:\n",
    "            confusion_matrix[old][new] += 1\n",
    "    \n",
    "    # Convert the dictionary-based confusion matrix to a DataFrame\n",
    "    confusion_matrix_df = pd.DataFrame(confusion_matrix).T  # Transpose for correct layout\n",
    "    \n",
    "    confusion_matrix_df.index.name = \"Old Sentiment (Row)\"\n",
    "    confusion_matrix_df.columns.name = \"New Sentiment (Column)\"\n",
    "    \n",
    "    # Print ticker label and confusion matrix\n",
    "    print(f\"Confusion Matrix for {ticker}:\")\n",
    "    print(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c3d0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old =c\n",
    "df_new = pd.read_csv(f\"{new_data}/AAPL_title_sentiments.csv\")\n",
    "\n",
    "\n",
    "df_old = df_old[df_old['ticker'] == df_old['source_ticker']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33043b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n",
      "New Sentiment  negative  neutral  positive\n",
      "Old Sentiment                             \n",
      "bearish               0        1         0\n",
      "hold                  0        1         0\n",
      "negative             53       25        10\n",
      "neutral              42       84        76\n",
      "positive             31      156       184\n"
     ]
    }
   ],
   "source": [
    "check_confusion_matrix(\"AAPL\", df_old, df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0fb54f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL', 'MSFT', 'IBM', 'ORCL', 'NVDA', 'INTC']\n",
    "original_data = \"dataset/news\"\n",
    "new_data_dir_1 = \"dataset/polygon_title_sentiment\"\n",
    "new_data_dir_2 = \"dataset/polygon_title_sentiment_2\"\n",
    "new_data_dir_3 = \"dataset/polygon_title_sentiment_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb01e822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for META:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                      94       96        25\n",
      "neutral                       34       58        27\n",
      "negative                       9        9        26\n",
      "Confusion Matrix for AAPL:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                     184      156        31\n",
      "neutral                       76       84        42\n",
      "negative                      10       25        53\n",
      "Confusion Matrix for AMZN:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                     244      209        42\n",
      "neutral                       89       67        53\n",
      "negative                      11       12        33\n",
      "Confusion Matrix for NFLX:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                      60       34         4\n",
      "neutral                       15       14        13\n",
      "negative                       0        0         7\n",
      "Confusion Matrix for GOOGL:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                     192      153        48\n",
      "neutral                       98       65        56\n",
      "negative                       8       15        31\n",
      "Confusion Matrix for MSFT:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                     244      169        41\n",
      "neutral                       93       54        58\n",
      "negative                       6       10        45\n",
      "Confusion Matrix for IBM:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                      94       21         3\n",
      "neutral                       17        9         3\n",
      "negative                       1        1         1\n",
      "Confusion Matrix for ORCL:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                      91       21         4\n",
      "neutral                       13        5         4\n",
      "negative                       1        4         2\n",
      "Confusion Matrix for NVDA:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                     394      253       105\n",
      "neutral                      135      126        76\n",
      "negative                      24       46       111\n",
      "Confusion Matrix for INTC:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                      62       28        17\n",
      "neutral                       34       28        27\n",
      "negative                      15       11        46\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    old_data =  pd.read_csv(f\"{original_data}/{ticker}_relation.csv\")\n",
    "#     new_data_1 = pd.read_csv(f\"{new_data_dir_1}/{ticker}_title_sentiments.csv\")\n",
    "#     new_data_2 = pd.read_csv(f\"{new_data_dir_2}/{ticker}_title_sentiments.csv\")\n",
    "    new_data_3 = pd.read_csv(f\"{new_data_dir_3}/{ticker}_title_sentiments.csv\")\n",
    "    \n",
    "    old_data = old_data[old_data['ticker'] == old_data['source_ticker']]\n",
    "    \n",
    "    old_data[\"old_sentiment\"] = old_data[\"sentiment\"]\n",
    "#     new_data_1[\"new_sentiment\"] = new_data_1[\"sentiment\"]\n",
    "#     new_data_2[\"new_sentiment\"] = new_data_2[\"sentiment\"]\n",
    "    new_data_3[\"new_sentiment\"] = new_data_3[\"sentiment\"]\n",
    "\n",
    "\n",
    "    old_data.drop('sentiment', axis=1, inplace=True)\n",
    "#     new_data_1.drop('sentiment', axis=1, inplace=True)\n",
    "#     new_data_2.drop('sentiment', axis=1, inplace=True)\n",
    "    new_data_3.drop('sentiment', axis=1, inplace=True)\n",
    "    \n",
    "#     print(\"first data\")\n",
    "#     check_confusion_matrix(ticker, old_data, new_data_1)\n",
    "#     print(\"second data\")\n",
    "#     check_confusion_matrix(ticker, old_data, new_data_2)\n",
    "#     print(\"third data\")\n",
    "    check_confusion_matrix(ticker, old_data, new_data_3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd0edc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for TEST:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                       1        1         0\n",
      "neutral                        0        0         1\n",
      "negative                       0        0         1\n"
     ]
    }
   ],
   "source": [
    "old_data = pd.DataFrame({\n",
    "    \"news_id\": [1, 2, 3, 4],\n",
    "    \"old_sentiment\": [\"positive\", \"neutral\", \"negative\", \"positive\"]\n",
    "})\n",
    "new_data = pd.DataFrame({\n",
    "    \"news_id\": [1, 2, 3, 4],\n",
    "    \"new_sentiment\": [\"positive\", \"negative\", \"negative\", \"neutral\"]\n",
    "})\n",
    "\n",
    "check_confusion_matrix(\"TEST\", old_data, new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb825af8",
   "metadata": {},
   "source": [
    "Comparing labels originated from using all article texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3cf16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['META', 'NFLX', 'IBM', 'ORCL', 'INTC']\n",
    "original_data = \"dataset/news\"\n",
    "new_data_dir = \"dataset/polygon_total_sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e786c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for META:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                      81       98        11\n",
      "neutral                       33       49        11\n",
      "negative                       4       12        18\n",
      "Confusion Matrix for NFLX:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                      48       27         1\n",
      "neutral                       10       26         5\n",
      "negative                       0        1         4\n",
      "Confusion Matrix for IBM:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                      25       75         1\n",
      "neutral                        3       22         2\n",
      "negative                       0        0         3\n",
      "Confusion Matrix for ORCL:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                      47       50         4\n",
      "neutral                        4       13         2\n",
      "negative                       0        1         3\n",
      "Confusion Matrix for INTC:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                      41       41        12\n",
      "neutral                       23       40        19\n",
      "negative                       9        7        56\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    old_data =  pd.read_csv(f\"{original_data}/{ticker}_relation.csv\")\n",
    "    new_data = pd.read_csv(f\"{new_data_dir}/{ticker}_total_sentiments.csv\")\n",
    "    \n",
    "    old_data = old_data[old_data['ticker'] == old_data['source_ticker']]\n",
    "    \n",
    "    old_data[\"old_sentiment\"] = old_data[\"sentiment\"]\n",
    "    new_data[\"new_sentiment\"] = new_data[\"sentiment\"]\n",
    "\n",
    "\n",
    "    old_data.drop('sentiment', axis=1, inplace=True)\n",
    "    new_data.drop('sentiment', axis=1, inplace=True)\n",
    "    \n",
    "    check_confusion_matrix(ticker, old_data, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1a58d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['META', 'NFLX', 'IBM', 'ORCL', 'INTC']\n",
    "original_data = \"dataset/polygon_title_sentiment_3\"\n",
    "new_data_dir = \"dataset/polygon_total_sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b30e0b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for META:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                     347      265       118\n",
      "neutral                      495      781       317\n",
      "negative                     106      172       259\n",
      "Confusion Matrix for NFLX:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                     241       94        44\n",
      "neutral                      242      357        89\n",
      "negative                      67       73        91\n",
      "Confusion Matrix for IBM:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                     132      128        17\n",
      "neutral                      158      216        65\n",
      "negative                      21       22        40\n",
      "Confusion Matrix for ORCL:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                     135      103        24\n",
      "neutral                      136      149        27\n",
      "negative                      31       24        36\n",
      "Confusion Matrix for INTC:\n",
      "New Sentiment (Column)  positive  neutral  negative\n",
      "Old Sentiment (Row)                                \n",
      "positive                     273      138        97\n",
      "neutral                      228      282       169\n",
      "negative                      85       75       173\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    old_data =  pd.read_csv(f\"{original_data}/{ticker}_title_sentiments.csv\")\n",
    "    new_data = pd.read_csv(f\"{new_data_dir}/{ticker}_total_sentiments.csv\")\n",
    "    \n",
    "#     old_data = old_data[old_data['ticker'] == old_data['source_ticker']]\n",
    "    \n",
    "    old_data[\"old_sentiment\"] = old_data[\"sentiment\"]\n",
    "    new_data[\"new_sentiment\"] = new_data[\"sentiment\"]\n",
    "\n",
    "\n",
    "    old_data.drop('sentiment', axis=1, inplace=True)\n",
    "    new_data.drop('sentiment', axis=1, inplace=True)\n",
    "    \n",
    "    check_confusion_matrix(ticker, old_data, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd0bd81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
